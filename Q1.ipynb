{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b46fe41",
      "metadata": {
        "id": "1b46fe41"
      },
      "source": [
        "<h1 align=\"center\">Introduction to Machine Learning - Course Code: 25737</h1>\n",
        "<h4 align=\"center\">Instructor: Dr. Amiri</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
        "<h4 align=\"center\">Computer Assignment 3</h4>\n",
        "<h4 align=\"center\">\n",
        "\n",
        "Question 1\n",
        "\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24a0fc13",
      "metadata": {
        "id": "24a0fc13"
      },
      "source": [
        "# Personal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "44babb65",
      "metadata": {
        "id": "44babb65"
      },
      "outputs": [],
      "source": [
        "# Set your student number\n",
        "student_number = 99102189\n",
        "Name = 'Mohammad'\n",
        "Last_Name = 'Mohammad Beigi'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca4a337a",
      "metadata": {
        "id": "ca4a337a"
      },
      "source": [
        "# Rules\n",
        "- You are not allowed to add or remove cells. You **must use the provided space to write your code**. If you don't follow this rule, **your Practical Assignment won't be graded**.  \n",
        "\n",
        "- Collaboration and using the internet is allowed, but your code **must be written by yourself**. **Copying code** from each other or from available resources will result in a **zero score for the assignment**.\n",
        "\n",
        "- You are not allowed to use `torch.nn`, `torch.optim` and any activation function and loss function implemented in torch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "12b76789",
      "metadata": {
        "id": "12b76789",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab488fa-34c3-438f-de9c-961dc7a53bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.2.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install torchvision\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886188c7",
      "metadata": {
        "id": "886188c7"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "55a0adcc",
      "metadata": {
        "id": "55a0adcc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18510868",
      "metadata": {
        "id": "18510868"
      },
      "source": [
        "## Datasets and Dataloaders\n",
        "\n",
        "Here, we download and load the train and test `FashionMNIST` dataset with the desired transforms. Then, we define the dataloaders for `train` and `test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "dc8759e2",
      "metadata": {
        "id": "dc8759e2"
      },
      "outputs": [],
      "source": [
        "train_set = FashionMNIST(root='.', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_set = FashionMNIST(root='.', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df47fcb",
      "metadata": {
        "id": "5df47fcb"
      },
      "source": [
        "\n",
        "Here you have to calculate the number of classes amd input dimention of the first layer (how many pixels does each image have?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "8f6763e6",
      "metadata": {
        "id": "8f6763e6"
      },
      "outputs": [],
      "source": [
        "# Calculate number of classes in the dataset\n",
        "num_classes = len(train_set.classes)\n",
        "\n",
        "# Calculate input dimensions (assuming images are square)\n",
        "input_dim = train_set[0][0].numel()  # Number of elements in the first image tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c695ff60",
      "metadata": {
        "id": "c695ff60"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, 64, shuffle=True)\n",
        "test_loader = DataLoader(test_set, 64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9dac6c2",
      "metadata": {
        "id": "f9dac6c2"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "Visualize 1 random image from each class by using `plt.subplots`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "e3d6b0c1",
      "metadata": {
        "id": "e3d6b0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "da0f57cb-ee4e-42e4-ef30-d04326c36b6e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_random_images(dataset, num_classes):\n",
        "    fig, axes = plt.subplots(1, num_classes, figsize=(10, 2))\n",
        "    class_images = {}\n",
        "\n",
        "    # Gather one image per class\n",
        "    while len(class_images) < num_classes:\n",
        "        index = np.random.randint(0, len(dataset))\n",
        "        image, label = dataset[index]\n",
        "        if label not in class_images:\n",
        "            class_images[label] = image\n",
        "\n",
        "    # Plot the images\n",
        "    for i, (label, image) in enumerate(sorted(class_images.items())):\n",
        "        ax = axes[i]\n",
        "        ax.imshow(image.squeeze(), cmap='gray')\n",
        "        ax.set_title(f'Class {label}')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "visualize_random_images(train_set, 10)  # There are 10 classes in FashionMNIST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a94c5aba",
      "metadata": {
        "id": "a94c5aba"
      },
      "source": [
        "## Initializing model's parameters\n",
        "\n",
        "In this part, we create the model and initialize its parameters and store the values of these parameters in the variable `parameters` which is a dictionary including the weigths and biases of each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "e6d40952",
      "metadata": {
        "id": "e6d40952"
      },
      "outputs": [],
      "source": [
        "def add_linear_layer(parameters: dict, shape, device, i=None):\n",
        "    \"\"\"\n",
        "    This function adds parameters of a linear unit of shape `shape` to the `parameters` dictionary.\n",
        "    \"\"\"\n",
        "    n_in, n_out = shape\n",
        "    with torch.no_grad():\n",
        "        w = torch.zeros(*shape, device=device)\n",
        "        # kaiming initialization for ReLU activations:\n",
        "        bound = 1 / np.sqrt(n_in).item()\n",
        "        w.uniform_(-bound, bound)\n",
        "        b = torch.zeros(n_out, device=device)  # no need to (1, n_out). it will broadcast itself.\n",
        "    w.requires_grad = True\n",
        "    b.requires_grad = True\n",
        "    # `i` is used to give numbers to parameter names\n",
        "    parameters.update({f'w{i}': w, f'b{i}': b})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce914706",
      "metadata": {
        "id": "ce914706"
      },
      "source": [
        "Now we define our neural network with the given layers and add the weights and biases to the dictionary `parameters`. **You are allowed to modify the values of the layers**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "8f3867d7",
      "metadata": {
        "id": "8f3867d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79477361-5c0c-46ce-b8ec-dabfa8ae9062"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['w0', 'b0', 'w1', 'b1', 'w2', 'b2', 'w3', 'b3', 'w4', 'b4'])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# input_dim : input dimention of the first layer, which you have calculated before.\n",
        "layers = [\n",
        "    (input_dim, 512),\n",
        "    (512, 256),\n",
        "    (256, 128),\n",
        "    (128, 64),\n",
        "    (64, num_classes)\n",
        "]\n",
        "num_layers = len(layers)\n",
        "parameters = {}\n",
        "\n",
        "# setting the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# adding the parameters to the dictionary\n",
        "for i, shape in enumerate(layers):\n",
        "    add_linear_layer(parameters, shape, device, i)\n",
        "\n",
        "parameters.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfd2c8e",
      "metadata": {
        "id": "8bfd2c8e"
      },
      "source": [
        "## Defining the required functions\n",
        "\n",
        "In this section, we should define the required functions. For each of these functions, the inputs and the desired outputs are given and you should write all or part of the function. **You are not allowed to use the activation functions and the loss functions implemented in torch**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b413d8",
      "metadata": {
        "id": "f3b413d8"
      },
      "source": [
        "Computing affine and relu outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "bebeeb0e",
      "metadata": {
        "id": "bebeeb0e"
      },
      "outputs": [],
      "source": [
        "def affine_forward(x, w, b):\n",
        "    return torch.matmul(x, w) + b\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    return torch.maximum(x, torch.tensor(0.0, device=x.device))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9baa5e",
      "metadata": {
        "id": "5d9baa5e"
      },
      "source": [
        "Function `model` returns output of the whole model for the input `x` using the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "d2562962",
      "metadata": {
        "id": "d2562962"
      },
      "outputs": [],
      "source": [
        "def model(x: torch.Tensor, parameters, num_layers=num_layers):\n",
        "    B = x.shape[0]  # number of batches\n",
        "    x = x.view(B, -1)  # Flatten the input\n",
        "\n",
        "    # Iterate over each layer and apply the affine transformation and ReLU\n",
        "    for i in range(num_layers):\n",
        "        w = parameters[f'w{i}']\n",
        "        b = parameters[f'b{i}']\n",
        "        x = affine_forward(x, w, b)  # Apply affine transformation\n",
        "        if i < num_layers - 1:  # Apply ReLU activation to all but the last layer\n",
        "            x = relu(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d17a9b4c",
      "metadata": {
        "id": "d17a9b4c"
      },
      "source": [
        "Implementing cross entropy loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "6959621c",
      "metadata": {
        "id": "6959621c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def cross_entropy_loss(scores, y):\n",
        "    n = len(y)  # Number of samples\n",
        "    # Convert scores to probabilities using softmax\n",
        "    probabilities = torch.exp(scores) / torch.exp(scores).sum(dim=1, keepdim=True)\n",
        "    # Gather the probabilities corresponding to the true classes\n",
        "    correct_probabilities = probabilities[range(n), y]\n",
        "    # Compute the negative log of these probabilities\n",
        "    loss = -torch.log(correct_probabilities).mean()\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a589af",
      "metadata": {
        "id": "15a589af"
      },
      "source": [
        "Implementing a function for optimizing paramters and a function to zeroing out their gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "3121c147",
      "metadata": {
        "id": "3121c147"
      },
      "outputs": [],
      "source": [
        "def sgd_optimizer(parameters: Dict[str, torch.Tensor], learning_rate=0.001):\n",
        "    # Update parameters\n",
        "    for param in parameters.values():\n",
        "        if param.grad is not None:  # Only try to update parameters that have gradients\n",
        "            param.data -= learning_rate * param.grad.data\n",
        "\n",
        "    # Zero the gradients after updating\n",
        "    for param in parameters.values():\n",
        "        if param.grad is not None:\n",
        "            param.grad = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17b4cf8",
      "metadata": {
        "id": "e17b4cf8"
      },
      "source": [
        "Training functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "76c0f03b",
      "metadata": {
        "id": "76c0f03b"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_pred: np.ndarray, y_true: np.ndarray):\n",
        "    # Calculate the number of correct predictions\n",
        "    correct_predictions = np.sum(y_pred == y_true)\n",
        "    # Calculate the accuracy: correct predictions / total number of data points\n",
        "    acc = correct_predictions / len(y_true)\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train(train_loader, learning_rate=0.001, epoch=None):\n",
        "    train_loss = 0\n",
        "    N_train = len(train_loader.dataset)\n",
        "\n",
        "    # Creating empty lists Y and Y_pred to store the labels and predictions of each batch\n",
        "    # for calculating the accuracy later\n",
        "    Y = []\n",
        "    Y_pred = []\n",
        "\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # 1- Calculate the output of the model to the given input batch\n",
        "        p = model(x, parameters)\n",
        "\n",
        "        # 2- Calculate the loss based on the model output\n",
        "        loss = cross_entropy_loss(p, y)\n",
        "        train_loss += loss.item() * y.size(0)  # Multiply by batch size for proper averaging later\n",
        "\n",
        "        # 3- Update the gradients using backward method\n",
        "        loss.backward()\n",
        "\n",
        "        # 4- Optimize the model parameters using the sgd_optimizer function defined previously\n",
        "        sgd_optimizer(parameters, learning_rate)\n",
        "\n",
        "        # Print the train loss (Show the epoch and batch as well)\n",
        "        print(f'Epoch: {epoch}, Batch: {i}, Batch Loss: {loss.item()}')\n",
        "\n",
        "        # Store labels and predictions for accuracy calculation\n",
        "        y_pred = p.argmax(dim=-1)\n",
        "        Y.append(y.cpu().numpy())\n",
        "        Y_pred.append(y_pred.cpu().numpy())\n",
        "\n",
        "    # Finalize loss and calculate accuracy\n",
        "    train_loss /= N_train  # Average loss over all samples\n",
        "    Y = np.concatenate(Y)\n",
        "    Y_pred = np.concatenate(Y_pred)\n",
        "    acc = accuracy(Y_pred, Y)\n",
        "    print(f'Accuracy of train set: {acc}')\n",
        "\n",
        "    return train_loss, acc\n",
        "\n",
        "\n",
        "def validate(loader, epoch=None, set_name=None):\n",
        "    total_loss = 0\n",
        "    N = len(loader.dataset)\n",
        "\n",
        "    # Creating empty lists Y and Y_pred to store the labels and predictions of each batch\n",
        "    # for calculating the accuracy later\n",
        "    Y = []\n",
        "    Y_pred = []\n",
        "\n",
        "    # Make sure to iterate over the correct loader, which should be passed as an argument\n",
        "    for i, (x, y) in enumerate(loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # 1- Calculate the model output\n",
        "        p = model(x, parameters)\n",
        "\n",
        "        # 2- Calculate the loss using the model output\n",
        "        loss = cross_entropy_loss(p, y)\n",
        "        total_loss += loss.item() * y.size(0)  # Multiply by batch size for proper averaging later\n",
        "\n",
        "        # Print the loss for each batch and epoch\n",
        "        print(f'Epoch: {epoch}, Batch: {i}, {set_name} Batch Loss: {loss.item()}')\n",
        "\n",
        "        # Store labels and predictions for accuracy calculation\n",
        "        y_pred = p.argmax(dim=-1)\n",
        "        Y.append(y.cpu().numpy())\n",
        "        Y_pred.append(y_pred.cpu().numpy())\n",
        "\n",
        "    # Calculate total loss and accuracy\n",
        "    total_loss /= N  # Average loss over all samples\n",
        "    Y = np.concatenate(Y)\n",
        "    Y_pred = np.concatenate(Y_pred)\n",
        "    acc = accuracy(Y_pred, Y)\n",
        "    print(f'Accuracy of {set_name} set: {acc}')\n",
        "\n",
        "    return total_loss, acc, Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "87ebb4b6",
      "metadata": {
        "id": "87ebb4b6"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "28d4eb0b",
      "metadata": {
        "id": "28d4eb0b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(dataloaders, num_epochs, learning_rate=0.001, model_name='pytorch_model'):\n",
        "    train_loader, test_loader = dataloaders\n",
        "\n",
        "    # Lists to store losses and accuracies\n",
        "    global train_losses, test_losses, train_accuracies, test_accuracies\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        train_loss, train_acc = train(train_loader, learning_rate, epoch)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        # Validation phase\n",
        "        test_loss, test_acc, Y_pred = validate(test_loader, epoch, set_name='test')\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
        "    return Y_pred\n",
        "\n",
        "    # Plotting loss history\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(test_losses, label='Test Loss')\n",
        "    plt.title('Loss History')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotting accuracy history\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(test_accuracies, label='Test Accuracy')\n",
        "    plt.title('Accuracy History')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "2ec4bdd2",
      "metadata": {
        "id": "2ec4bdd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd87db36-f71e-4115-da65-d5ec9e940d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 20, Batch: 490, Batch Loss: 0.3787146806716919\n",
            "Epoch: 20, Batch: 491, Batch Loss: 0.6821416616439819\n",
            "Epoch: 20, Batch: 492, Batch Loss: 0.23397426307201385\n",
            "Epoch: 20, Batch: 493, Batch Loss: 0.4061078429222107\n",
            "Epoch: 20, Batch: 494, Batch Loss: 0.5024861693382263\n",
            "Epoch: 20, Batch: 495, Batch Loss: 0.3040231466293335\n",
            "Epoch: 20, Batch: 496, Batch Loss: 0.6456047892570496\n",
            "Epoch: 20, Batch: 497, Batch Loss: 0.5842409729957581\n",
            "Epoch: 20, Batch: 498, Batch Loss: 0.5186441540718079\n",
            "Epoch: 20, Batch: 499, Batch Loss: 0.43440210819244385\n",
            "Epoch: 20, Batch: 500, Batch Loss: 0.27056336402893066\n",
            "Epoch: 20, Batch: 501, Batch Loss: 0.4180242121219635\n",
            "Epoch: 20, Batch: 502, Batch Loss: 0.42897316813468933\n",
            "Epoch: 20, Batch: 503, Batch Loss: 0.274751216173172\n",
            "Epoch: 20, Batch: 504, Batch Loss: 0.3741123080253601\n",
            "Epoch: 20, Batch: 505, Batch Loss: 0.420360803604126\n",
            "Epoch: 20, Batch: 506, Batch Loss: 0.44928795099258423\n",
            "Epoch: 20, Batch: 507, Batch Loss: 0.46796390414237976\n",
            "Epoch: 20, Batch: 508, Batch Loss: 0.2997290790081024\n",
            "Epoch: 20, Batch: 509, Batch Loss: 0.33400559425354004\n",
            "Epoch: 20, Batch: 510, Batch Loss: 0.4579862654209137\n",
            "Epoch: 20, Batch: 511, Batch Loss: 0.4192908704280853\n",
            "Epoch: 20, Batch: 512, Batch Loss: 0.27821794152259827\n",
            "Epoch: 20, Batch: 513, Batch Loss: 0.3854515254497528\n",
            "Epoch: 20, Batch: 514, Batch Loss: 0.42209017276763916\n",
            "Epoch: 20, Batch: 515, Batch Loss: 0.21761445701122284\n",
            "Epoch: 20, Batch: 516, Batch Loss: 0.3605770468711853\n",
            "Epoch: 20, Batch: 517, Batch Loss: 0.5463070869445801\n",
            "Epoch: 20, Batch: 518, Batch Loss: 0.3640848994255066\n",
            "Epoch: 20, Batch: 519, Batch Loss: 0.46008118987083435\n",
            "Epoch: 20, Batch: 520, Batch Loss: 0.21866820752620697\n",
            "Epoch: 20, Batch: 521, Batch Loss: 0.32008686661720276\n",
            "Epoch: 20, Batch: 522, Batch Loss: 0.29967015981674194\n",
            "Epoch: 20, Batch: 523, Batch Loss: 0.3813292682170868\n",
            "Epoch: 20, Batch: 524, Batch Loss: 0.39209333062171936\n",
            "Epoch: 20, Batch: 525, Batch Loss: 0.31455525755882263\n",
            "Epoch: 20, Batch: 526, Batch Loss: 0.3652820289134979\n",
            "Epoch: 20, Batch: 527, Batch Loss: 0.6099537014961243\n",
            "Epoch: 20, Batch: 528, Batch Loss: 0.32496941089630127\n",
            "Epoch: 20, Batch: 529, Batch Loss: 0.33475375175476074\n",
            "Epoch: 20, Batch: 530, Batch Loss: 0.4970361888408661\n",
            "Epoch: 20, Batch: 531, Batch Loss: 0.4534001350402832\n",
            "Epoch: 20, Batch: 532, Batch Loss: 0.5497583746910095\n",
            "Epoch: 20, Batch: 533, Batch Loss: 0.576772153377533\n",
            "Epoch: 20, Batch: 534, Batch Loss: 0.34463441371917725\n",
            "Epoch: 20, Batch: 535, Batch Loss: 0.36214426159858704\n",
            "Epoch: 20, Batch: 536, Batch Loss: 0.46154189109802246\n",
            "Epoch: 20, Batch: 537, Batch Loss: 0.4846174716949463\n",
            "Epoch: 20, Batch: 538, Batch Loss: 0.31238746643066406\n",
            "Epoch: 20, Batch: 539, Batch Loss: 0.2371547818183899\n",
            "Epoch: 20, Batch: 540, Batch Loss: 0.5009818077087402\n",
            "Epoch: 20, Batch: 541, Batch Loss: 0.3999696671962738\n",
            "Epoch: 20, Batch: 542, Batch Loss: 0.4169553518295288\n",
            "Epoch: 20, Batch: 543, Batch Loss: 0.5315952897071838\n",
            "Epoch: 20, Batch: 544, Batch Loss: 0.3166195750236511\n",
            "Epoch: 20, Batch: 545, Batch Loss: 0.5517096519470215\n",
            "Epoch: 20, Batch: 546, Batch Loss: 0.26859936118125916\n",
            "Epoch: 20, Batch: 547, Batch Loss: 0.5697734355926514\n",
            "Epoch: 20, Batch: 548, Batch Loss: 0.3750983774662018\n",
            "Epoch: 20, Batch: 549, Batch Loss: 0.3302884101867676\n",
            "Epoch: 20, Batch: 550, Batch Loss: 0.3142072558403015\n",
            "Epoch: 20, Batch: 551, Batch Loss: 0.3194999098777771\n",
            "Epoch: 20, Batch: 552, Batch Loss: 0.5681148767471313\n",
            "Epoch: 20, Batch: 553, Batch Loss: 0.44102412462234497\n",
            "Epoch: 20, Batch: 554, Batch Loss: 0.41714584827423096\n",
            "Epoch: 20, Batch: 555, Batch Loss: 0.26087114214897156\n",
            "Epoch: 20, Batch: 556, Batch Loss: 0.5106148719787598\n",
            "Epoch: 20, Batch: 557, Batch Loss: 0.27706393599510193\n",
            "Epoch: 20, Batch: 558, Batch Loss: 0.35675379633903503\n",
            "Epoch: 20, Batch: 559, Batch Loss: 0.3400348424911499\n",
            "Epoch: 20, Batch: 560, Batch Loss: 0.33900147676467896\n",
            "Epoch: 20, Batch: 561, Batch Loss: 0.4649915397167206\n",
            "Epoch: 20, Batch: 562, Batch Loss: 0.4234909117221832\n",
            "Epoch: 20, Batch: 563, Batch Loss: 0.42541441321372986\n",
            "Epoch: 20, Batch: 564, Batch Loss: 0.3070165514945984\n",
            "Epoch: 20, Batch: 565, Batch Loss: 0.3605367839336395\n",
            "Epoch: 20, Batch: 566, Batch Loss: 0.6430813670158386\n",
            "Epoch: 20, Batch: 567, Batch Loss: 0.41120821237564087\n",
            "Epoch: 20, Batch: 568, Batch Loss: 0.3584654927253723\n",
            "Epoch: 20, Batch: 569, Batch Loss: 0.3658325970172882\n",
            "Epoch: 20, Batch: 570, Batch Loss: 0.3689536452293396\n",
            "Epoch: 20, Batch: 571, Batch Loss: 0.3689526319503784\n",
            "Epoch: 20, Batch: 572, Batch Loss: 0.2929242253303528\n",
            "Epoch: 20, Batch: 573, Batch Loss: 0.46109119057655334\n",
            "Epoch: 20, Batch: 574, Batch Loss: 0.3116442561149597\n",
            "Epoch: 20, Batch: 575, Batch Loss: 0.375998854637146\n",
            "Epoch: 20, Batch: 576, Batch Loss: 0.33186036348342896\n",
            "Epoch: 20, Batch: 577, Batch Loss: 0.23896551132202148\n",
            "Epoch: 20, Batch: 578, Batch Loss: 0.5426952242851257\n",
            "Epoch: 20, Batch: 579, Batch Loss: 0.29715970158576965\n",
            "Epoch: 20, Batch: 580, Batch Loss: 0.5211794376373291\n",
            "Epoch: 20, Batch: 581, Batch Loss: 0.43795594573020935\n",
            "Epoch: 20, Batch: 582, Batch Loss: 0.36095136404037476\n",
            "Epoch: 20, Batch: 583, Batch Loss: 0.43642884492874146\n",
            "Epoch: 20, Batch: 584, Batch Loss: 0.31822872161865234\n",
            "Epoch: 20, Batch: 585, Batch Loss: 0.4256761372089386\n",
            "Epoch: 20, Batch: 586, Batch Loss: 0.40505489706993103\n",
            "Epoch: 20, Batch: 587, Batch Loss: 0.5505050420761108\n",
            "Epoch: 20, Batch: 588, Batch Loss: 0.3958445191383362\n",
            "Epoch: 20, Batch: 589, Batch Loss: 0.19595974683761597\n",
            "Epoch: 20, Batch: 590, Batch Loss: 0.3034611642360687\n",
            "Epoch: 20, Batch: 591, Batch Loss: 0.6133492588996887\n",
            "Epoch: 20, Batch: 592, Batch Loss: 0.38906189799308777\n",
            "Epoch: 20, Batch: 593, Batch Loss: 0.32263219356536865\n",
            "Epoch: 20, Batch: 594, Batch Loss: 0.5553472638130188\n",
            "Epoch: 20, Batch: 595, Batch Loss: 0.46298524737358093\n",
            "Epoch: 20, Batch: 596, Batch Loss: 0.6454588174819946\n",
            "Epoch: 20, Batch: 597, Batch Loss: 0.49316030740737915\n",
            "Epoch: 20, Batch: 598, Batch Loss: 0.48265016078948975\n",
            "Epoch: 20, Batch: 599, Batch Loss: 0.6495176553726196\n",
            "Epoch: 20, Batch: 600, Batch Loss: 0.43540099263191223\n",
            "Epoch: 20, Batch: 601, Batch Loss: 0.3225446939468384\n",
            "Epoch: 20, Batch: 602, Batch Loss: 0.6518141031265259\n",
            "Epoch: 20, Batch: 603, Batch Loss: 0.46516597270965576\n",
            "Epoch: 20, Batch: 604, Batch Loss: 0.31661346554756165\n",
            "Epoch: 20, Batch: 605, Batch Loss: 0.6270202398300171\n",
            "Epoch: 20, Batch: 606, Batch Loss: 0.24014921486377716\n",
            "Epoch: 20, Batch: 607, Batch Loss: 0.4239101707935333\n",
            "Epoch: 20, Batch: 608, Batch Loss: 0.37576544284820557\n",
            "Epoch: 20, Batch: 609, Batch Loss: 0.4711301326751709\n",
            "Epoch: 20, Batch: 610, Batch Loss: 0.3312314748764038\n",
            "Epoch: 20, Batch: 611, Batch Loss: 0.4811365604400635\n",
            "Epoch: 20, Batch: 612, Batch Loss: 0.33367523550987244\n",
            "Epoch: 20, Batch: 613, Batch Loss: 0.376268208026886\n",
            "Epoch: 20, Batch: 614, Batch Loss: 0.385509192943573\n",
            "Epoch: 20, Batch: 615, Batch Loss: 0.45776158571243286\n",
            "Epoch: 20, Batch: 616, Batch Loss: 0.4289194345474243\n",
            "Epoch: 20, Batch: 617, Batch Loss: 0.5227943658828735\n",
            "Epoch: 20, Batch: 618, Batch Loss: 0.38079968094825745\n",
            "Epoch: 20, Batch: 619, Batch Loss: 0.5061506628990173\n",
            "Epoch: 20, Batch: 620, Batch Loss: 0.4696803092956543\n",
            "Epoch: 20, Batch: 621, Batch Loss: 0.4099881052970886\n",
            "Epoch: 20, Batch: 622, Batch Loss: 0.25329694151878357\n",
            "Epoch: 20, Batch: 623, Batch Loss: 0.2670048475265503\n",
            "Epoch: 20, Batch: 624, Batch Loss: 0.4020436704158783\n",
            "Epoch: 20, Batch: 625, Batch Loss: 0.5758870840072632\n",
            "Epoch: 20, Batch: 626, Batch Loss: 0.2912539839744568\n",
            "Epoch: 20, Batch: 627, Batch Loss: 0.5681192874908447\n",
            "Epoch: 20, Batch: 628, Batch Loss: 0.8470482230186462\n",
            "Epoch: 20, Batch: 629, Batch Loss: 0.42291298508644104\n",
            "Epoch: 20, Batch: 630, Batch Loss: 0.505204439163208\n",
            "Epoch: 20, Batch: 631, Batch Loss: 0.3364912271499634\n",
            "Epoch: 20, Batch: 632, Batch Loss: 0.3673114776611328\n",
            "Epoch: 20, Batch: 633, Batch Loss: 0.4990168809890747\n",
            "Epoch: 20, Batch: 634, Batch Loss: 0.3659311830997467\n",
            "Epoch: 20, Batch: 635, Batch Loss: 0.3972478210926056\n",
            "Epoch: 20, Batch: 636, Batch Loss: 0.45337802171707153\n",
            "Epoch: 20, Batch: 637, Batch Loss: 0.34140822291374207\n",
            "Epoch: 20, Batch: 638, Batch Loss: 0.4666987359523773\n",
            "Epoch: 20, Batch: 639, Batch Loss: 0.41809821128845215\n",
            "Epoch: 20, Batch: 640, Batch Loss: 0.4811475872993469\n",
            "Epoch: 20, Batch: 641, Batch Loss: 0.3966732919216156\n",
            "Epoch: 20, Batch: 642, Batch Loss: 0.34811052680015564\n",
            "Epoch: 20, Batch: 643, Batch Loss: 0.2695547342300415\n",
            "Epoch: 20, Batch: 644, Batch Loss: 0.6290686130523682\n",
            "Epoch: 20, Batch: 645, Batch Loss: 0.47233885526657104\n",
            "Epoch: 20, Batch: 646, Batch Loss: 0.3290984034538269\n",
            "Epoch: 20, Batch: 647, Batch Loss: 0.7260016202926636\n",
            "Epoch: 20, Batch: 648, Batch Loss: 0.2999931871891022\n",
            "Epoch: 20, Batch: 649, Batch Loss: 0.7611271739006042\n",
            "Epoch: 20, Batch: 650, Batch Loss: 0.5110495090484619\n",
            "Epoch: 20, Batch: 651, Batch Loss: 0.412569522857666\n",
            "Epoch: 20, Batch: 652, Batch Loss: 0.47871822118759155\n",
            "Epoch: 20, Batch: 653, Batch Loss: 0.3220199942588806\n",
            "Epoch: 20, Batch: 654, Batch Loss: 0.30717360973358154\n",
            "Epoch: 20, Batch: 655, Batch Loss: 0.6965889930725098\n",
            "Epoch: 20, Batch: 656, Batch Loss: 0.43603813648223877\n",
            "Epoch: 20, Batch: 657, Batch Loss: 0.5094977021217346\n",
            "Epoch: 20, Batch: 658, Batch Loss: 0.41477251052856445\n",
            "Epoch: 20, Batch: 659, Batch Loss: 0.4636117219924927\n",
            "Epoch: 20, Batch: 660, Batch Loss: 0.384181946516037\n",
            "Epoch: 20, Batch: 661, Batch Loss: 0.33517712354660034\n",
            "Epoch: 20, Batch: 662, Batch Loss: 0.3366541266441345\n",
            "Epoch: 20, Batch: 663, Batch Loss: 0.46404939889907837\n",
            "Epoch: 20, Batch: 664, Batch Loss: 0.20098385214805603\n",
            "Epoch: 20, Batch: 665, Batch Loss: 0.4335240125656128\n",
            "Epoch: 20, Batch: 666, Batch Loss: 0.34072554111480713\n",
            "Epoch: 20, Batch: 667, Batch Loss: 0.4271290898323059\n",
            "Epoch: 20, Batch: 668, Batch Loss: 0.39029332995414734\n",
            "Epoch: 20, Batch: 669, Batch Loss: 0.32696956396102905\n",
            "Epoch: 20, Batch: 670, Batch Loss: 0.3357340693473816\n",
            "Epoch: 20, Batch: 671, Batch Loss: 0.49525564908981323\n",
            "Epoch: 20, Batch: 672, Batch Loss: 0.3434320092201233\n",
            "Epoch: 20, Batch: 673, Batch Loss: 0.5770888328552246\n",
            "Epoch: 20, Batch: 674, Batch Loss: 0.40508368611335754\n",
            "Epoch: 20, Batch: 675, Batch Loss: 0.26437604427337646\n",
            "Epoch: 20, Batch: 676, Batch Loss: 0.5265040397644043\n",
            "Epoch: 20, Batch: 677, Batch Loss: 0.6521661877632141\n",
            "Epoch: 20, Batch: 678, Batch Loss: 0.4985446035861969\n",
            "Epoch: 20, Batch: 679, Batch Loss: 0.46208852529525757\n",
            "Epoch: 20, Batch: 680, Batch Loss: 0.37457865476608276\n",
            "Epoch: 20, Batch: 681, Batch Loss: 0.42845240235328674\n",
            "Epoch: 20, Batch: 682, Batch Loss: 0.5160049796104431\n",
            "Epoch: 20, Batch: 683, Batch Loss: 0.44224268198013306\n",
            "Epoch: 20, Batch: 684, Batch Loss: 0.39321792125701904\n",
            "Epoch: 20, Batch: 685, Batch Loss: 0.5007157921791077\n",
            "Epoch: 20, Batch: 686, Batch Loss: 0.5201519727706909\n",
            "Epoch: 20, Batch: 687, Batch Loss: 0.5878341197967529\n",
            "Epoch: 20, Batch: 688, Batch Loss: 0.2702837288379669\n",
            "Epoch: 20, Batch: 689, Batch Loss: 0.5402554273605347\n",
            "Epoch: 20, Batch: 690, Batch Loss: 0.3857334852218628\n",
            "Epoch: 20, Batch: 691, Batch Loss: 0.26318931579589844\n",
            "Epoch: 20, Batch: 692, Batch Loss: 0.3724573850631714\n",
            "Epoch: 20, Batch: 693, Batch Loss: 0.6368191242218018\n",
            "Epoch: 20, Batch: 694, Batch Loss: 0.33620455861091614\n",
            "Epoch: 20, Batch: 695, Batch Loss: 0.3067135214805603\n",
            "Epoch: 20, Batch: 696, Batch Loss: 0.43040817975997925\n",
            "Epoch: 20, Batch: 697, Batch Loss: 0.6297973990440369\n",
            "Epoch: 20, Batch: 698, Batch Loss: 0.5918243527412415\n",
            "Epoch: 20, Batch: 699, Batch Loss: 0.31607845425605774\n",
            "Epoch: 20, Batch: 700, Batch Loss: 0.3112923502922058\n",
            "Epoch: 20, Batch: 701, Batch Loss: 0.46123969554901123\n",
            "Epoch: 20, Batch: 702, Batch Loss: 0.3633962869644165\n",
            "Epoch: 20, Batch: 703, Batch Loss: 0.42073267698287964\n",
            "Epoch: 20, Batch: 704, Batch Loss: 0.3594273626804352\n",
            "Epoch: 20, Batch: 705, Batch Loss: 0.43426641821861267\n",
            "Epoch: 20, Batch: 706, Batch Loss: 0.3181620240211487\n",
            "Epoch: 20, Batch: 707, Batch Loss: 0.46917837858200073\n",
            "Epoch: 20, Batch: 708, Batch Loss: 0.5964398384094238\n",
            "Epoch: 20, Batch: 709, Batch Loss: 0.4587119519710541\n",
            "Epoch: 20, Batch: 710, Batch Loss: 0.501013457775116\n",
            "Epoch: 20, Batch: 711, Batch Loss: 0.3895058035850525\n",
            "Epoch: 20, Batch: 712, Batch Loss: 0.6475937366485596\n",
            "Epoch: 20, Batch: 713, Batch Loss: 0.38041549921035767\n",
            "Epoch: 20, Batch: 714, Batch Loss: 0.3706324100494385\n",
            "Epoch: 20, Batch: 715, Batch Loss: 0.44728517532348633\n",
            "Epoch: 20, Batch: 716, Batch Loss: 0.5832715630531311\n",
            "Epoch: 20, Batch: 717, Batch Loss: 0.6236194372177124\n",
            "Epoch: 20, Batch: 718, Batch Loss: 0.4601488709449768\n",
            "Epoch: 20, Batch: 719, Batch Loss: 0.35603275895118713\n",
            "Epoch: 20, Batch: 720, Batch Loss: 0.48767712712287903\n",
            "Epoch: 20, Batch: 721, Batch Loss: 0.29665225744247437\n",
            "Epoch: 20, Batch: 722, Batch Loss: 0.4562281370162964\n",
            "Epoch: 20, Batch: 723, Batch Loss: 0.19276119768619537\n",
            "Epoch: 20, Batch: 724, Batch Loss: 0.4047703146934509\n",
            "Epoch: 20, Batch: 725, Batch Loss: 0.4815787672996521\n",
            "Epoch: 20, Batch: 726, Batch Loss: 0.6212592124938965\n",
            "Epoch: 20, Batch: 727, Batch Loss: 0.2806283235549927\n",
            "Epoch: 20, Batch: 728, Batch Loss: 0.5148637890815735\n",
            "Epoch: 20, Batch: 729, Batch Loss: 0.33115899562835693\n",
            "Epoch: 20, Batch: 730, Batch Loss: 0.41724660992622375\n",
            "Epoch: 20, Batch: 731, Batch Loss: 0.348195880651474\n",
            "Epoch: 20, Batch: 732, Batch Loss: 0.31759482622146606\n",
            "Epoch: 20, Batch: 733, Batch Loss: 0.46797528862953186\n",
            "Epoch: 20, Batch: 734, Batch Loss: 0.29905885457992554\n",
            "Epoch: 20, Batch: 735, Batch Loss: 0.3843315839767456\n",
            "Epoch: 20, Batch: 736, Batch Loss: 0.6079142093658447\n",
            "Epoch: 20, Batch: 737, Batch Loss: 0.42789426445961\n",
            "Epoch: 20, Batch: 738, Batch Loss: 0.42147180438041687\n",
            "Epoch: 20, Batch: 739, Batch Loss: 0.44477522373199463\n",
            "Epoch: 20, Batch: 740, Batch Loss: 0.37306973338127136\n",
            "Epoch: 20, Batch: 741, Batch Loss: 0.2905718684196472\n",
            "Epoch: 20, Batch: 742, Batch Loss: 0.2853429913520813\n",
            "Epoch: 20, Batch: 743, Batch Loss: 0.5596073865890503\n",
            "Epoch: 20, Batch: 744, Batch Loss: 0.25102460384368896\n",
            "Epoch: 20, Batch: 745, Batch Loss: 0.261735200881958\n",
            "Epoch: 20, Batch: 746, Batch Loss: 0.3828321099281311\n",
            "Epoch: 20, Batch: 747, Batch Loss: 0.26309603452682495\n",
            "Epoch: 20, Batch: 748, Batch Loss: 0.4784800708293915\n",
            "Epoch: 20, Batch: 749, Batch Loss: 0.3913286328315735\n",
            "Epoch: 20, Batch: 750, Batch Loss: 0.40258103609085083\n",
            "Epoch: 20, Batch: 751, Batch Loss: 0.5237678289413452\n",
            "Epoch: 20, Batch: 752, Batch Loss: 0.4206935167312622\n",
            "Epoch: 20, Batch: 753, Batch Loss: 0.24754613637924194\n",
            "Epoch: 20, Batch: 754, Batch Loss: 0.43045786023139954\n",
            "Epoch: 20, Batch: 755, Batch Loss: 0.48631301522254944\n",
            "Epoch: 20, Batch: 756, Batch Loss: 0.4705728590488434\n",
            "Epoch: 20, Batch: 757, Batch Loss: 0.29348400235176086\n",
            "Epoch: 20, Batch: 758, Batch Loss: 0.4721265733242035\n",
            "Epoch: 20, Batch: 759, Batch Loss: 0.3478671908378601\n",
            "Epoch: 20, Batch: 760, Batch Loss: 0.38033005595207214\n",
            "Epoch: 20, Batch: 761, Batch Loss: 0.5862873792648315\n",
            "Epoch: 20, Batch: 762, Batch Loss: 0.36577504873275757\n",
            "Epoch: 20, Batch: 763, Batch Loss: 0.419824481010437\n",
            "Epoch: 20, Batch: 764, Batch Loss: 0.4335009753704071\n",
            "Epoch: 20, Batch: 765, Batch Loss: 0.4956815838813782\n",
            "Epoch: 20, Batch: 766, Batch Loss: 0.33852195739746094\n",
            "Epoch: 20, Batch: 767, Batch Loss: 0.5213354825973511\n",
            "Epoch: 20, Batch: 768, Batch Loss: 0.4207720160484314\n",
            "Epoch: 20, Batch: 769, Batch Loss: 0.35656681656837463\n",
            "Epoch: 20, Batch: 770, Batch Loss: 0.48428231477737427\n",
            "Epoch: 20, Batch: 771, Batch Loss: 0.5386872291564941\n",
            "Epoch: 20, Batch: 772, Batch Loss: 0.42678242921829224\n",
            "Epoch: 20, Batch: 773, Batch Loss: 0.2788833975791931\n",
            "Epoch: 20, Batch: 774, Batch Loss: 0.36079198122024536\n",
            "Epoch: 20, Batch: 775, Batch Loss: 0.29250484704971313\n",
            "Epoch: 20, Batch: 776, Batch Loss: 0.38830581307411194\n",
            "Epoch: 20, Batch: 777, Batch Loss: 0.4641323387622833\n",
            "Epoch: 20, Batch: 778, Batch Loss: 0.4696641266345978\n",
            "Epoch: 20, Batch: 779, Batch Loss: 0.4478943645954132\n",
            "Epoch: 20, Batch: 780, Batch Loss: 0.45451146364212036\n",
            "Epoch: 20, Batch: 781, Batch Loss: 0.4603976905345917\n",
            "Epoch: 20, Batch: 782, Batch Loss: 0.40836286544799805\n",
            "Epoch: 20, Batch: 783, Batch Loss: 0.37793391942977905\n",
            "Epoch: 20, Batch: 784, Batch Loss: 0.5559647679328918\n",
            "Epoch: 20, Batch: 785, Batch Loss: 0.466708242893219\n",
            "Epoch: 20, Batch: 786, Batch Loss: 0.6649755835533142\n",
            "Epoch: 20, Batch: 787, Batch Loss: 0.34993669390678406\n",
            "Epoch: 20, Batch: 788, Batch Loss: 0.39752256870269775\n",
            "Epoch: 20, Batch: 789, Batch Loss: 0.27601921558380127\n",
            "Epoch: 20, Batch: 790, Batch Loss: 0.470042884349823\n",
            "Epoch: 20, Batch: 791, Batch Loss: 0.5136455297470093\n",
            "Epoch: 20, Batch: 792, Batch Loss: 0.31097304821014404\n",
            "Epoch: 20, Batch: 793, Batch Loss: 0.4379681348800659\n",
            "Epoch: 20, Batch: 794, Batch Loss: 0.27920669317245483\n",
            "Epoch: 20, Batch: 795, Batch Loss: 0.2975562810897827\n",
            "Epoch: 20, Batch: 796, Batch Loss: 0.601887583732605\n",
            "Epoch: 20, Batch: 797, Batch Loss: 0.3268106281757355\n",
            "Epoch: 20, Batch: 798, Batch Loss: 0.3135540783405304\n",
            "Epoch: 20, Batch: 799, Batch Loss: 0.4899592995643616\n",
            "Epoch: 20, Batch: 800, Batch Loss: 0.44809019565582275\n",
            "Epoch: 20, Batch: 801, Batch Loss: 0.5136277079582214\n",
            "Epoch: 20, Batch: 802, Batch Loss: 0.5149620771408081\n",
            "Epoch: 20, Batch: 803, Batch Loss: 0.41458454728126526\n",
            "Epoch: 20, Batch: 804, Batch Loss: 0.31879401206970215\n",
            "Epoch: 20, Batch: 805, Batch Loss: 0.7070746421813965\n",
            "Epoch: 20, Batch: 806, Batch Loss: 0.3372367024421692\n",
            "Epoch: 20, Batch: 807, Batch Loss: 0.3559235632419586\n",
            "Epoch: 20, Batch: 808, Batch Loss: 0.3360932171344757\n",
            "Epoch: 20, Batch: 809, Batch Loss: 0.3787916600704193\n",
            "Epoch: 20, Batch: 810, Batch Loss: 0.33311665058135986\n",
            "Epoch: 20, Batch: 811, Batch Loss: 0.3095759153366089\n",
            "Epoch: 20, Batch: 812, Batch Loss: 0.4445311725139618\n",
            "Epoch: 20, Batch: 813, Batch Loss: 0.3124939501285553\n",
            "Epoch: 20, Batch: 814, Batch Loss: 0.43442726135253906\n",
            "Epoch: 20, Batch: 815, Batch Loss: 0.4030831456184387\n",
            "Epoch: 20, Batch: 816, Batch Loss: 0.3931749165058136\n",
            "Epoch: 20, Batch: 817, Batch Loss: 0.5937889218330383\n",
            "Epoch: 20, Batch: 818, Batch Loss: 0.3037267029285431\n",
            "Epoch: 20, Batch: 819, Batch Loss: 0.48657703399658203\n",
            "Epoch: 20, Batch: 820, Batch Loss: 0.41967302560806274\n",
            "Epoch: 20, Batch: 821, Batch Loss: 0.4646929204463959\n",
            "Epoch: 20, Batch: 822, Batch Loss: 0.23963826894760132\n",
            "Epoch: 20, Batch: 823, Batch Loss: 0.3604683578014374\n",
            "Epoch: 20, Batch: 824, Batch Loss: 0.296248197555542\n",
            "Epoch: 20, Batch: 825, Batch Loss: 0.3509176969528198\n",
            "Epoch: 20, Batch: 826, Batch Loss: 0.36251306533813477\n",
            "Epoch: 20, Batch: 827, Batch Loss: 0.2967122197151184\n",
            "Epoch: 20, Batch: 828, Batch Loss: 0.4527774751186371\n",
            "Epoch: 20, Batch: 829, Batch Loss: 0.2794167399406433\n",
            "Epoch: 20, Batch: 830, Batch Loss: 0.39729011058807373\n",
            "Epoch: 20, Batch: 831, Batch Loss: 0.3564012050628662\n",
            "Epoch: 20, Batch: 832, Batch Loss: 0.43668806552886963\n",
            "Epoch: 20, Batch: 833, Batch Loss: 0.522988498210907\n",
            "Epoch: 20, Batch: 834, Batch Loss: 0.3754834830760956\n",
            "Epoch: 20, Batch: 835, Batch Loss: 0.25566065311431885\n",
            "Epoch: 20, Batch: 836, Batch Loss: 0.5589317083358765\n",
            "Epoch: 20, Batch: 837, Batch Loss: 0.26156145334243774\n",
            "Epoch: 20, Batch: 838, Batch Loss: 0.4005180895328522\n",
            "Epoch: 20, Batch: 839, Batch Loss: 0.3921031653881073\n",
            "Epoch: 20, Batch: 840, Batch Loss: 0.3806367814540863\n",
            "Epoch: 20, Batch: 841, Batch Loss: 0.36470964550971985\n",
            "Epoch: 20, Batch: 842, Batch Loss: 0.5147464275360107\n",
            "Epoch: 20, Batch: 843, Batch Loss: 0.21105803549289703\n",
            "Epoch: 20, Batch: 844, Batch Loss: 0.20979826152324677\n",
            "Epoch: 20, Batch: 845, Batch Loss: 0.335954874753952\n",
            "Epoch: 20, Batch: 846, Batch Loss: 0.3289979100227356\n",
            "Epoch: 20, Batch: 847, Batch Loss: 0.3154316246509552\n",
            "Epoch: 20, Batch: 848, Batch Loss: 0.6592591404914856\n",
            "Epoch: 20, Batch: 849, Batch Loss: 0.4360980987548828\n",
            "Epoch: 20, Batch: 850, Batch Loss: 0.4296058714389801\n",
            "Epoch: 20, Batch: 851, Batch Loss: 0.39811035990715027\n",
            "Epoch: 20, Batch: 852, Batch Loss: 0.48219603300094604\n",
            "Epoch: 20, Batch: 853, Batch Loss: 0.23157519102096558\n",
            "Epoch: 20, Batch: 854, Batch Loss: 0.42085587978363037\n",
            "Epoch: 20, Batch: 855, Batch Loss: 0.35239216685295105\n",
            "Epoch: 20, Batch: 856, Batch Loss: 0.42098096013069153\n",
            "Epoch: 20, Batch: 857, Batch Loss: 0.5000138878822327\n",
            "Epoch: 20, Batch: 858, Batch Loss: 0.37595340609550476\n",
            "Epoch: 20, Batch: 859, Batch Loss: 0.37881675362586975\n",
            "Epoch: 20, Batch: 860, Batch Loss: 0.2825213074684143\n",
            "Epoch: 20, Batch: 861, Batch Loss: 0.28888824582099915\n",
            "Epoch: 20, Batch: 862, Batch Loss: 0.35441070795059204\n",
            "Epoch: 20, Batch: 863, Batch Loss: 0.4844861626625061\n",
            "Epoch: 20, Batch: 864, Batch Loss: 0.31361812353134155\n",
            "Epoch: 20, Batch: 865, Batch Loss: 0.4067310094833374\n",
            "Epoch: 20, Batch: 866, Batch Loss: 0.4104721248149872\n",
            "Epoch: 20, Batch: 867, Batch Loss: 0.30408331751823425\n",
            "Epoch: 20, Batch: 868, Batch Loss: 0.33118289709091187\n",
            "Epoch: 20, Batch: 869, Batch Loss: 0.33920085430145264\n",
            "Epoch: 20, Batch: 870, Batch Loss: 0.3341536223888397\n",
            "Epoch: 20, Batch: 871, Batch Loss: 0.4947928190231323\n",
            "Epoch: 20, Batch: 872, Batch Loss: 0.42249158024787903\n",
            "Epoch: 20, Batch: 873, Batch Loss: 0.4359440207481384\n",
            "Epoch: 20, Batch: 874, Batch Loss: 0.21981535851955414\n",
            "Epoch: 20, Batch: 875, Batch Loss: 0.39919665455818176\n",
            "Epoch: 20, Batch: 876, Batch Loss: 0.45576372742652893\n",
            "Epoch: 20, Batch: 877, Batch Loss: 0.41512471437454224\n",
            "Epoch: 20, Batch: 878, Batch Loss: 0.6399886608123779\n",
            "Epoch: 20, Batch: 879, Batch Loss: 0.3943444490432739\n",
            "Epoch: 20, Batch: 880, Batch Loss: 0.291466623544693\n",
            "Epoch: 20, Batch: 881, Batch Loss: 0.32996276021003723\n",
            "Epoch: 20, Batch: 882, Batch Loss: 0.4247691035270691\n",
            "Epoch: 20, Batch: 883, Batch Loss: 0.4744924306869507\n",
            "Epoch: 20, Batch: 884, Batch Loss: 0.47626981139183044\n",
            "Epoch: 20, Batch: 885, Batch Loss: 0.377432644367218\n",
            "Epoch: 20, Batch: 886, Batch Loss: 0.4007563591003418\n",
            "Epoch: 20, Batch: 887, Batch Loss: 0.3169981837272644\n",
            "Epoch: 20, Batch: 888, Batch Loss: 0.18388471007347107\n",
            "Epoch: 20, Batch: 889, Batch Loss: 0.6136435270309448\n",
            "Epoch: 20, Batch: 890, Batch Loss: 0.4054945707321167\n",
            "Epoch: 20, Batch: 891, Batch Loss: 0.44525977969169617\n",
            "Epoch: 20, Batch: 892, Batch Loss: 0.5687735676765442\n",
            "Epoch: 20, Batch: 893, Batch Loss: 0.3888421654701233\n",
            "Epoch: 20, Batch: 894, Batch Loss: 0.22422634065151215\n",
            "Epoch: 20, Batch: 895, Batch Loss: 0.5422185063362122\n",
            "Epoch: 20, Batch: 896, Batch Loss: 0.30541297793388367\n",
            "Epoch: 20, Batch: 897, Batch Loss: 0.319769024848938\n",
            "Epoch: 20, Batch: 898, Batch Loss: 0.32087182998657227\n",
            "Epoch: 20, Batch: 899, Batch Loss: 0.4580765664577484\n",
            "Epoch: 20, Batch: 900, Batch Loss: 0.5426321029663086\n",
            "Epoch: 20, Batch: 901, Batch Loss: 0.37382829189300537\n",
            "Epoch: 20, Batch: 902, Batch Loss: 0.39436405897140503\n",
            "Epoch: 20, Batch: 903, Batch Loss: 0.25910091400146484\n",
            "Epoch: 20, Batch: 904, Batch Loss: 0.5321981310844421\n",
            "Epoch: 20, Batch: 905, Batch Loss: 0.391349196434021\n",
            "Epoch: 20, Batch: 906, Batch Loss: 0.3155648410320282\n",
            "Epoch: 20, Batch: 907, Batch Loss: 0.38652434945106506\n",
            "Epoch: 20, Batch: 908, Batch Loss: 0.2800702154636383\n",
            "Epoch: 20, Batch: 909, Batch Loss: 0.37959662079811096\n",
            "Epoch: 20, Batch: 910, Batch Loss: 0.5448657274246216\n",
            "Epoch: 20, Batch: 911, Batch Loss: 0.584610104560852\n",
            "Epoch: 20, Batch: 912, Batch Loss: 0.6151325106620789\n",
            "Epoch: 20, Batch: 913, Batch Loss: 0.33691108226776123\n",
            "Epoch: 20, Batch: 914, Batch Loss: 0.25146639347076416\n",
            "Epoch: 20, Batch: 915, Batch Loss: 0.2436683624982834\n",
            "Epoch: 20, Batch: 916, Batch Loss: 0.30369794368743896\n",
            "Epoch: 20, Batch: 917, Batch Loss: 0.3146909177303314\n",
            "Epoch: 20, Batch: 918, Batch Loss: 0.4651121199131012\n",
            "Epoch: 20, Batch: 919, Batch Loss: 0.3291424810886383\n",
            "Epoch: 20, Batch: 920, Batch Loss: 0.42735356092453003\n",
            "Epoch: 20, Batch: 921, Batch Loss: 0.4489193856716156\n",
            "Epoch: 20, Batch: 922, Batch Loss: 0.28846362233161926\n",
            "Epoch: 20, Batch: 923, Batch Loss: 0.4146578311920166\n",
            "Epoch: 20, Batch: 924, Batch Loss: 0.5413156747817993\n",
            "Epoch: 20, Batch: 925, Batch Loss: 0.508746325969696\n",
            "Epoch: 20, Batch: 926, Batch Loss: 0.39083871245384216\n",
            "Epoch: 20, Batch: 927, Batch Loss: 0.3291345238685608\n",
            "Epoch: 20, Batch: 928, Batch Loss: 0.43032747507095337\n",
            "Epoch: 20, Batch: 929, Batch Loss: 0.2550566494464874\n",
            "Epoch: 20, Batch: 930, Batch Loss: 0.23748236894607544\n",
            "Epoch: 20, Batch: 931, Batch Loss: 0.31782326102256775\n",
            "Epoch: 20, Batch: 932, Batch Loss: 0.6353228688240051\n",
            "Epoch: 20, Batch: 933, Batch Loss: 0.3776150941848755\n",
            "Epoch: 20, Batch: 934, Batch Loss: 0.3217976689338684\n",
            "Epoch: 20, Batch: 935, Batch Loss: 0.6157439351081848\n",
            "Epoch: 20, Batch: 936, Batch Loss: 0.4300163686275482\n",
            "Epoch: 20, Batch: 937, Batch Loss: 0.4180498421192169\n",
            "Accuracy of train set: 0.8563\n",
            "Epoch: 20, Batch: 0, test Batch Loss: 0.46817755699157715\n",
            "Epoch: 20, Batch: 1, test Batch Loss: 0.6460357308387756\n",
            "Epoch: 20, Batch: 2, test Batch Loss: 0.4549621045589447\n",
            "Epoch: 20, Batch: 3, test Batch Loss: 0.6373496651649475\n",
            "Epoch: 20, Batch: 4, test Batch Loss: 0.4563094675540924\n",
            "Epoch: 20, Batch: 5, test Batch Loss: 0.5177662372589111\n",
            "Epoch: 20, Batch: 6, test Batch Loss: 0.3820136785507202\n",
            "Epoch: 20, Batch: 7, test Batch Loss: 0.4863547384738922\n",
            "Epoch: 20, Batch: 8, test Batch Loss: 0.4390883445739746\n",
            "Epoch: 20, Batch: 9, test Batch Loss: 0.4784339666366577\n",
            "Epoch: 20, Batch: 10, test Batch Loss: 0.6156594753265381\n",
            "Epoch: 20, Batch: 11, test Batch Loss: 0.6139445900917053\n",
            "Epoch: 20, Batch: 12, test Batch Loss: 0.42682501673698425\n",
            "Epoch: 20, Batch: 13, test Batch Loss: 0.3970695734024048\n",
            "Epoch: 20, Batch: 14, test Batch Loss: 0.4801161587238312\n",
            "Epoch: 20, Batch: 15, test Batch Loss: 0.592222273349762\n",
            "Epoch: 20, Batch: 16, test Batch Loss: 0.47531265020370483\n",
            "Epoch: 20, Batch: 17, test Batch Loss: 0.4646800756454468\n",
            "Epoch: 20, Batch: 18, test Batch Loss: 0.56879061460495\n",
            "Epoch: 20, Batch: 19, test Batch Loss: 0.2986977696418762\n",
            "Epoch: 20, Batch: 20, test Batch Loss: 0.5677596926689148\n",
            "Epoch: 20, Batch: 21, test Batch Loss: 0.7249398827552795\n",
            "Epoch: 20, Batch: 22, test Batch Loss: 0.433746337890625\n",
            "Epoch: 20, Batch: 23, test Batch Loss: 0.5685558915138245\n",
            "Epoch: 20, Batch: 24, test Batch Loss: 0.4888843595981598\n",
            "Epoch: 20, Batch: 25, test Batch Loss: 0.3979250192642212\n",
            "Epoch: 20, Batch: 26, test Batch Loss: 0.7259277105331421\n",
            "Epoch: 20, Batch: 27, test Batch Loss: 0.41762709617614746\n",
            "Epoch: 20, Batch: 28, test Batch Loss: 0.5242137312889099\n",
            "Epoch: 20, Batch: 29, test Batch Loss: 0.5091285109519958\n",
            "Epoch: 20, Batch: 30, test Batch Loss: 0.4128587543964386\n",
            "Epoch: 20, Batch: 31, test Batch Loss: 0.6747992634773254\n",
            "Epoch: 20, Batch: 32, test Batch Loss: 0.4428650140762329\n",
            "Epoch: 20, Batch: 33, test Batch Loss: 0.4794011414051056\n",
            "Epoch: 20, Batch: 34, test Batch Loss: 0.815820574760437\n",
            "Epoch: 20, Batch: 35, test Batch Loss: 0.4691481292247772\n",
            "Epoch: 20, Batch: 36, test Batch Loss: 0.6076887845993042\n",
            "Epoch: 20, Batch: 37, test Batch Loss: 0.6006446480751038\n",
            "Epoch: 20, Batch: 38, test Batch Loss: 0.49802592396736145\n",
            "Epoch: 20, Batch: 39, test Batch Loss: 0.5663322806358337\n",
            "Epoch: 20, Batch: 40, test Batch Loss: 0.4601835310459137\n",
            "Epoch: 20, Batch: 41, test Batch Loss: 0.5003397464752197\n",
            "Epoch: 20, Batch: 42, test Batch Loss: 0.44425007700920105\n",
            "Epoch: 20, Batch: 43, test Batch Loss: 0.8184780478477478\n",
            "Epoch: 20, Batch: 44, test Batch Loss: 0.5334523916244507\n",
            "Epoch: 20, Batch: 45, test Batch Loss: 0.4014662802219391\n",
            "Epoch: 20, Batch: 46, test Batch Loss: 0.5554183721542358\n",
            "Epoch: 20, Batch: 47, test Batch Loss: 0.40245959162712097\n",
            "Epoch: 20, Batch: 48, test Batch Loss: 0.4797106981277466\n",
            "Epoch: 20, Batch: 49, test Batch Loss: 0.5551140308380127\n",
            "Epoch: 20, Batch: 50, test Batch Loss: 0.5336002707481384\n",
            "Epoch: 20, Batch: 51, test Batch Loss: 0.5244852304458618\n",
            "Epoch: 20, Batch: 52, test Batch Loss: 0.4875076711177826\n",
            "Epoch: 20, Batch: 53, test Batch Loss: 0.6043999195098877\n",
            "Epoch: 20, Batch: 54, test Batch Loss: 0.49922049045562744\n",
            "Epoch: 20, Batch: 55, test Batch Loss: 0.5255776643753052\n",
            "Epoch: 20, Batch: 56, test Batch Loss: 0.6518102884292603\n",
            "Epoch: 20, Batch: 57, test Batch Loss: 0.54920494556427\n",
            "Epoch: 20, Batch: 58, test Batch Loss: 0.46102938055992126\n",
            "Epoch: 20, Batch: 59, test Batch Loss: 0.46157994866371155\n",
            "Epoch: 20, Batch: 60, test Batch Loss: 0.4996868968009949\n",
            "Epoch: 20, Batch: 61, test Batch Loss: 0.5419978499412537\n",
            "Epoch: 20, Batch: 62, test Batch Loss: 0.5149290561676025\n",
            "Epoch: 20, Batch: 63, test Batch Loss: 0.5039994120597839\n",
            "Epoch: 20, Batch: 64, test Batch Loss: 0.5187868475914001\n",
            "Epoch: 20, Batch: 65, test Batch Loss: 0.40959787368774414\n",
            "Epoch: 20, Batch: 66, test Batch Loss: 0.46612298488616943\n",
            "Epoch: 20, Batch: 67, test Batch Loss: 0.43941858410835266\n",
            "Epoch: 20, Batch: 68, test Batch Loss: 0.5190465450286865\n",
            "Epoch: 20, Batch: 69, test Batch Loss: 0.43123260140419006\n",
            "Epoch: 20, Batch: 70, test Batch Loss: 0.5514265894889832\n",
            "Epoch: 20, Batch: 71, test Batch Loss: 0.42099690437316895\n",
            "Epoch: 20, Batch: 72, test Batch Loss: 0.5944286584854126\n",
            "Epoch: 20, Batch: 73, test Batch Loss: 0.4829779267311096\n",
            "Epoch: 20, Batch: 74, test Batch Loss: 0.43236249685287476\n",
            "Epoch: 20, Batch: 75, test Batch Loss: 0.5858535170555115\n",
            "Epoch: 20, Batch: 76, test Batch Loss: 0.4862726032733917\n",
            "Epoch: 20, Batch: 77, test Batch Loss: 0.5765849947929382\n",
            "Epoch: 20, Batch: 78, test Batch Loss: 0.38326406478881836\n",
            "Epoch: 20, Batch: 79, test Batch Loss: 0.49083149433135986\n",
            "Epoch: 20, Batch: 80, test Batch Loss: 0.6513123512268066\n",
            "Epoch: 20, Batch: 81, test Batch Loss: 0.8611282110214233\n",
            "Epoch: 20, Batch: 82, test Batch Loss: 0.6107842922210693\n",
            "Epoch: 20, Batch: 83, test Batch Loss: 0.4352092742919922\n",
            "Epoch: 20, Batch: 84, test Batch Loss: 0.5318440794944763\n",
            "Epoch: 20, Batch: 85, test Batch Loss: 0.6229438185691833\n",
            "Epoch: 20, Batch: 86, test Batch Loss: 0.5429976582527161\n",
            "Epoch: 20, Batch: 87, test Batch Loss: 0.41619637608528137\n",
            "Epoch: 20, Batch: 88, test Batch Loss: 0.5564370155334473\n",
            "Epoch: 20, Batch: 89, test Batch Loss: 0.5422832369804382\n",
            "Epoch: 20, Batch: 90, test Batch Loss: 0.48063647747039795\n",
            "Epoch: 20, Batch: 91, test Batch Loss: 0.40141019225120544\n",
            "Epoch: 20, Batch: 92, test Batch Loss: 0.7010740637779236\n",
            "Epoch: 20, Batch: 93, test Batch Loss: 0.4297514855861664\n",
            "Epoch: 20, Batch: 94, test Batch Loss: 0.5328249931335449\n",
            "Epoch: 20, Batch: 95, test Batch Loss: 0.4846060276031494\n",
            "Epoch: 20, Batch: 96, test Batch Loss: 0.28941699862480164\n",
            "Epoch: 20, Batch: 97, test Batch Loss: 0.31535542011260986\n",
            "Epoch: 20, Batch: 98, test Batch Loss: 0.4261278212070465\n",
            "Epoch: 20, Batch: 99, test Batch Loss: 0.3818042278289795\n",
            "Epoch: 20, Batch: 100, test Batch Loss: 0.5175294280052185\n",
            "Epoch: 20, Batch: 101, test Batch Loss: 0.4864862561225891\n",
            "Epoch: 20, Batch: 102, test Batch Loss: 0.2795664370059967\n",
            "Epoch: 20, Batch: 103, test Batch Loss: 0.2551558017730713\n",
            "Epoch: 20, Batch: 104, test Batch Loss: 0.35161036252975464\n",
            "Epoch: 20, Batch: 105, test Batch Loss: 0.39417022466659546\n",
            "Epoch: 20, Batch: 106, test Batch Loss: 0.5236653685569763\n",
            "Epoch: 20, Batch: 107, test Batch Loss: 0.4808148741722107\n",
            "Epoch: 20, Batch: 108, test Batch Loss: 0.3916998505592346\n",
            "Epoch: 20, Batch: 109, test Batch Loss: 0.4583776891231537\n",
            "Epoch: 20, Batch: 110, test Batch Loss: 0.6075915694236755\n",
            "Epoch: 20, Batch: 111, test Batch Loss: 0.7730287313461304\n",
            "Epoch: 20, Batch: 112, test Batch Loss: 0.4050922989845276\n",
            "Epoch: 20, Batch: 113, test Batch Loss: 0.4795593023300171\n",
            "Epoch: 20, Batch: 114, test Batch Loss: 0.4331756830215454\n",
            "Epoch: 20, Batch: 115, test Batch Loss: 0.37593042850494385\n",
            "Epoch: 20, Batch: 116, test Batch Loss: 0.6328509449958801\n",
            "Epoch: 20, Batch: 117, test Batch Loss: 0.6091979742050171\n",
            "Epoch: 20, Batch: 118, test Batch Loss: 0.5016949772834778\n",
            "Epoch: 20, Batch: 119, test Batch Loss: 0.600484311580658\n",
            "Epoch: 20, Batch: 120, test Batch Loss: 0.4858400225639343\n",
            "Epoch: 20, Batch: 121, test Batch Loss: 0.7149292230606079\n",
            "Epoch: 20, Batch: 122, test Batch Loss: 0.4287583529949188\n",
            "Epoch: 20, Batch: 123, test Batch Loss: 0.4605155289173126\n",
            "Epoch: 20, Batch: 124, test Batch Loss: 0.42227160930633545\n",
            "Epoch: 20, Batch: 125, test Batch Loss: 0.295585036277771\n",
            "Epoch: 20, Batch: 126, test Batch Loss: 0.46214616298675537\n",
            "Epoch: 20, Batch: 127, test Batch Loss: 0.5002442598342896\n",
            "Epoch: 20, Batch: 128, test Batch Loss: 0.4403552711009979\n",
            "Epoch: 20, Batch: 129, test Batch Loss: 0.41931742429733276\n",
            "Epoch: 20, Batch: 130, test Batch Loss: 0.3923857808113098\n",
            "Epoch: 20, Batch: 131, test Batch Loss: 0.3818519711494446\n",
            "Epoch: 20, Batch: 132, test Batch Loss: 0.41667264699935913\n",
            "Epoch: 20, Batch: 133, test Batch Loss: 0.5640254616737366\n",
            "Epoch: 20, Batch: 134, test Batch Loss: 0.5528721213340759\n",
            "Epoch: 20, Batch: 135, test Batch Loss: 0.5890344381332397\n",
            "Epoch: 20, Batch: 136, test Batch Loss: 0.6732250452041626\n",
            "Epoch: 20, Batch: 137, test Batch Loss: 0.44704800844192505\n",
            "Epoch: 20, Batch: 138, test Batch Loss: 0.7174769043922424\n",
            "Epoch: 20, Batch: 139, test Batch Loss: 0.532932460308075\n",
            "Epoch: 20, Batch: 140, test Batch Loss: 0.4600525200366974\n",
            "Epoch: 20, Batch: 141, test Batch Loss: 0.46739304065704346\n",
            "Epoch: 20, Batch: 142, test Batch Loss: 0.3893633484840393\n",
            "Epoch: 20, Batch: 143, test Batch Loss: 0.5449519753456116\n",
            "Epoch: 20, Batch: 144, test Batch Loss: 0.5220509767532349\n",
            "Epoch: 20, Batch: 145, test Batch Loss: 0.5147278904914856\n",
            "Epoch: 20, Batch: 146, test Batch Loss: 0.5363131761550903\n",
            "Epoch: 20, Batch: 147, test Batch Loss: 0.42609602212905884\n",
            "Epoch: 20, Batch: 148, test Batch Loss: 0.4599630832672119\n",
            "Epoch: 20, Batch: 149, test Batch Loss: 0.5803331136703491\n",
            "Epoch: 20, Batch: 150, test Batch Loss: 0.5544740557670593\n",
            "Epoch: 20, Batch: 151, test Batch Loss: 0.3798390328884125\n",
            "Epoch: 20, Batch: 152, test Batch Loss: 0.5983559489250183\n",
            "Epoch: 20, Batch: 153, test Batch Loss: 0.23399002850055695\n",
            "Epoch: 20, Batch: 154, test Batch Loss: 0.545276403427124\n",
            "Epoch: 20, Batch: 155, test Batch Loss: 0.762376070022583\n",
            "Epoch: 20, Batch: 156, test Batch Loss: 0.5409649610519409\n",
            "Accuracy of test set: 0.8136\n",
            "Epoch 21/25 - Train Loss: 0.4108, Train Acc: 0.8563, Test Loss: 0.5050, Test Acc: 0.8136\n",
            "Epoch: 21, Batch: 0, Batch Loss: 0.6090244650840759\n",
            "Epoch: 21, Batch: 1, Batch Loss: 0.552083432674408\n",
            "Epoch: 21, Batch: 2, Batch Loss: 0.348854660987854\n",
            "Epoch: 21, Batch: 3, Batch Loss: 0.29330679774284363\n",
            "Epoch: 21, Batch: 4, Batch Loss: 0.2081109583377838\n",
            "Epoch: 21, Batch: 5, Batch Loss: 0.23081515729427338\n",
            "Epoch: 21, Batch: 6, Batch Loss: 0.3169836699962616\n",
            "Epoch: 21, Batch: 7, Batch Loss: 0.40321528911590576\n",
            "Epoch: 21, Batch: 8, Batch Loss: 0.41775014996528625\n",
            "Epoch: 21, Batch: 9, Batch Loss: 0.41360756754875183\n",
            "Epoch: 21, Batch: 10, Batch Loss: 0.3770221471786499\n",
            "Epoch: 21, Batch: 11, Batch Loss: 0.3684445023536682\n",
            "Epoch: 21, Batch: 12, Batch Loss: 0.303763747215271\n",
            "Epoch: 21, Batch: 13, Batch Loss: 0.6281413435935974\n",
            "Epoch: 21, Batch: 14, Batch Loss: 0.36472365260124207\n",
            "Epoch: 21, Batch: 15, Batch Loss: 0.5698956251144409\n",
            "Epoch: 21, Batch: 16, Batch Loss: 0.32625699043273926\n",
            "Epoch: 21, Batch: 17, Batch Loss: 0.6463937163352966\n",
            "Epoch: 21, Batch: 18, Batch Loss: 0.26773524284362793\n",
            "Epoch: 21, Batch: 19, Batch Loss: 0.34069743752479553\n",
            "Epoch: 21, Batch: 20, Batch Loss: 0.38424718379974365\n",
            "Epoch: 21, Batch: 21, Batch Loss: 0.358732670545578\n",
            "Epoch: 21, Batch: 22, Batch Loss: 0.27157658338546753\n",
            "Epoch: 21, Batch: 23, Batch Loss: 0.33501848578453064\n",
            "Epoch: 21, Batch: 24, Batch Loss: 0.4221329092979431\n",
            "Epoch: 21, Batch: 25, Batch Loss: 0.2553302049636841\n",
            "Epoch: 21, Batch: 26, Batch Loss: 0.39591655135154724\n",
            "Epoch: 21, Batch: 27, Batch Loss: 0.37003013491630554\n",
            "Epoch: 21, Batch: 28, Batch Loss: 0.36251842975616455\n",
            "Epoch: 21, Batch: 29, Batch Loss: 0.4269214868545532\n",
            "Epoch: 21, Batch: 30, Batch Loss: 0.5215684175491333\n",
            "Epoch: 21, Batch: 31, Batch Loss: 0.41737303137779236\n",
            "Epoch: 21, Batch: 32, Batch Loss: 0.46679747104644775\n",
            "Epoch: 21, Batch: 33, Batch Loss: 0.3909401595592499\n",
            "Epoch: 21, Batch: 34, Batch Loss: 0.3684568405151367\n",
            "Epoch: 21, Batch: 35, Batch Loss: 0.2994265556335449\n",
            "Epoch: 21, Batch: 36, Batch Loss: 0.31410425901412964\n",
            "Epoch: 21, Batch: 37, Batch Loss: 0.4185428321361542\n",
            "Epoch: 21, Batch: 38, Batch Loss: 0.26497554779052734\n",
            "Epoch: 21, Batch: 39, Batch Loss: 0.3680551052093506\n",
            "Epoch: 21, Batch: 40, Batch Loss: 0.29052117466926575\n",
            "Epoch: 21, Batch: 41, Batch Loss: 0.325091153383255\n",
            "Epoch: 21, Batch: 42, Batch Loss: 0.34385010600090027\n",
            "Epoch: 21, Batch: 43, Batch Loss: 0.3394995927810669\n",
            "Epoch: 21, Batch: 44, Batch Loss: 0.38035327196121216\n",
            "Epoch: 21, Batch: 45, Batch Loss: 0.37854716181755066\n",
            "Epoch: 21, Batch: 46, Batch Loss: 0.2605358064174652\n",
            "Epoch: 21, Batch: 47, Batch Loss: 0.2855081856250763\n",
            "Epoch: 21, Batch: 48, Batch Loss: 0.41912975907325745\n",
            "Epoch: 21, Batch: 49, Batch Loss: 0.2799374759197235\n",
            "Epoch: 21, Batch: 50, Batch Loss: 0.34156665205955505\n",
            "Epoch: 21, Batch: 51, Batch Loss: 0.5166040658950806\n",
            "Epoch: 21, Batch: 52, Batch Loss: 0.7342715859413147\n",
            "Epoch: 21, Batch: 53, Batch Loss: 0.5401506423950195\n",
            "Epoch: 21, Batch: 54, Batch Loss: 0.38686510920524597\n",
            "Epoch: 21, Batch: 55, Batch Loss: 0.47223198413848877\n",
            "Epoch: 21, Batch: 56, Batch Loss: 0.38754791021347046\n",
            "Epoch: 21, Batch: 57, Batch Loss: 0.2945808172225952\n",
            "Epoch: 21, Batch: 58, Batch Loss: 0.31470629572868347\n",
            "Epoch: 21, Batch: 59, Batch Loss: 0.36022669076919556\n",
            "Epoch: 21, Batch: 60, Batch Loss: 0.34601646661758423\n",
            "Epoch: 21, Batch: 61, Batch Loss: 0.6420612335205078\n",
            "Epoch: 21, Batch: 62, Batch Loss: 0.4561631977558136\n",
            "Epoch: 21, Batch: 63, Batch Loss: 0.45041313767433167\n",
            "Epoch: 21, Batch: 64, Batch Loss: 0.2908211648464203\n",
            "Epoch: 21, Batch: 65, Batch Loss: 0.36529776453971863\n",
            "Epoch: 21, Batch: 66, Batch Loss: 0.407064825296402\n",
            "Epoch: 21, Batch: 67, Batch Loss: 0.32723939418792725\n",
            "Epoch: 21, Batch: 68, Batch Loss: 0.5602446794509888\n",
            "Epoch: 21, Batch: 69, Batch Loss: 0.4280395209789276\n",
            "Epoch: 21, Batch: 70, Batch Loss: 0.3632770776748657\n",
            "Epoch: 21, Batch: 71, Batch Loss: 0.5316803455352783\n",
            "Epoch: 21, Batch: 72, Batch Loss: 0.44433915615081787\n",
            "Epoch: 21, Batch: 73, Batch Loss: 0.4462568461894989\n",
            "Epoch: 21, Batch: 74, Batch Loss: 0.4003467261791229\n",
            "Epoch: 21, Batch: 75, Batch Loss: 0.33955222368240356\n",
            "Epoch: 21, Batch: 76, Batch Loss: 0.40143024921417236\n",
            "Epoch: 21, Batch: 77, Batch Loss: 0.44405508041381836\n",
            "Epoch: 21, Batch: 78, Batch Loss: 0.3125587999820709\n",
            "Epoch: 21, Batch: 79, Batch Loss: 0.34343600273132324\n",
            "Epoch: 21, Batch: 80, Batch Loss: 0.2812650501728058\n",
            "Epoch: 21, Batch: 81, Batch Loss: 0.32381054759025574\n",
            "Epoch: 21, Batch: 82, Batch Loss: 0.5342209339141846\n",
            "Epoch: 21, Batch: 83, Batch Loss: 0.5111048221588135\n",
            "Epoch: 21, Batch: 84, Batch Loss: 0.33147409558296204\n",
            "Epoch: 21, Batch: 85, Batch Loss: 0.3127115070819855\n",
            "Epoch: 21, Batch: 86, Batch Loss: 0.3650265634059906\n",
            "Epoch: 21, Batch: 87, Batch Loss: 0.3850663900375366\n",
            "Epoch: 21, Batch: 88, Batch Loss: 0.6354093551635742\n",
            "Epoch: 21, Batch: 89, Batch Loss: 0.4722241461277008\n",
            "Epoch: 21, Batch: 90, Batch Loss: 0.3835417926311493\n",
            "Epoch: 21, Batch: 91, Batch Loss: 0.28518015146255493\n",
            "Epoch: 21, Batch: 92, Batch Loss: 0.6084303855895996\n",
            "Epoch: 21, Batch: 93, Batch Loss: 0.38616958260536194\n",
            "Epoch: 21, Batch: 94, Batch Loss: 0.34098389744758606\n",
            "Epoch: 21, Batch: 95, Batch Loss: 0.5170010328292847\n",
            "Epoch: 21, Batch: 96, Batch Loss: 0.4518653452396393\n",
            "Epoch: 21, Batch: 97, Batch Loss: 0.5193713307380676\n",
            "Epoch: 21, Batch: 98, Batch Loss: 0.4648871123790741\n",
            "Epoch: 21, Batch: 99, Batch Loss: 0.47271281480789185\n",
            "Epoch: 21, Batch: 100, Batch Loss: 0.35477355122566223\n",
            "Epoch: 21, Batch: 101, Batch Loss: 0.464004248380661\n",
            "Epoch: 21, Batch: 102, Batch Loss: 0.46189460158348083\n",
            "Epoch: 21, Batch: 103, Batch Loss: 0.21180158853530884\n",
            "Epoch: 21, Batch: 104, Batch Loss: 0.37436744570732117\n",
            "Epoch: 21, Batch: 105, Batch Loss: 0.323287695646286\n",
            "Epoch: 21, Batch: 106, Batch Loss: 0.3971320390701294\n",
            "Epoch: 21, Batch: 107, Batch Loss: 0.47317200899124146\n",
            "Epoch: 21, Batch: 108, Batch Loss: 0.43827101588249207\n",
            "Epoch: 21, Batch: 109, Batch Loss: 0.3521887958049774\n",
            "Epoch: 21, Batch: 110, Batch Loss: 0.295449435710907\n",
            "Epoch: 21, Batch: 111, Batch Loss: 0.3050634562969208\n",
            "Epoch: 21, Batch: 112, Batch Loss: 0.2946683168411255\n",
            "Epoch: 21, Batch: 113, Batch Loss: 0.48537778854370117\n",
            "Epoch: 21, Batch: 114, Batch Loss: 0.2528133988380432\n",
            "Epoch: 21, Batch: 115, Batch Loss: 0.5601670742034912\n",
            "Epoch: 21, Batch: 116, Batch Loss: 0.5468536615371704\n",
            "Epoch: 21, Batch: 117, Batch Loss: 0.26248544454574585\n",
            "Epoch: 21, Batch: 118, Batch Loss: 0.3911588490009308\n",
            "Epoch: 21, Batch: 119, Batch Loss: 0.35337403416633606\n",
            "Epoch: 21, Batch: 120, Batch Loss: 0.3880740702152252\n",
            "Epoch: 21, Batch: 121, Batch Loss: 0.5469950437545776\n",
            "Epoch: 21, Batch: 122, Batch Loss: 0.5205061435699463\n",
            "Epoch: 21, Batch: 123, Batch Loss: 0.4993751347064972\n",
            "Epoch: 21, Batch: 124, Batch Loss: 0.3586418330669403\n",
            "Epoch: 21, Batch: 125, Batch Loss: 0.4628952145576477\n",
            "Epoch: 21, Batch: 126, Batch Loss: 0.4711449146270752\n",
            "Epoch: 21, Batch: 127, Batch Loss: 0.6090855598449707\n",
            "Epoch: 21, Batch: 128, Batch Loss: 0.4417293667793274\n",
            "Epoch: 21, Batch: 129, Batch Loss: 0.3545268774032593\n",
            "Epoch: 21, Batch: 130, Batch Loss: 0.46043825149536133\n",
            "Epoch: 21, Batch: 131, Batch Loss: 0.36955174803733826\n",
            "Epoch: 21, Batch: 132, Batch Loss: 0.46960246562957764\n",
            "Epoch: 21, Batch: 133, Batch Loss: 0.37043049931526184\n",
            "Epoch: 21, Batch: 134, Batch Loss: 0.5994152426719666\n",
            "Epoch: 21, Batch: 135, Batch Loss: 0.40602949261665344\n",
            "Epoch: 21, Batch: 136, Batch Loss: 0.42203786969184875\n",
            "Epoch: 21, Batch: 137, Batch Loss: 0.37826046347618103\n",
            "Epoch: 21, Batch: 138, Batch Loss: 0.48950809240341187\n",
            "Epoch: 21, Batch: 139, Batch Loss: 0.5707293152809143\n",
            "Epoch: 21, Batch: 140, Batch Loss: 0.5172523260116577\n",
            "Epoch: 21, Batch: 141, Batch Loss: 0.4791072607040405\n",
            "Epoch: 21, Batch: 142, Batch Loss: 0.23934537172317505\n",
            "Epoch: 21, Batch: 143, Batch Loss: 0.26886841654777527\n",
            "Epoch: 21, Batch: 144, Batch Loss: 0.2849753201007843\n",
            "Epoch: 21, Batch: 145, Batch Loss: 0.5968701839447021\n",
            "Epoch: 21, Batch: 146, Batch Loss: 0.29365259408950806\n",
            "Epoch: 21, Batch: 147, Batch Loss: 0.43032771348953247\n",
            "Epoch: 21, Batch: 148, Batch Loss: 0.30864718556404114\n",
            "Epoch: 21, Batch: 149, Batch Loss: 0.28310126066207886\n",
            "Epoch: 21, Batch: 150, Batch Loss: 0.5711512565612793\n",
            "Epoch: 21, Batch: 151, Batch Loss: 0.22610054910182953\n",
            "Epoch: 21, Batch: 152, Batch Loss: 0.3564753234386444\n",
            "Epoch: 21, Batch: 153, Batch Loss: 0.45178937911987305\n",
            "Epoch: 21, Batch: 154, Batch Loss: 0.2851564586162567\n",
            "Epoch: 21, Batch: 155, Batch Loss: 0.3367989659309387\n",
            "Epoch: 21, Batch: 156, Batch Loss: 0.5494077205657959\n",
            "Epoch: 21, Batch: 157, Batch Loss: 0.3771946132183075\n",
            "Epoch: 21, Batch: 158, Batch Loss: 0.38793855905532837\n",
            "Epoch: 21, Batch: 159, Batch Loss: 0.3639291822910309\n",
            "Epoch: 21, Batch: 160, Batch Loss: 0.45045003294944763\n",
            "Epoch: 21, Batch: 161, Batch Loss: 0.4220805764198303\n",
            "Epoch: 21, Batch: 162, Batch Loss: 0.42655783891677856\n",
            "Epoch: 21, Batch: 163, Batch Loss: 0.22457003593444824\n",
            "Epoch: 21, Batch: 164, Batch Loss: 0.45710068941116333\n",
            "Epoch: 21, Batch: 165, Batch Loss: 0.24739223718643188\n",
            "Epoch: 21, Batch: 166, Batch Loss: 0.32528460025787354\n",
            "Epoch: 21, Batch: 167, Batch Loss: 0.3431759476661682\n",
            "Epoch: 21, Batch: 168, Batch Loss: 0.4674220383167267\n",
            "Epoch: 21, Batch: 169, Batch Loss: 0.4103107154369354\n",
            "Epoch: 21, Batch: 170, Batch Loss: 0.4950602948665619\n",
            "Epoch: 21, Batch: 171, Batch Loss: 0.5512884855270386\n",
            "Epoch: 21, Batch: 172, Batch Loss: 0.39582210779190063\n",
            "Epoch: 21, Batch: 173, Batch Loss: 0.33425354957580566\n",
            "Epoch: 21, Batch: 174, Batch Loss: 0.2869957685470581\n",
            "Epoch: 21, Batch: 175, Batch Loss: 0.4733550548553467\n",
            "Epoch: 21, Batch: 176, Batch Loss: 0.31634828448295593\n",
            "Epoch: 21, Batch: 177, Batch Loss: 0.42598941922187805\n",
            "Epoch: 21, Batch: 178, Batch Loss: 0.3227679133415222\n",
            "Epoch: 21, Batch: 179, Batch Loss: 0.4353634715080261\n",
            "Epoch: 21, Batch: 180, Batch Loss: 0.3664814829826355\n",
            "Epoch: 21, Batch: 181, Batch Loss: 0.3559282124042511\n",
            "Epoch: 21, Batch: 182, Batch Loss: 0.4234568476676941\n",
            "Epoch: 21, Batch: 183, Batch Loss: 0.32677575945854187\n",
            "Epoch: 21, Batch: 184, Batch Loss: 0.5784778594970703\n",
            "Epoch: 21, Batch: 185, Batch Loss: 0.2753962278366089\n",
            "Epoch: 21, Batch: 186, Batch Loss: 0.5886286497116089\n",
            "Epoch: 21, Batch: 187, Batch Loss: 0.4600977301597595\n",
            "Epoch: 21, Batch: 188, Batch Loss: 0.38893261551856995\n",
            "Epoch: 21, Batch: 189, Batch Loss: 0.36475351452827454\n",
            "Epoch: 21, Batch: 190, Batch Loss: 0.3850169777870178\n",
            "Epoch: 21, Batch: 191, Batch Loss: 0.4038679003715515\n",
            "Epoch: 21, Batch: 192, Batch Loss: 0.2606879770755768\n",
            "Epoch: 21, Batch: 193, Batch Loss: 0.3826678991317749\n",
            "Epoch: 21, Batch: 194, Batch Loss: 0.37785160541534424\n",
            "Epoch: 21, Batch: 195, Batch Loss: 0.5430586934089661\n",
            "Epoch: 21, Batch: 196, Batch Loss: 0.35137584805488586\n",
            "Epoch: 21, Batch: 197, Batch Loss: 0.4511547088623047\n",
            "Epoch: 21, Batch: 198, Batch Loss: 0.36143460869789124\n",
            "Epoch: 21, Batch: 199, Batch Loss: 0.27880537509918213\n",
            "Epoch: 21, Batch: 200, Batch Loss: 0.3692028224468231\n",
            "Epoch: 21, Batch: 201, Batch Loss: 0.248083233833313\n",
            "Epoch: 21, Batch: 202, Batch Loss: 0.2522216737270355\n",
            "Epoch: 21, Batch: 203, Batch Loss: 0.42927971482276917\n",
            "Epoch: 21, Batch: 204, Batch Loss: 0.39743977785110474\n",
            "Epoch: 21, Batch: 205, Batch Loss: 0.39419883489608765\n",
            "Epoch: 21, Batch: 206, Batch Loss: 0.33941611647605896\n",
            "Epoch: 21, Batch: 207, Batch Loss: 0.4369262158870697\n",
            "Epoch: 21, Batch: 208, Batch Loss: 0.4183066189289093\n",
            "Epoch: 21, Batch: 209, Batch Loss: 0.34677278995513916\n",
            "Epoch: 21, Batch: 210, Batch Loss: 0.5839717984199524\n",
            "Epoch: 21, Batch: 211, Batch Loss: 0.30781376361846924\n",
            "Epoch: 21, Batch: 212, Batch Loss: 0.4095539152622223\n",
            "Epoch: 21, Batch: 213, Batch Loss: 0.5015175342559814\n",
            "Epoch: 21, Batch: 214, Batch Loss: 0.3720259964466095\n",
            "Epoch: 21, Batch: 215, Batch Loss: 0.6284149885177612\n",
            "Epoch: 21, Batch: 216, Batch Loss: 0.4459626078605652\n",
            "Epoch: 21, Batch: 217, Batch Loss: 0.40412092208862305\n",
            "Epoch: 21, Batch: 218, Batch Loss: 0.4054240584373474\n",
            "Epoch: 21, Batch: 219, Batch Loss: 0.3051985800266266\n",
            "Epoch: 21, Batch: 220, Batch Loss: 0.5819178223609924\n",
            "Epoch: 21, Batch: 221, Batch Loss: 0.36911553144454956\n",
            "Epoch: 21, Batch: 222, Batch Loss: 0.3710862398147583\n",
            "Epoch: 21, Batch: 223, Batch Loss: 0.4231735169887543\n",
            "Epoch: 21, Batch: 224, Batch Loss: 0.2123258411884308\n",
            "Epoch: 21, Batch: 225, Batch Loss: 0.3383374512195587\n",
            "Epoch: 21, Batch: 226, Batch Loss: 0.4247879087924957\n",
            "Epoch: 21, Batch: 227, Batch Loss: 0.33151790499687195\n",
            "Epoch: 21, Batch: 228, Batch Loss: 0.5263578295707703\n",
            "Epoch: 21, Batch: 229, Batch Loss: 0.2805231809616089\n",
            "Epoch: 21, Batch: 230, Batch Loss: 0.48068767786026\n",
            "Epoch: 21, Batch: 231, Batch Loss: 0.48647838830947876\n",
            "Epoch: 21, Batch: 232, Batch Loss: 0.2856305241584778\n",
            "Epoch: 21, Batch: 233, Batch Loss: 0.40873467922210693\n",
            "Epoch: 21, Batch: 234, Batch Loss: 0.5195890665054321\n",
            "Epoch: 21, Batch: 235, Batch Loss: 0.3707475960254669\n",
            "Epoch: 21, Batch: 236, Batch Loss: 0.6299744844436646\n",
            "Epoch: 21, Batch: 237, Batch Loss: 0.5074949860572815\n",
            "Epoch: 21, Batch: 238, Batch Loss: 0.369245707988739\n",
            "Epoch: 21, Batch: 239, Batch Loss: 0.29210516810417175\n",
            "Epoch: 21, Batch: 240, Batch Loss: 0.5004413723945618\n",
            "Epoch: 21, Batch: 241, Batch Loss: 0.5415303111076355\n",
            "Epoch: 21, Batch: 242, Batch Loss: 0.42729732394218445\n",
            "Epoch: 21, Batch: 243, Batch Loss: 0.46807897090911865\n",
            "Epoch: 21, Batch: 244, Batch Loss: 0.34113818407058716\n",
            "Epoch: 21, Batch: 245, Batch Loss: 0.4201381802558899\n",
            "Epoch: 21, Batch: 246, Batch Loss: 0.4494895040988922\n",
            "Epoch: 21, Batch: 247, Batch Loss: 0.3051684498786926\n",
            "Epoch: 21, Batch: 248, Batch Loss: 0.19330859184265137\n",
            "Epoch: 21, Batch: 249, Batch Loss: 0.35924142599105835\n",
            "Epoch: 21, Batch: 250, Batch Loss: 0.4294990301132202\n",
            "Epoch: 21, Batch: 251, Batch Loss: 0.507874608039856\n",
            "Epoch: 21, Batch: 252, Batch Loss: 0.35492071509361267\n",
            "Epoch: 21, Batch: 253, Batch Loss: 0.5010035037994385\n",
            "Epoch: 21, Batch: 254, Batch Loss: 0.24590584635734558\n",
            "Epoch: 21, Batch: 255, Batch Loss: 0.5522089004516602\n",
            "Epoch: 21, Batch: 256, Batch Loss: 0.3594766855239868\n",
            "Epoch: 21, Batch: 257, Batch Loss: 0.3606959581375122\n",
            "Epoch: 21, Batch: 258, Batch Loss: 0.35144755244255066\n",
            "Epoch: 21, Batch: 259, Batch Loss: 0.4236215651035309\n",
            "Epoch: 21, Batch: 260, Batch Loss: 0.23380911350250244\n",
            "Epoch: 21, Batch: 261, Batch Loss: 0.417908638715744\n",
            "Epoch: 21, Batch: 262, Batch Loss: 0.4603935778141022\n",
            "Epoch: 21, Batch: 263, Batch Loss: 0.3036996126174927\n",
            "Epoch: 21, Batch: 264, Batch Loss: 0.31051307916641235\n",
            "Epoch: 21, Batch: 265, Batch Loss: 0.36673715710639954\n",
            "Epoch: 21, Batch: 266, Batch Loss: 0.31180107593536377\n",
            "Epoch: 21, Batch: 267, Batch Loss: 0.4754664897918701\n",
            "Epoch: 21, Batch: 268, Batch Loss: 0.3142271637916565\n",
            "Epoch: 21, Batch: 269, Batch Loss: 0.3593702018260956\n",
            "Epoch: 21, Batch: 270, Batch Loss: 0.4070361852645874\n",
            "Epoch: 21, Batch: 271, Batch Loss: 0.6280194520950317\n",
            "Epoch: 21, Batch: 272, Batch Loss: 0.4469696283340454\n",
            "Epoch: 21, Batch: 273, Batch Loss: 0.46373826265335083\n",
            "Epoch: 21, Batch: 274, Batch Loss: 0.5017654299736023\n",
            "Epoch: 21, Batch: 275, Batch Loss: 0.34251290559768677\n",
            "Epoch: 21, Batch: 276, Batch Loss: 0.31761232018470764\n",
            "Epoch: 21, Batch: 277, Batch Loss: 0.38025134801864624\n",
            "Epoch: 21, Batch: 278, Batch Loss: 0.3564540147781372\n",
            "Epoch: 21, Batch: 279, Batch Loss: 0.45777690410614014\n",
            "Epoch: 21, Batch: 280, Batch Loss: 0.4457871615886688\n",
            "Epoch: 21, Batch: 281, Batch Loss: 0.22143852710723877\n",
            "Epoch: 21, Batch: 282, Batch Loss: 0.38691550493240356\n",
            "Epoch: 21, Batch: 283, Batch Loss: 0.5982381701469421\n",
            "Epoch: 21, Batch: 284, Batch Loss: 0.6188315153121948\n",
            "Epoch: 21, Batch: 285, Batch Loss: 0.397475928068161\n",
            "Epoch: 21, Batch: 286, Batch Loss: 0.45186880230903625\n",
            "Epoch: 21, Batch: 287, Batch Loss: 0.5048299431800842\n",
            "Epoch: 21, Batch: 288, Batch Loss: 0.3111046850681305\n",
            "Epoch: 21, Batch: 289, Batch Loss: 0.3337920308113098\n",
            "Epoch: 21, Batch: 290, Batch Loss: 0.3791159987449646\n",
            "Epoch: 21, Batch: 291, Batch Loss: 0.3886735141277313\n",
            "Epoch: 21, Batch: 292, Batch Loss: 0.24055641889572144\n",
            "Epoch: 21, Batch: 293, Batch Loss: 0.28889384865760803\n",
            "Epoch: 21, Batch: 294, Batch Loss: 0.2891444265842438\n",
            "Epoch: 21, Batch: 295, Batch Loss: 0.4145701825618744\n",
            "Epoch: 21, Batch: 296, Batch Loss: 0.7027991414070129\n",
            "Epoch: 21, Batch: 297, Batch Loss: 0.27386853098869324\n",
            "Epoch: 21, Batch: 298, Batch Loss: 0.6291325092315674\n",
            "Epoch: 21, Batch: 299, Batch Loss: 0.30615195631980896\n",
            "Epoch: 21, Batch: 300, Batch Loss: 0.6389731764793396\n",
            "Epoch: 21, Batch: 301, Batch Loss: 0.3599403500556946\n",
            "Epoch: 21, Batch: 302, Batch Loss: 0.4179943799972534\n",
            "Epoch: 21, Batch: 303, Batch Loss: 0.3405531346797943\n",
            "Epoch: 21, Batch: 304, Batch Loss: 0.43018558621406555\n",
            "Epoch: 21, Batch: 305, Batch Loss: 0.23132619261741638\n",
            "Epoch: 21, Batch: 306, Batch Loss: 0.39467287063598633\n",
            "Epoch: 21, Batch: 307, Batch Loss: 0.45725172758102417\n",
            "Epoch: 21, Batch: 308, Batch Loss: 0.31109973788261414\n",
            "Epoch: 21, Batch: 309, Batch Loss: 0.257821649312973\n",
            "Epoch: 21, Batch: 310, Batch Loss: 0.365960955619812\n",
            "Epoch: 21, Batch: 311, Batch Loss: 0.4639117419719696\n",
            "Epoch: 21, Batch: 312, Batch Loss: 0.5133149027824402\n",
            "Epoch: 21, Batch: 313, Batch Loss: 0.20143678784370422\n",
            "Epoch: 21, Batch: 314, Batch Loss: 0.48944252729415894\n",
            "Epoch: 21, Batch: 315, Batch Loss: 0.2643706798553467\n",
            "Epoch: 21, Batch: 316, Batch Loss: 0.23000572621822357\n",
            "Epoch: 21, Batch: 317, Batch Loss: 0.37251752614974976\n",
            "Epoch: 21, Batch: 318, Batch Loss: 0.4853203594684601\n",
            "Epoch: 21, Batch: 319, Batch Loss: 0.5715276598930359\n",
            "Epoch: 21, Batch: 320, Batch Loss: 0.29516902565956116\n",
            "Epoch: 21, Batch: 321, Batch Loss: 0.31043630838394165\n",
            "Epoch: 21, Batch: 322, Batch Loss: 0.42092111706733704\n",
            "Epoch: 21, Batch: 323, Batch Loss: 0.312237948179245\n",
            "Epoch: 21, Batch: 324, Batch Loss: 0.37433475255966187\n",
            "Epoch: 21, Batch: 325, Batch Loss: 0.46084609627723694\n",
            "Epoch: 21, Batch: 326, Batch Loss: 0.46511703729629517\n",
            "Epoch: 21, Batch: 327, Batch Loss: 0.4525681734085083\n",
            "Epoch: 21, Batch: 328, Batch Loss: 0.2213013917207718\n",
            "Epoch: 21, Batch: 329, Batch Loss: 0.27360475063323975\n",
            "Epoch: 21, Batch: 330, Batch Loss: 0.5346688628196716\n",
            "Epoch: 21, Batch: 331, Batch Loss: 0.3613995909690857\n",
            "Epoch: 21, Batch: 332, Batch Loss: 0.31440088152885437\n",
            "Epoch: 21, Batch: 333, Batch Loss: 0.4683707654476166\n",
            "Epoch: 21, Batch: 334, Batch Loss: 0.36721348762512207\n",
            "Epoch: 21, Batch: 335, Batch Loss: 0.28821849822998047\n",
            "Epoch: 21, Batch: 336, Batch Loss: 0.3289504945278168\n",
            "Epoch: 21, Batch: 337, Batch Loss: 0.32026514410972595\n",
            "Epoch: 21, Batch: 338, Batch Loss: 0.3230630159378052\n",
            "Epoch: 21, Batch: 339, Batch Loss: 0.3256424367427826\n",
            "Epoch: 21, Batch: 340, Batch Loss: 0.42375341057777405\n",
            "Epoch: 21, Batch: 341, Batch Loss: 0.4156261384487152\n",
            "Epoch: 21, Batch: 342, Batch Loss: 0.48073500394821167\n",
            "Epoch: 21, Batch: 343, Batch Loss: 0.42694780230522156\n",
            "Epoch: 21, Batch: 344, Batch Loss: 0.4003032445907593\n",
            "Epoch: 21, Batch: 345, Batch Loss: 0.35192978382110596\n",
            "Epoch: 21, Batch: 346, Batch Loss: 0.25909343361854553\n",
            "Epoch: 21, Batch: 347, Batch Loss: 0.427894651889801\n",
            "Epoch: 21, Batch: 348, Batch Loss: 0.3284808099269867\n",
            "Epoch: 21, Batch: 349, Batch Loss: 0.5946664810180664\n",
            "Epoch: 21, Batch: 350, Batch Loss: 0.4327120780944824\n",
            "Epoch: 21, Batch: 351, Batch Loss: 0.33744722604751587\n",
            "Epoch: 21, Batch: 352, Batch Loss: 0.5275458693504333\n",
            "Epoch: 21, Batch: 353, Batch Loss: 0.525652289390564\n",
            "Epoch: 21, Batch: 354, Batch Loss: 0.36029309034347534\n",
            "Epoch: 21, Batch: 355, Batch Loss: 0.49449777603149414\n",
            "Epoch: 21, Batch: 356, Batch Loss: 0.37387388944625854\n",
            "Epoch: 21, Batch: 357, Batch Loss: 0.24698814749717712\n",
            "Epoch: 21, Batch: 358, Batch Loss: 0.5340930819511414\n",
            "Epoch: 21, Batch: 359, Batch Loss: 0.3651963472366333\n",
            "Epoch: 21, Batch: 360, Batch Loss: 0.40021365880966187\n",
            "Epoch: 21, Batch: 361, Batch Loss: 0.396542489528656\n",
            "Epoch: 21, Batch: 362, Batch Loss: 0.4210449159145355\n",
            "Epoch: 21, Batch: 363, Batch Loss: 0.27711278200149536\n",
            "Epoch: 21, Batch: 364, Batch Loss: 0.5402212142944336\n",
            "Epoch: 21, Batch: 365, Batch Loss: 0.5077738165855408\n",
            "Epoch: 21, Batch: 366, Batch Loss: 0.23365260660648346\n",
            "Epoch: 21, Batch: 367, Batch Loss: 0.3830660283565521\n",
            "Epoch: 21, Batch: 368, Batch Loss: 0.4536399245262146\n",
            "Epoch: 21, Batch: 369, Batch Loss: 0.34346523880958557\n",
            "Epoch: 21, Batch: 370, Batch Loss: 0.3004333972930908\n",
            "Epoch: 21, Batch: 371, Batch Loss: 0.4394288659095764\n",
            "Epoch: 21, Batch: 372, Batch Loss: 0.44970089197158813\n",
            "Epoch: 21, Batch: 373, Batch Loss: 0.33433395624160767\n",
            "Epoch: 21, Batch: 374, Batch Loss: 0.4675571620464325\n",
            "Epoch: 21, Batch: 375, Batch Loss: 0.5735025405883789\n",
            "Epoch: 21, Batch: 376, Batch Loss: 0.3761827051639557\n",
            "Epoch: 21, Batch: 377, Batch Loss: 0.26717913150787354\n",
            "Epoch: 21, Batch: 378, Batch Loss: 0.5045751333236694\n",
            "Epoch: 21, Batch: 379, Batch Loss: 0.3704923093318939\n",
            "Epoch: 21, Batch: 380, Batch Loss: 0.35720986127853394\n",
            "Epoch: 21, Batch: 381, Batch Loss: 0.39170998334884644\n",
            "Epoch: 21, Batch: 382, Batch Loss: 0.5050153136253357\n",
            "Epoch: 21, Batch: 383, Batch Loss: 0.22276058793067932\n",
            "Epoch: 21, Batch: 384, Batch Loss: 0.24289995431900024\n",
            "Epoch: 21, Batch: 385, Batch Loss: 0.3964899182319641\n",
            "Epoch: 21, Batch: 386, Batch Loss: 0.43783247470855713\n",
            "Epoch: 21, Batch: 387, Batch Loss: 0.34443357586860657\n",
            "Epoch: 21, Batch: 388, Batch Loss: 0.8105472326278687\n",
            "Epoch: 21, Batch: 389, Batch Loss: 0.4104384779930115\n",
            "Epoch: 21, Batch: 390, Batch Loss: 0.4243674874305725\n",
            "Epoch: 21, Batch: 391, Batch Loss: 0.3286243677139282\n",
            "Epoch: 21, Batch: 392, Batch Loss: 0.29463088512420654\n",
            "Epoch: 21, Batch: 393, Batch Loss: 0.4017474353313446\n",
            "Epoch: 21, Batch: 394, Batch Loss: 0.560482382774353\n",
            "Epoch: 21, Batch: 395, Batch Loss: 0.5985642671585083\n",
            "Epoch: 21, Batch: 396, Batch Loss: 0.47344157099723816\n",
            "Epoch: 21, Batch: 397, Batch Loss: 0.40222567319869995\n",
            "Epoch: 21, Batch: 398, Batch Loss: 0.5186207294464111\n",
            "Epoch: 21, Batch: 399, Batch Loss: 0.2939988970756531\n",
            "Epoch: 21, Batch: 400, Batch Loss: 0.5658613443374634\n",
            "Epoch: 21, Batch: 401, Batch Loss: 0.3805324137210846\n",
            "Epoch: 21, Batch: 402, Batch Loss: 0.5366628170013428\n",
            "Epoch: 21, Batch: 403, Batch Loss: 0.41283902525901794\n",
            "Epoch: 21, Batch: 404, Batch Loss: 0.5423372983932495\n",
            "Epoch: 21, Batch: 405, Batch Loss: 0.5376527309417725\n",
            "Epoch: 21, Batch: 406, Batch Loss: 0.410133421421051\n",
            "Epoch: 21, Batch: 407, Batch Loss: 0.2727092504501343\n",
            "Epoch: 21, Batch: 408, Batch Loss: 0.33713164925575256\n",
            "Epoch: 21, Batch: 409, Batch Loss: 0.3592855930328369\n",
            "Epoch: 21, Batch: 410, Batch Loss: 0.3606184720993042\n",
            "Epoch: 21, Batch: 411, Batch Loss: 0.28260353207588196\n",
            "Epoch: 21, Batch: 412, Batch Loss: 0.2927694320678711\n",
            "Epoch: 21, Batch: 413, Batch Loss: 0.618701159954071\n",
            "Epoch: 21, Batch: 414, Batch Loss: 0.44080546498298645\n",
            "Epoch: 21, Batch: 415, Batch Loss: 0.43930208683013916\n",
            "Epoch: 21, Batch: 416, Batch Loss: 0.42163968086242676\n",
            "Epoch: 21, Batch: 417, Batch Loss: 0.4493260383605957\n",
            "Epoch: 21, Batch: 418, Batch Loss: 0.41035017371177673\n",
            "Epoch: 21, Batch: 419, Batch Loss: 0.22288064658641815\n",
            "Epoch: 21, Batch: 420, Batch Loss: 0.34674450755119324\n",
            "Epoch: 21, Batch: 421, Batch Loss: 0.5629496574401855\n",
            "Epoch: 21, Batch: 422, Batch Loss: 0.4904124140739441\n",
            "Epoch: 21, Batch: 423, Batch Loss: 0.34603971242904663\n",
            "Epoch: 21, Batch: 424, Batch Loss: 0.512008011341095\n",
            "Epoch: 21, Batch: 425, Batch Loss: 0.4820537269115448\n",
            "Epoch: 21, Batch: 426, Batch Loss: 0.49879124760627747\n",
            "Epoch: 21, Batch: 427, Batch Loss: 0.2952256500720978\n",
            "Epoch: 21, Batch: 428, Batch Loss: 0.3418293595314026\n",
            "Epoch: 21, Batch: 429, Batch Loss: 0.3835139572620392\n",
            "Epoch: 21, Batch: 430, Batch Loss: 0.3164675235748291\n",
            "Epoch: 21, Batch: 431, Batch Loss: 0.2844172418117523\n",
            "Epoch: 21, Batch: 432, Batch Loss: 0.34264853596687317\n",
            "Epoch: 21, Batch: 433, Batch Loss: 0.34495532512664795\n",
            "Epoch: 21, Batch: 434, Batch Loss: 0.39374056458473206\n",
            "Epoch: 21, Batch: 435, Batch Loss: 0.3474808931350708\n",
            "Epoch: 21, Batch: 436, Batch Loss: 0.37577199935913086\n",
            "Epoch: 21, Batch: 437, Batch Loss: 0.3548301160335541\n",
            "Epoch: 21, Batch: 438, Batch Loss: 0.5678637027740479\n",
            "Epoch: 21, Batch: 439, Batch Loss: 0.2554011940956116\n",
            "Epoch: 21, Batch: 440, Batch Loss: 0.3844406306743622\n",
            "Epoch: 21, Batch: 441, Batch Loss: 0.4221128523349762\n",
            "Epoch: 21, Batch: 442, Batch Loss: 0.3332361578941345\n",
            "Epoch: 21, Batch: 443, Batch Loss: 0.3698543608188629\n",
            "Epoch: 21, Batch: 444, Batch Loss: 0.2747510075569153\n",
            "Epoch: 21, Batch: 445, Batch Loss: 0.26333725452423096\n",
            "Epoch: 21, Batch: 446, Batch Loss: 0.279558926820755\n",
            "Epoch: 21, Batch: 447, Batch Loss: 0.38178345561027527\n",
            "Epoch: 21, Batch: 448, Batch Loss: 0.191232830286026\n",
            "Epoch: 21, Batch: 449, Batch Loss: 0.4771975576877594\n",
            "Epoch: 21, Batch: 450, Batch Loss: 0.6729724407196045\n",
            "Epoch: 21, Batch: 451, Batch Loss: 0.3649762272834778\n",
            "Epoch: 21, Batch: 452, Batch Loss: 0.6035096049308777\n",
            "Epoch: 21, Batch: 453, Batch Loss: 0.47074198722839355\n",
            "Epoch: 21, Batch: 454, Batch Loss: 0.20524291694164276\n",
            "Epoch: 21, Batch: 455, Batch Loss: 0.4358808696269989\n",
            "Epoch: 21, Batch: 456, Batch Loss: 0.37736809253692627\n",
            "Epoch: 21, Batch: 457, Batch Loss: 0.5167320966720581\n",
            "Epoch: 21, Batch: 458, Batch Loss: 0.3752257227897644\n",
            "Epoch: 21, Batch: 459, Batch Loss: 0.2656291127204895\n",
            "Epoch: 21, Batch: 460, Batch Loss: 0.26066192984580994\n",
            "Epoch: 21, Batch: 461, Batch Loss: 0.4301559329032898\n",
            "Epoch: 21, Batch: 462, Batch Loss: 0.2989490330219269\n",
            "Epoch: 21, Batch: 463, Batch Loss: 0.29233789443969727\n",
            "Epoch: 21, Batch: 464, Batch Loss: 0.5604792237281799\n",
            "Epoch: 21, Batch: 465, Batch Loss: 0.49572086334228516\n",
            "Epoch: 21, Batch: 466, Batch Loss: 0.7543942332267761\n",
            "Epoch: 21, Batch: 467, Batch Loss: 0.2702219784259796\n",
            "Epoch: 21, Batch: 468, Batch Loss: 0.2798927426338196\n",
            "Epoch: 21, Batch: 469, Batch Loss: 0.2991577386856079\n",
            "Epoch: 21, Batch: 470, Batch Loss: 0.4573684334754944\n",
            "Epoch: 21, Batch: 471, Batch Loss: 0.3753725290298462\n",
            "Epoch: 21, Batch: 472, Batch Loss: 0.5227903127670288\n",
            "Epoch: 21, Batch: 473, Batch Loss: 0.4350188970565796\n",
            "Epoch: 21, Batch: 474, Batch Loss: 0.44740813970565796\n",
            "Epoch: 21, Batch: 475, Batch Loss: 0.4665452837944031\n",
            "Epoch: 21, Batch: 476, Batch Loss: 0.4761980473995209\n",
            "Epoch: 21, Batch: 477, Batch Loss: 0.3766341805458069\n",
            "Epoch: 21, Batch: 478, Batch Loss: 0.25709161162376404\n",
            "Epoch: 21, Batch: 479, Batch Loss: 0.6020789742469788\n",
            "Epoch: 21, Batch: 480, Batch Loss: 0.305202841758728\n",
            "Epoch: 21, Batch: 481, Batch Loss: 0.6598157286643982\n",
            "Epoch: 21, Batch: 482, Batch Loss: 0.2940572202205658\n",
            "Epoch: 21, Batch: 483, Batch Loss: 0.5094039440155029\n",
            "Epoch: 21, Batch: 484, Batch Loss: 0.22107790410518646\n",
            "Epoch: 21, Batch: 485, Batch Loss: 0.4409567415714264\n",
            "Epoch: 21, Batch: 486, Batch Loss: 0.3034011125564575\n",
            "Epoch: 21, Batch: 487, Batch Loss: 0.64451003074646\n",
            "Epoch: 21, Batch: 488, Batch Loss: 0.5527435541152954\n",
            "Epoch: 21, Batch: 489, Batch Loss: 0.3983747959136963\n",
            "Epoch: 21, Batch: 490, Batch Loss: 0.4604153037071228\n",
            "Epoch: 21, Batch: 491, Batch Loss: 0.454035222530365\n",
            "Epoch: 21, Batch: 492, Batch Loss: 0.5542069673538208\n",
            "Epoch: 21, Batch: 493, Batch Loss: 0.29944533109664917\n",
            "Epoch: 21, Batch: 494, Batch Loss: 0.47942230105400085\n",
            "Epoch: 21, Batch: 495, Batch Loss: 0.36431339383125305\n",
            "Epoch: 21, Batch: 496, Batch Loss: 0.28243008255958557\n",
            "Epoch: 21, Batch: 497, Batch Loss: 0.30420413613319397\n",
            "Epoch: 21, Batch: 498, Batch Loss: 0.4510003626346588\n",
            "Epoch: 21, Batch: 499, Batch Loss: 0.48150739073753357\n",
            "Epoch: 21, Batch: 500, Batch Loss: 0.3979015052318573\n",
            "Epoch: 21, Batch: 501, Batch Loss: 0.22642488777637482\n",
            "Epoch: 21, Batch: 502, Batch Loss: 0.3759785294532776\n",
            "Epoch: 21, Batch: 503, Batch Loss: 0.5249731540679932\n",
            "Epoch: 21, Batch: 504, Batch Loss: 0.41331103444099426\n",
            "Epoch: 21, Batch: 505, Batch Loss: 0.3110535144805908\n",
            "Epoch: 21, Batch: 506, Batch Loss: 0.5428289175033569\n",
            "Epoch: 21, Batch: 507, Batch Loss: 0.29520556330680847\n",
            "Epoch: 21, Batch: 508, Batch Loss: 0.43576741218566895\n",
            "Epoch: 21, Batch: 509, Batch Loss: 0.5107547640800476\n",
            "Epoch: 21, Batch: 510, Batch Loss: 0.37090861797332764\n",
            "Epoch: 21, Batch: 511, Batch Loss: 0.3366636335849762\n",
            "Epoch: 21, Batch: 512, Batch Loss: 0.4383677542209625\n",
            "Epoch: 21, Batch: 513, Batch Loss: 0.34887397289276123\n",
            "Epoch: 21, Batch: 514, Batch Loss: 0.32140642404556274\n",
            "Epoch: 21, Batch: 515, Batch Loss: 0.37175723910331726\n",
            "Epoch: 21, Batch: 516, Batch Loss: 0.4098568260669708\n",
            "Epoch: 21, Batch: 517, Batch Loss: 0.24760085344314575\n",
            "Epoch: 21, Batch: 518, Batch Loss: 0.4273052513599396\n",
            "Epoch: 21, Batch: 519, Batch Loss: 0.5390974283218384\n",
            "Epoch: 21, Batch: 520, Batch Loss: 0.4567320644855499\n",
            "Epoch: 21, Batch: 521, Batch Loss: 0.3756617605686188\n",
            "Epoch: 21, Batch: 522, Batch Loss: 0.447689950466156\n",
            "Epoch: 21, Batch: 523, Batch Loss: 0.5162540674209595\n",
            "Epoch: 21, Batch: 524, Batch Loss: 0.47181159257888794\n",
            "Epoch: 21, Batch: 525, Batch Loss: 0.3455694615840912\n",
            "Epoch: 21, Batch: 526, Batch Loss: 0.4140819311141968\n",
            "Epoch: 21, Batch: 527, Batch Loss: 0.3487609326839447\n",
            "Epoch: 21, Batch: 528, Batch Loss: 0.6741375923156738\n",
            "Epoch: 21, Batch: 529, Batch Loss: 0.3607265055179596\n",
            "Epoch: 21, Batch: 530, Batch Loss: 0.4665389657020569\n",
            "Epoch: 21, Batch: 531, Batch Loss: 0.29124680161476135\n",
            "Epoch: 21, Batch: 532, Batch Loss: 0.34631967544555664\n",
            "Epoch: 21, Batch: 533, Batch Loss: 0.20453104376792908\n",
            "Epoch: 21, Batch: 534, Batch Loss: 0.42377781867980957\n",
            "Epoch: 21, Batch: 535, Batch Loss: 0.4617137610912323\n",
            "Epoch: 21, Batch: 536, Batch Loss: 0.38694268465042114\n",
            "Epoch: 21, Batch: 537, Batch Loss: 0.30370745062828064\n",
            "Epoch: 21, Batch: 538, Batch Loss: 0.3878656029701233\n",
            "Epoch: 21, Batch: 539, Batch Loss: 0.3538275957107544\n",
            "Epoch: 21, Batch: 540, Batch Loss: 0.3435840904712677\n",
            "Epoch: 21, Batch: 541, Batch Loss: 0.3304592967033386\n",
            "Epoch: 21, Batch: 542, Batch Loss: 0.3518516421318054\n",
            "Epoch: 21, Batch: 543, Batch Loss: 0.4497033655643463\n",
            "Epoch: 21, Batch: 544, Batch Loss: 0.38423943519592285\n",
            "Epoch: 21, Batch: 545, Batch Loss: 0.47368085384368896\n",
            "Epoch: 21, Batch: 546, Batch Loss: 0.31791970133781433\n",
            "Epoch: 21, Batch: 547, Batch Loss: 0.37207046151161194\n",
            "Epoch: 21, Batch: 548, Batch Loss: 0.46242696046829224\n",
            "Epoch: 21, Batch: 549, Batch Loss: 0.2679976224899292\n",
            "Epoch: 21, Batch: 550, Batch Loss: 0.2673957943916321\n",
            "Epoch: 21, Batch: 551, Batch Loss: 0.6502900719642639\n",
            "Epoch: 21, Batch: 552, Batch Loss: 0.4145798683166504\n",
            "Epoch: 21, Batch: 553, Batch Loss: 0.5422289967536926\n",
            "Epoch: 21, Batch: 554, Batch Loss: 0.3532937467098236\n",
            "Epoch: 21, Batch: 555, Batch Loss: 0.6905321478843689\n",
            "Epoch: 21, Batch: 556, Batch Loss: 0.4104450047016144\n",
            "Epoch: 21, Batch: 557, Batch Loss: 0.5047765970230103\n",
            "Epoch: 21, Batch: 558, Batch Loss: 0.348544716835022\n",
            "Epoch: 21, Batch: 559, Batch Loss: 0.2643792927265167\n",
            "Epoch: 21, Batch: 560, Batch Loss: 0.424317866563797\n",
            "Epoch: 21, Batch: 561, Batch Loss: 0.49608200788497925\n",
            "Epoch: 21, Batch: 562, Batch Loss: 0.38319844007492065\n",
            "Epoch: 21, Batch: 563, Batch Loss: 0.49688321352005005\n",
            "Epoch: 21, Batch: 564, Batch Loss: 0.3719492256641388\n",
            "Epoch: 21, Batch: 565, Batch Loss: 0.5225430130958557\n",
            "Epoch: 21, Batch: 566, Batch Loss: 0.31194284558296204\n",
            "Epoch: 21, Batch: 567, Batch Loss: 0.3910599946975708\n",
            "Epoch: 21, Batch: 568, Batch Loss: 0.5463948249816895\n",
            "Epoch: 21, Batch: 569, Batch Loss: 0.2905481159687042\n",
            "Epoch: 21, Batch: 570, Batch Loss: 0.4644407331943512\n",
            "Epoch: 21, Batch: 571, Batch Loss: 0.4491642117500305\n",
            "Epoch: 21, Batch: 572, Batch Loss: 0.3859404921531677\n",
            "Epoch: 21, Batch: 573, Batch Loss: 0.3410772979259491\n",
            "Epoch: 21, Batch: 574, Batch Loss: 0.31166237592697144\n",
            "Epoch: 21, Batch: 575, Batch Loss: 0.2607960104942322\n",
            "Epoch: 21, Batch: 576, Batch Loss: 0.34391260147094727\n",
            "Epoch: 21, Batch: 577, Batch Loss: 0.3788151741027832\n",
            "Epoch: 21, Batch: 578, Batch Loss: 0.4864692986011505\n",
            "Epoch: 21, Batch: 579, Batch Loss: 0.32384172081947327\n",
            "Epoch: 21, Batch: 580, Batch Loss: 0.3359284996986389\n",
            "Epoch: 21, Batch: 581, Batch Loss: 0.36254945397377014\n",
            "Epoch: 21, Batch: 582, Batch Loss: 0.3415810465812683\n",
            "Epoch: 21, Batch: 583, Batch Loss: 0.45062607526779175\n",
            "Epoch: 21, Batch: 584, Batch Loss: 0.5132637619972229\n",
            "Epoch: 21, Batch: 585, Batch Loss: 0.24830502271652222\n",
            "Epoch: 21, Batch: 586, Batch Loss: 0.28365659713745117\n",
            "Epoch: 21, Batch: 587, Batch Loss: 0.7191064357757568\n",
            "Epoch: 21, Batch: 588, Batch Loss: 0.2172357738018036\n",
            "Epoch: 21, Batch: 589, Batch Loss: 0.31713443994522095\n",
            "Epoch: 21, Batch: 590, Batch Loss: 0.31131285429000854\n",
            "Epoch: 21, Batch: 591, Batch Loss: 0.28364306688308716\n",
            "Epoch: 21, Batch: 592, Batch Loss: 0.3634103536605835\n",
            "Epoch: 21, Batch: 593, Batch Loss: 0.36673617362976074\n",
            "Epoch: 21, Batch: 594, Batch Loss: 0.39799949526786804\n",
            "Epoch: 21, Batch: 595, Batch Loss: 0.3032856285572052\n",
            "Epoch: 21, Batch: 596, Batch Loss: 0.28497156500816345\n",
            "Epoch: 21, Batch: 597, Batch Loss: 0.5279069542884827\n",
            "Epoch: 21, Batch: 598, Batch Loss: 0.3594450354576111\n",
            "Epoch: 21, Batch: 599, Batch Loss: 0.2502541244029999\n",
            "Epoch: 21, Batch: 600, Batch Loss: 0.43964603543281555\n",
            "Epoch: 21, Batch: 601, Batch Loss: 0.446823388338089\n",
            "Epoch: 21, Batch: 602, Batch Loss: 0.26422378420829773\n",
            "Epoch: 21, Batch: 603, Batch Loss: 0.3172350227832794\n",
            "Epoch: 21, Batch: 604, Batch Loss: 0.29925018548965454\n",
            "Epoch: 21, Batch: 605, Batch Loss: 0.39218655228614807\n",
            "Epoch: 21, Batch: 606, Batch Loss: 0.7039690017700195\n",
            "Epoch: 21, Batch: 607, Batch Loss: 0.5232200622558594\n",
            "Epoch: 21, Batch: 608, Batch Loss: 0.3409464657306671\n",
            "Epoch: 21, Batch: 609, Batch Loss: 0.6416991353034973\n",
            "Epoch: 21, Batch: 610, Batch Loss: 0.579501211643219\n",
            "Epoch: 21, Batch: 611, Batch Loss: 0.3567280173301697\n",
            "Epoch: 21, Batch: 612, Batch Loss: 0.29657071828842163\n",
            "Epoch: 21, Batch: 613, Batch Loss: 0.4454383850097656\n",
            "Epoch: 21, Batch: 614, Batch Loss: 0.3684253990650177\n",
            "Epoch: 21, Batch: 615, Batch Loss: 0.5563015937805176\n",
            "Epoch: 21, Batch: 616, Batch Loss: 0.2743452489376068\n",
            "Epoch: 21, Batch: 617, Batch Loss: 0.4223746657371521\n",
            "Epoch: 21, Batch: 618, Batch Loss: 0.22286903858184814\n",
            "Epoch: 21, Batch: 619, Batch Loss: 0.40904107689857483\n",
            "Epoch: 21, Batch: 620, Batch Loss: 0.3884778916835785\n",
            "Epoch: 21, Batch: 621, Batch Loss: 0.2681810259819031\n",
            "Epoch: 21, Batch: 622, Batch Loss: 0.5189946293830872\n",
            "Epoch: 21, Batch: 623, Batch Loss: 0.575749933719635\n",
            "Epoch: 21, Batch: 624, Batch Loss: 0.3332648277282715\n",
            "Epoch: 21, Batch: 625, Batch Loss: 0.6798321604728699\n",
            "Epoch: 21, Batch: 626, Batch Loss: 0.26403385400772095\n",
            "Epoch: 21, Batch: 627, Batch Loss: 0.5917605757713318\n",
            "Epoch: 21, Batch: 628, Batch Loss: 0.43325403332710266\n",
            "Epoch: 21, Batch: 629, Batch Loss: 0.5470969676971436\n",
            "Epoch: 21, Batch: 630, Batch Loss: 0.27946415543556213\n",
            "Epoch: 21, Batch: 631, Batch Loss: 0.28393054008483887\n",
            "Epoch: 21, Batch: 632, Batch Loss: 0.3940117657184601\n",
            "Epoch: 21, Batch: 633, Batch Loss: 0.41678953170776367\n",
            "Epoch: 21, Batch: 634, Batch Loss: 0.23449768126010895\n",
            "Epoch: 21, Batch: 635, Batch Loss: 0.45539402961730957\n",
            "Epoch: 21, Batch: 636, Batch Loss: 0.37785694003105164\n",
            "Epoch: 21, Batch: 637, Batch Loss: 0.335907906293869\n",
            "Epoch: 21, Batch: 638, Batch Loss: 0.3817426860332489\n",
            "Epoch: 21, Batch: 639, Batch Loss: 0.32295405864715576\n",
            "Epoch: 21, Batch: 640, Batch Loss: 0.4555216133594513\n",
            "Epoch: 21, Batch: 641, Batch Loss: 0.3819715678691864\n",
            "Epoch: 21, Batch: 642, Batch Loss: 0.27322685718536377\n",
            "Epoch: 21, Batch: 643, Batch Loss: 0.4814103841781616\n",
            "Epoch: 21, Batch: 644, Batch Loss: 0.37844058871269226\n",
            "Epoch: 21, Batch: 645, Batch Loss: 0.2610786259174347\n",
            "Epoch: 21, Batch: 646, Batch Loss: 0.5473732352256775\n",
            "Epoch: 21, Batch: 647, Batch Loss: 0.3965577483177185\n",
            "Epoch: 21, Batch: 648, Batch Loss: 0.3306925892829895\n",
            "Epoch: 21, Batch: 649, Batch Loss: 0.37191978096961975\n",
            "Epoch: 21, Batch: 650, Batch Loss: 0.3709665536880493\n",
            "Epoch: 21, Batch: 651, Batch Loss: 0.4825640916824341\n",
            "Epoch: 21, Batch: 652, Batch Loss: 0.3717135190963745\n",
            "Epoch: 21, Batch: 653, Batch Loss: 0.4670114517211914\n",
            "Epoch: 21, Batch: 654, Batch Loss: 0.2854233384132385\n",
            "Epoch: 21, Batch: 655, Batch Loss: 0.42139941453933716\n",
            "Epoch: 21, Batch: 656, Batch Loss: 0.346016526222229\n",
            "Epoch: 21, Batch: 657, Batch Loss: 0.40043699741363525\n",
            "Epoch: 21, Batch: 658, Batch Loss: 0.42559781670570374\n",
            "Epoch: 21, Batch: 659, Batch Loss: 0.31951990723609924\n",
            "Epoch: 21, Batch: 660, Batch Loss: 0.3494175374507904\n",
            "Epoch: 21, Batch: 661, Batch Loss: 0.31563010811805725\n",
            "Epoch: 21, Batch: 662, Batch Loss: 0.44490402936935425\n",
            "Epoch: 21, Batch: 663, Batch Loss: 0.359184592962265\n",
            "Epoch: 21, Batch: 664, Batch Loss: 0.3922612965106964\n",
            "Epoch: 21, Batch: 665, Batch Loss: 0.3756117522716522\n",
            "Epoch: 21, Batch: 666, Batch Loss: 0.3393760025501251\n",
            "Epoch: 21, Batch: 667, Batch Loss: 0.36164847016334534\n",
            "Epoch: 21, Batch: 668, Batch Loss: 0.3875311017036438\n",
            "Epoch: 21, Batch: 669, Batch Loss: 0.27313661575317383\n",
            "Epoch: 21, Batch: 670, Batch Loss: 0.39864206314086914\n",
            "Epoch: 21, Batch: 671, Batch Loss: 0.34191665053367615\n",
            "Epoch: 21, Batch: 672, Batch Loss: 0.35602590441703796\n",
            "Epoch: 21, Batch: 673, Batch Loss: 0.5197745561599731\n",
            "Epoch: 21, Batch: 674, Batch Loss: 0.32739439606666565\n",
            "Epoch: 21, Batch: 675, Batch Loss: 0.5678228735923767\n",
            "Epoch: 21, Batch: 676, Batch Loss: 0.565017580986023\n",
            "Epoch: 21, Batch: 677, Batch Loss: 0.3797963559627533\n",
            "Epoch: 21, Batch: 678, Batch Loss: 0.4589100182056427\n",
            "Epoch: 21, Batch: 679, Batch Loss: 0.3865913450717926\n",
            "Epoch: 21, Batch: 680, Batch Loss: 0.3987603783607483\n",
            "Epoch: 21, Batch: 681, Batch Loss: 0.2973359227180481\n",
            "Epoch: 21, Batch: 682, Batch Loss: 0.4205697178840637\n",
            "Epoch: 21, Batch: 683, Batch Loss: 0.5537985563278198\n",
            "Epoch: 21, Batch: 684, Batch Loss: 0.39219576120376587\n",
            "Epoch: 21, Batch: 685, Batch Loss: 0.3554193675518036\n",
            "Epoch: 21, Batch: 686, Batch Loss: 0.49906042218208313\n",
            "Epoch: 21, Batch: 687, Batch Loss: 0.4857661724090576\n",
            "Epoch: 21, Batch: 688, Batch Loss: 0.24983815848827362\n",
            "Epoch: 21, Batch: 689, Batch Loss: 0.5654539465904236\n",
            "Epoch: 21, Batch: 690, Batch Loss: 0.44494566321372986\n",
            "Epoch: 21, Batch: 691, Batch Loss: 0.3693072497844696\n",
            "Epoch: 21, Batch: 692, Batch Loss: 0.4873626232147217\n",
            "Epoch: 21, Batch: 693, Batch Loss: 0.6754887700080872\n",
            "Epoch: 21, Batch: 694, Batch Loss: 0.2551805078983307\n",
            "Epoch: 21, Batch: 695, Batch Loss: 0.2776152193546295\n",
            "Epoch: 21, Batch: 696, Batch Loss: 0.5589877963066101\n",
            "Epoch: 21, Batch: 697, Batch Loss: 0.4372182786464691\n",
            "Epoch: 21, Batch: 698, Batch Loss: 0.30061075091362\n",
            "Epoch: 21, Batch: 699, Batch Loss: 0.3393982946872711\n",
            "Epoch: 21, Batch: 700, Batch Loss: 0.5195602774620056\n",
            "Epoch: 21, Batch: 701, Batch Loss: 0.4531654119491577\n",
            "Epoch: 21, Batch: 702, Batch Loss: 0.43348124623298645\n",
            "Epoch: 21, Batch: 703, Batch Loss: 0.3787590563297272\n",
            "Epoch: 21, Batch: 704, Batch Loss: 0.5371221303939819\n",
            "Epoch: 21, Batch: 705, Batch Loss: 0.370792031288147\n",
            "Epoch: 21, Batch: 706, Batch Loss: 0.39699873328208923\n",
            "Epoch: 21, Batch: 707, Batch Loss: 0.6884530782699585\n",
            "Epoch: 21, Batch: 708, Batch Loss: 0.43514570593833923\n",
            "Epoch: 21, Batch: 709, Batch Loss: 0.2678517699241638\n",
            "Epoch: 21, Batch: 710, Batch Loss: 0.35538771748542786\n",
            "Epoch: 21, Batch: 711, Batch Loss: 0.35512712597846985\n",
            "Epoch: 21, Batch: 712, Batch Loss: 0.4647575318813324\n",
            "Epoch: 21, Batch: 713, Batch Loss: 0.33438560366630554\n",
            "Epoch: 21, Batch: 714, Batch Loss: 0.3888070285320282\n",
            "Epoch: 21, Batch: 715, Batch Loss: 0.4530657231807709\n",
            "Epoch: 21, Batch: 716, Batch Loss: 0.5467731952667236\n",
            "Epoch: 21, Batch: 717, Batch Loss: 0.32899653911590576\n",
            "Epoch: 21, Batch: 718, Batch Loss: 0.4960150420665741\n",
            "Epoch: 21, Batch: 719, Batch Loss: 0.30271363258361816\n",
            "Epoch: 21, Batch: 720, Batch Loss: 0.43522191047668457\n",
            "Epoch: 21, Batch: 721, Batch Loss: 0.5676396489143372\n",
            "Epoch: 21, Batch: 722, Batch Loss: 0.6721733212471008\n",
            "Epoch: 21, Batch: 723, Batch Loss: 0.42149338126182556\n",
            "Epoch: 21, Batch: 724, Batch Loss: 0.46306538581848145\n",
            "Epoch: 21, Batch: 725, Batch Loss: 0.4247143566608429\n",
            "Epoch: 21, Batch: 726, Batch Loss: 0.37298011779785156\n",
            "Epoch: 21, Batch: 727, Batch Loss: 0.34710755944252014\n",
            "Epoch: 21, Batch: 728, Batch Loss: 0.41971495747566223\n",
            "Epoch: 21, Batch: 729, Batch Loss: 0.43610450625419617\n",
            "Epoch: 21, Batch: 730, Batch Loss: 0.28813493251800537\n",
            "Epoch: 21, Batch: 731, Batch Loss: 0.515838086605072\n",
            "Epoch: 21, Batch: 732, Batch Loss: 0.4056459665298462\n",
            "Epoch: 21, Batch: 733, Batch Loss: 0.2811873257160187\n",
            "Epoch: 21, Batch: 734, Batch Loss: 0.4714907705783844\n",
            "Epoch: 21, Batch: 735, Batch Loss: 0.42139995098114014\n",
            "Epoch: 21, Batch: 736, Batch Loss: 0.23698952794075012\n",
            "Epoch: 21, Batch: 737, Batch Loss: 0.31791046261787415\n",
            "Epoch: 21, Batch: 738, Batch Loss: 0.43233829736709595\n",
            "Epoch: 21, Batch: 739, Batch Loss: 0.38584277033805847\n",
            "Epoch: 21, Batch: 740, Batch Loss: 0.48386460542678833\n",
            "Epoch: 21, Batch: 741, Batch Loss: 0.3844592869281769\n",
            "Epoch: 21, Batch: 742, Batch Loss: 0.41567227244377136\n",
            "Epoch: 21, Batch: 743, Batch Loss: 0.3639715909957886\n",
            "Epoch: 21, Batch: 744, Batch Loss: 0.40334951877593994\n",
            "Epoch: 21, Batch: 745, Batch Loss: 0.36084192991256714\n",
            "Epoch: 21, Batch: 746, Batch Loss: 0.32487767934799194\n",
            "Epoch: 21, Batch: 747, Batch Loss: 0.5543049573898315\n",
            "Epoch: 21, Batch: 748, Batch Loss: 0.4343186020851135\n",
            "Epoch: 21, Batch: 749, Batch Loss: 0.35674476623535156\n",
            "Epoch: 21, Batch: 750, Batch Loss: 0.4618331491947174\n",
            "Epoch: 21, Batch: 751, Batch Loss: 0.5069007873535156\n",
            "Epoch: 21, Batch: 752, Batch Loss: 0.6045060753822327\n",
            "Epoch: 21, Batch: 753, Batch Loss: 0.3454766869544983\n",
            "Epoch: 21, Batch: 754, Batch Loss: 0.45693325996398926\n",
            "Epoch: 21, Batch: 755, Batch Loss: 0.40284258127212524\n",
            "Epoch: 21, Batch: 756, Batch Loss: 0.4609519839286804\n",
            "Epoch: 21, Batch: 757, Batch Loss: 0.4499167799949646\n",
            "Epoch: 21, Batch: 758, Batch Loss: 0.34492969512939453\n",
            "Epoch: 21, Batch: 759, Batch Loss: 0.38532617688179016\n",
            "Epoch: 21, Batch: 760, Batch Loss: 0.28703123331069946\n",
            "Epoch: 21, Batch: 761, Batch Loss: 0.48919346928596497\n",
            "Epoch: 21, Batch: 762, Batch Loss: 0.33075571060180664\n",
            "Epoch: 21, Batch: 763, Batch Loss: 0.44266971945762634\n",
            "Epoch: 21, Batch: 764, Batch Loss: 0.42154964804649353\n",
            "Epoch: 21, Batch: 765, Batch Loss: 0.45301559567451477\n",
            "Epoch: 21, Batch: 766, Batch Loss: 0.5317620635032654\n",
            "Epoch: 21, Batch: 767, Batch Loss: 0.18896397948265076\n",
            "Epoch: 21, Batch: 768, Batch Loss: 0.40952038764953613\n",
            "Epoch: 21, Batch: 769, Batch Loss: 0.26733845472335815\n",
            "Epoch: 21, Batch: 770, Batch Loss: 0.3838874399662018\n",
            "Epoch: 21, Batch: 771, Batch Loss: 0.3301185965538025\n",
            "Epoch: 21, Batch: 772, Batch Loss: 0.3557561933994293\n",
            "Epoch: 21, Batch: 773, Batch Loss: 0.3851015567779541\n",
            "Epoch: 21, Batch: 774, Batch Loss: 0.3272117078304291\n",
            "Epoch: 21, Batch: 775, Batch Loss: 0.27901792526245117\n",
            "Epoch: 21, Batch: 776, Batch Loss: 0.6201288104057312\n",
            "Epoch: 21, Batch: 777, Batch Loss: 0.3707321286201477\n",
            "Epoch: 21, Batch: 778, Batch Loss: 0.2995642125606537\n",
            "Epoch: 21, Batch: 779, Batch Loss: 0.23511624336242676\n",
            "Epoch: 21, Batch: 780, Batch Loss: 0.4461805820465088\n",
            "Epoch: 21, Batch: 781, Batch Loss: 0.5916430950164795\n",
            "Epoch: 21, Batch: 782, Batch Loss: 0.3711923658847809\n",
            "Epoch: 21, Batch: 783, Batch Loss: 0.47697335481643677\n",
            "Epoch: 21, Batch: 784, Batch Loss: 0.30324453115463257\n",
            "Epoch: 21, Batch: 785, Batch Loss: 0.43056395649909973\n",
            "Epoch: 21, Batch: 786, Batch Loss: 0.28435763716697693\n",
            "Epoch: 21, Batch: 787, Batch Loss: 0.2953985929489136\n",
            "Epoch: 21, Batch: 788, Batch Loss: 0.31806233525276184\n",
            "Epoch: 21, Batch: 789, Batch Loss: 0.31349387764930725\n",
            "Epoch: 21, Batch: 790, Batch Loss: 0.4492313265800476\n",
            "Epoch: 21, Batch: 791, Batch Loss: 0.2705579400062561\n",
            "Epoch: 21, Batch: 792, Batch Loss: 0.3825945258140564\n",
            "Epoch: 21, Batch: 793, Batch Loss: 0.28368937969207764\n",
            "Epoch: 21, Batch: 794, Batch Loss: 0.2967885732650757\n",
            "Epoch: 21, Batch: 795, Batch Loss: 0.2024531066417694\n",
            "Epoch: 21, Batch: 796, Batch Loss: 0.4535754919052124\n",
            "Epoch: 21, Batch: 797, Batch Loss: 0.25485286116600037\n",
            "Epoch: 21, Batch: 798, Batch Loss: 0.36433425545692444\n",
            "Epoch: 21, Batch: 799, Batch Loss: 0.34459757804870605\n",
            "Epoch: 21, Batch: 800, Batch Loss: 0.40660926699638367\n",
            "Epoch: 21, Batch: 801, Batch Loss: 0.47868090867996216\n",
            "Epoch: 21, Batch: 802, Batch Loss: 0.46653902530670166\n",
            "Epoch: 21, Batch: 803, Batch Loss: 0.3404546082019806\n",
            "Epoch: 21, Batch: 804, Batch Loss: 0.41821467876434326\n",
            "Epoch: 21, Batch: 805, Batch Loss: 0.5994198322296143\n",
            "Epoch: 21, Batch: 806, Batch Loss: 0.4398490786552429\n",
            "Epoch: 21, Batch: 807, Batch Loss: 0.40448951721191406\n",
            "Epoch: 21, Batch: 808, Batch Loss: 0.344072550535202\n",
            "Epoch: 21, Batch: 809, Batch Loss: 0.3569200038909912\n",
            "Epoch: 21, Batch: 810, Batch Loss: 0.3808319866657257\n",
            "Epoch: 21, Batch: 811, Batch Loss: 0.34829843044281006\n",
            "Epoch: 21, Batch: 812, Batch Loss: 0.3956449627876282\n",
            "Epoch: 21, Batch: 813, Batch Loss: 0.3580361008644104\n",
            "Epoch: 21, Batch: 814, Batch Loss: 0.48582229018211365\n",
            "Epoch: 21, Batch: 815, Batch Loss: 0.42922165989875793\n",
            "Epoch: 21, Batch: 816, Batch Loss: 0.40000709891319275\n",
            "Epoch: 21, Batch: 817, Batch Loss: 0.606002688407898\n",
            "Epoch: 21, Batch: 818, Batch Loss: 0.32057979702949524\n",
            "Epoch: 21, Batch: 819, Batch Loss: 0.5260248780250549\n",
            "Epoch: 21, Batch: 820, Batch Loss: 0.2855408787727356\n",
            "Epoch: 21, Batch: 821, Batch Loss: 0.3218936324119568\n",
            "Epoch: 21, Batch: 822, Batch Loss: 0.3113606870174408\n",
            "Epoch: 21, Batch: 823, Batch Loss: 0.41149619221687317\n",
            "Epoch: 21, Batch: 824, Batch Loss: 0.4450502395629883\n",
            "Epoch: 21, Batch: 825, Batch Loss: 0.3576286733150482\n",
            "Epoch: 21, Batch: 826, Batch Loss: 0.4082767963409424\n",
            "Epoch: 21, Batch: 827, Batch Loss: 0.4201597571372986\n",
            "Epoch: 21, Batch: 828, Batch Loss: 0.43408870697021484\n",
            "Epoch: 21, Batch: 829, Batch Loss: 0.3513263761997223\n",
            "Epoch: 21, Batch: 830, Batch Loss: 0.4334985613822937\n",
            "Epoch: 21, Batch: 831, Batch Loss: 0.434566468000412\n",
            "Epoch: 21, Batch: 832, Batch Loss: 0.3597935438156128\n",
            "Epoch: 21, Batch: 833, Batch Loss: 0.29594287276268005\n",
            "Epoch: 21, Batch: 834, Batch Loss: 0.3950183689594269\n",
            "Epoch: 21, Batch: 835, Batch Loss: 0.2573000192642212\n",
            "Epoch: 21, Batch: 836, Batch Loss: 0.4567897319793701\n",
            "Epoch: 21, Batch: 837, Batch Loss: 0.5338766574859619\n",
            "Epoch: 21, Batch: 838, Batch Loss: 0.27684977650642395\n",
            "Epoch: 21, Batch: 839, Batch Loss: 0.42531681060791016\n",
            "Epoch: 21, Batch: 840, Batch Loss: 0.35665908455848694\n",
            "Epoch: 21, Batch: 841, Batch Loss: 0.31424155831336975\n",
            "Epoch: 21, Batch: 842, Batch Loss: 0.28122246265411377\n",
            "Epoch: 21, Batch: 843, Batch Loss: 0.3058837652206421\n",
            "Epoch: 21, Batch: 844, Batch Loss: 0.5632131099700928\n",
            "Epoch: 21, Batch: 845, Batch Loss: 0.3759612739086151\n",
            "Epoch: 21, Batch: 846, Batch Loss: 0.4431987404823303\n",
            "Epoch: 21, Batch: 847, Batch Loss: 0.48028191924095154\n",
            "Epoch: 21, Batch: 848, Batch Loss: 0.3816259801387787\n",
            "Epoch: 21, Batch: 849, Batch Loss: 0.3416719436645508\n",
            "Epoch: 21, Batch: 850, Batch Loss: 0.29668670892715454\n",
            "Epoch: 21, Batch: 851, Batch Loss: 0.506950318813324\n",
            "Epoch: 21, Batch: 852, Batch Loss: 0.5181335806846619\n",
            "Epoch: 21, Batch: 853, Batch Loss: 0.4087865948677063\n",
            "Epoch: 21, Batch: 854, Batch Loss: 0.3573600649833679\n",
            "Epoch: 21, Batch: 855, Batch Loss: 0.37200862169265747\n",
            "Epoch: 21, Batch: 856, Batch Loss: 0.44524526596069336\n",
            "Epoch: 21, Batch: 857, Batch Loss: 0.41320762038230896\n",
            "Epoch: 21, Batch: 858, Batch Loss: 0.37773123383522034\n",
            "Epoch: 21, Batch: 859, Batch Loss: 0.33853843808174133\n",
            "Epoch: 21, Batch: 860, Batch Loss: 0.3515947163105011\n",
            "Epoch: 21, Batch: 861, Batch Loss: 0.3616276979446411\n",
            "Epoch: 21, Batch: 862, Batch Loss: 0.4082736074924469\n",
            "Epoch: 21, Batch: 863, Batch Loss: 0.31180912256240845\n",
            "Epoch: 21, Batch: 864, Batch Loss: 0.7515053749084473\n",
            "Epoch: 21, Batch: 865, Batch Loss: 0.4515487849712372\n",
            "Epoch: 21, Batch: 866, Batch Loss: 0.25395068526268005\n",
            "Epoch: 21, Batch: 867, Batch Loss: 0.2575828433036804\n",
            "Epoch: 21, Batch: 868, Batch Loss: 0.28795427083969116\n",
            "Epoch: 21, Batch: 869, Batch Loss: 0.38681265711784363\n",
            "Epoch: 21, Batch: 870, Batch Loss: 0.3689357340335846\n",
            "Epoch: 21, Batch: 871, Batch Loss: 0.5499748587608337\n",
            "Epoch: 21, Batch: 872, Batch Loss: 0.3268078863620758\n",
            "Epoch: 21, Batch: 873, Batch Loss: 0.25740760564804077\n",
            "Epoch: 21, Batch: 874, Batch Loss: 0.4284380078315735\n",
            "Epoch: 21, Batch: 875, Batch Loss: 0.4231858551502228\n",
            "Epoch: 21, Batch: 876, Batch Loss: 0.3581177294254303\n",
            "Epoch: 21, Batch: 877, Batch Loss: 0.42470431327819824\n",
            "Epoch: 21, Batch: 878, Batch Loss: 0.3943758010864258\n",
            "Epoch: 21, Batch: 879, Batch Loss: 0.5093111991882324\n",
            "Epoch: 21, Batch: 880, Batch Loss: 0.345473051071167\n",
            "Epoch: 21, Batch: 881, Batch Loss: 0.3763398230075836\n",
            "Epoch: 21, Batch: 882, Batch Loss: 0.46628597378730774\n",
            "Epoch: 21, Batch: 883, Batch Loss: 0.6818348169326782\n",
            "Epoch: 21, Batch: 884, Batch Loss: 0.5770562887191772\n",
            "Epoch: 21, Batch: 885, Batch Loss: 0.5581982731819153\n",
            "Epoch: 21, Batch: 886, Batch Loss: 0.43007898330688477\n",
            "Epoch: 21, Batch: 887, Batch Loss: 0.4156261682510376\n",
            "Epoch: 21, Batch: 888, Batch Loss: 0.4060825705528259\n",
            "Epoch: 21, Batch: 889, Batch Loss: 0.3851606547832489\n",
            "Epoch: 21, Batch: 890, Batch Loss: 0.3750433325767517\n",
            "Epoch: 21, Batch: 891, Batch Loss: 0.4562022089958191\n",
            "Epoch: 21, Batch: 892, Batch Loss: 0.34264227747917175\n",
            "Epoch: 21, Batch: 893, Batch Loss: 0.3397342264652252\n",
            "Epoch: 21, Batch: 894, Batch Loss: 0.3642803728580475\n",
            "Epoch: 21, Batch: 895, Batch Loss: 0.36894312500953674\n",
            "Epoch: 21, Batch: 896, Batch Loss: 0.4190956652164459\n",
            "Epoch: 21, Batch: 897, Batch Loss: 0.4516178369522095\n",
            "Epoch: 21, Batch: 898, Batch Loss: 0.47550392150878906\n",
            "Epoch: 21, Batch: 899, Batch Loss: 0.4094400107860565\n",
            "Epoch: 21, Batch: 900, Batch Loss: 0.29983243346214294\n",
            "Epoch: 21, Batch: 901, Batch Loss: 0.24025438725948334\n",
            "Epoch: 21, Batch: 902, Batch Loss: 0.38011428713798523\n",
            "Epoch: 21, Batch: 903, Batch Loss: 0.525469958782196\n",
            "Epoch: 21, Batch: 904, Batch Loss: 0.5796541571617126\n",
            "Epoch: 21, Batch: 905, Batch Loss: 0.4308553636074066\n",
            "Epoch: 21, Batch: 906, Batch Loss: 0.6565461754798889\n",
            "Epoch: 21, Batch: 907, Batch Loss: 0.3486487567424774\n",
            "Epoch: 21, Batch: 908, Batch Loss: 0.3621743321418762\n",
            "Epoch: 21, Batch: 909, Batch Loss: 0.41633978486061096\n",
            "Epoch: 21, Batch: 910, Batch Loss: 0.3958123028278351\n",
            "Epoch: 21, Batch: 911, Batch Loss: 0.41194358468055725\n",
            "Epoch: 21, Batch: 912, Batch Loss: 0.4429543912410736\n",
            "Epoch: 21, Batch: 913, Batch Loss: 0.29067590832710266\n",
            "Epoch: 21, Batch: 914, Batch Loss: 0.4490903615951538\n",
            "Epoch: 21, Batch: 915, Batch Loss: 0.3586256802082062\n",
            "Epoch: 21, Batch: 916, Batch Loss: 0.3811684548854828\n",
            "Epoch: 21, Batch: 917, Batch Loss: 0.42975690960884094\n",
            "Epoch: 21, Batch: 918, Batch Loss: 0.35946768522262573\n",
            "Epoch: 21, Batch: 919, Batch Loss: 0.42450231313705444\n",
            "Epoch: 21, Batch: 920, Batch Loss: 0.46640390157699585\n",
            "Epoch: 21, Batch: 921, Batch Loss: 0.3642750382423401\n",
            "Epoch: 21, Batch: 922, Batch Loss: 0.45580947399139404\n",
            "Epoch: 21, Batch: 923, Batch Loss: 0.6655759811401367\n",
            "Epoch: 21, Batch: 924, Batch Loss: 0.2459140419960022\n",
            "Epoch: 21, Batch: 925, Batch Loss: 0.4090738594532013\n",
            "Epoch: 21, Batch: 926, Batch Loss: 0.6145231127738953\n",
            "Epoch: 21, Batch: 927, Batch Loss: 0.4637409448623657\n",
            "Epoch: 21, Batch: 928, Batch Loss: 0.5092846751213074\n",
            "Epoch: 21, Batch: 929, Batch Loss: 0.438266783952713\n",
            "Epoch: 21, Batch: 930, Batch Loss: 0.493875116109848\n",
            "Epoch: 21, Batch: 931, Batch Loss: 0.5005937814712524\n",
            "Epoch: 21, Batch: 932, Batch Loss: 0.30649757385253906\n",
            "Epoch: 21, Batch: 933, Batch Loss: 0.4558658301830292\n",
            "Epoch: 21, Batch: 934, Batch Loss: 0.13517281413078308\n",
            "Epoch: 21, Batch: 935, Batch Loss: 0.41853952407836914\n",
            "Epoch: 21, Batch: 936, Batch Loss: 0.4031982421875\n",
            "Epoch: 21, Batch: 937, Batch Loss: 0.5621433854103088\n",
            "Accuracy of train set: 0.8585666666666667\n",
            "Epoch: 21, Batch: 0, test Batch Loss: 0.5492563247680664\n",
            "Epoch: 21, Batch: 1, test Batch Loss: 0.45547062158584595\n",
            "Epoch: 21, Batch: 2, test Batch Loss: 0.7617677450180054\n",
            "Epoch: 21, Batch: 3, test Batch Loss: 0.6255820989608765\n",
            "Epoch: 21, Batch: 4, test Batch Loss: 0.5750564336776733\n",
            "Epoch: 21, Batch: 5, test Batch Loss: 0.4758625328540802\n",
            "Epoch: 21, Batch: 6, test Batch Loss: 0.6600391864776611\n",
            "Epoch: 21, Batch: 7, test Batch Loss: 0.36466875672340393\n",
            "Epoch: 21, Batch: 8, test Batch Loss: 0.691857099533081\n",
            "Epoch: 21, Batch: 9, test Batch Loss: 0.6125319004058838\n",
            "Epoch: 21, Batch: 10, test Batch Loss: 0.5546075701713562\n",
            "Epoch: 21, Batch: 11, test Batch Loss: 0.4403631091117859\n",
            "Epoch: 21, Batch: 12, test Batch Loss: 0.6837353110313416\n",
            "Epoch: 21, Batch: 13, test Batch Loss: 0.4638931453227997\n",
            "Epoch: 21, Batch: 14, test Batch Loss: 0.8919296264648438\n",
            "Epoch: 21, Batch: 15, test Batch Loss: 0.27911576628685\n",
            "Epoch: 21, Batch: 16, test Batch Loss: 0.5900611877441406\n",
            "Epoch: 21, Batch: 17, test Batch Loss: 0.7245733737945557\n",
            "Epoch: 21, Batch: 18, test Batch Loss: 0.5907881855964661\n",
            "Epoch: 21, Batch: 19, test Batch Loss: 0.3837263286113739\n",
            "Epoch: 21, Batch: 20, test Batch Loss: 0.6047114133834839\n",
            "Epoch: 21, Batch: 21, test Batch Loss: 0.3822302520275116\n",
            "Epoch: 21, Batch: 22, test Batch Loss: 0.776051938533783\n",
            "Epoch: 21, Batch: 23, test Batch Loss: 0.3762928545475006\n",
            "Epoch: 21, Batch: 24, test Batch Loss: 0.3916722238063812\n",
            "Epoch: 21, Batch: 25, test Batch Loss: 0.6216673851013184\n",
            "Epoch: 21, Batch: 26, test Batch Loss: 0.40275096893310547\n",
            "Epoch: 21, Batch: 27, test Batch Loss: 0.48987436294555664\n",
            "Epoch: 21, Batch: 28, test Batch Loss: 0.5142581462860107\n",
            "Epoch: 21, Batch: 29, test Batch Loss: 0.6777034997940063\n",
            "Epoch: 21, Batch: 30, test Batch Loss: 0.3551117479801178\n",
            "Epoch: 21, Batch: 31, test Batch Loss: 0.7475852370262146\n",
            "Epoch: 21, Batch: 32, test Batch Loss: 0.34349894523620605\n",
            "Epoch: 21, Batch: 33, test Batch Loss: 0.5322847366333008\n",
            "Epoch: 21, Batch: 34, test Batch Loss: 0.490226149559021\n",
            "Epoch: 21, Batch: 35, test Batch Loss: 0.5928829908370972\n",
            "Epoch: 21, Batch: 36, test Batch Loss: 0.5838068723678589\n",
            "Epoch: 21, Batch: 37, test Batch Loss: 0.3684709072113037\n",
            "Epoch: 21, Batch: 38, test Batch Loss: 0.5703585147857666\n",
            "Epoch: 21, Batch: 39, test Batch Loss: 0.6038851737976074\n",
            "Epoch: 21, Batch: 40, test Batch Loss: 0.3795892000198364\n",
            "Epoch: 21, Batch: 41, test Batch Loss: 0.40204834938049316\n",
            "Epoch: 21, Batch: 42, test Batch Loss: 0.44734635949134827\n",
            "Epoch: 21, Batch: 43, test Batch Loss: 0.6930997371673584\n",
            "Epoch: 21, Batch: 44, test Batch Loss: 0.48972010612487793\n",
            "Epoch: 21, Batch: 45, test Batch Loss: 0.48107606172561646\n",
            "Epoch: 21, Batch: 46, test Batch Loss: 0.3292444348335266\n",
            "Epoch: 21, Batch: 47, test Batch Loss: 0.7663888335227966\n",
            "Epoch: 21, Batch: 48, test Batch Loss: 0.5257489085197449\n",
            "Epoch: 21, Batch: 49, test Batch Loss: 0.8261624574661255\n",
            "Epoch: 21, Batch: 50, test Batch Loss: 0.3705925941467285\n",
            "Epoch: 21, Batch: 51, test Batch Loss: 0.5370966792106628\n",
            "Epoch: 21, Batch: 52, test Batch Loss: 0.4984261691570282\n",
            "Epoch: 21, Batch: 53, test Batch Loss: 0.820777416229248\n",
            "Epoch: 21, Batch: 54, test Batch Loss: 0.5590109825134277\n",
            "Epoch: 21, Batch: 55, test Batch Loss: 0.285712867975235\n",
            "Epoch: 21, Batch: 56, test Batch Loss: 0.3933223485946655\n",
            "Epoch: 21, Batch: 57, test Batch Loss: 0.7446574568748474\n",
            "Epoch: 21, Batch: 58, test Batch Loss: 0.30404162406921387\n",
            "Epoch: 21, Batch: 59, test Batch Loss: 0.42532074451446533\n",
            "Epoch: 21, Batch: 60, test Batch Loss: 0.4123288691043854\n",
            "Epoch: 21, Batch: 61, test Batch Loss: 0.5141586065292358\n",
            "Epoch: 21, Batch: 62, test Batch Loss: 0.9070444107055664\n",
            "Epoch: 21, Batch: 63, test Batch Loss: 0.5571119785308838\n",
            "Epoch: 21, Batch: 64, test Batch Loss: 0.4970785975456238\n",
            "Epoch: 21, Batch: 65, test Batch Loss: 0.4415198564529419\n",
            "Epoch: 21, Batch: 66, test Batch Loss: 0.6799749732017517\n",
            "Epoch: 21, Batch: 67, test Batch Loss: 0.4466365873813629\n",
            "Epoch: 21, Batch: 68, test Batch Loss: 0.8121933341026306\n",
            "Epoch: 21, Batch: 69, test Batch Loss: 0.6014745235443115\n",
            "Epoch: 21, Batch: 70, test Batch Loss: 0.5238664746284485\n",
            "Epoch: 21, Batch: 71, test Batch Loss: 0.5646510720252991\n",
            "Epoch: 21, Batch: 72, test Batch Loss: 0.5419089794158936\n",
            "Epoch: 21, Batch: 73, test Batch Loss: 0.38198649883270264\n",
            "Epoch: 21, Batch: 74, test Batch Loss: 0.6505479216575623\n",
            "Epoch: 21, Batch: 75, test Batch Loss: 0.39738768339157104\n",
            "Epoch: 21, Batch: 76, test Batch Loss: 0.4574523866176605\n",
            "Epoch: 21, Batch: 77, test Batch Loss: 0.32337459921836853\n",
            "Epoch: 21, Batch: 78, test Batch Loss: 0.357119619846344\n",
            "Epoch: 21, Batch: 79, test Batch Loss: 0.5959122180938721\n",
            "Epoch: 21, Batch: 80, test Batch Loss: 0.4531102180480957\n",
            "Epoch: 21, Batch: 81, test Batch Loss: 0.6280481815338135\n",
            "Epoch: 21, Batch: 82, test Batch Loss: 0.6293879747390747\n",
            "Epoch: 21, Batch: 83, test Batch Loss: 0.45376357436180115\n",
            "Epoch: 21, Batch: 84, test Batch Loss: 0.6438361406326294\n",
            "Epoch: 21, Batch: 85, test Batch Loss: 0.5160479545593262\n",
            "Epoch: 21, Batch: 86, test Batch Loss: 0.7037895917892456\n",
            "Epoch: 21, Batch: 87, test Batch Loss: 0.7176916599273682\n",
            "Epoch: 21, Batch: 88, test Batch Loss: 0.4881144165992737\n",
            "Epoch: 21, Batch: 89, test Batch Loss: 0.7303348183631897\n",
            "Epoch: 21, Batch: 90, test Batch Loss: 0.5278766751289368\n",
            "Epoch: 21, Batch: 91, test Batch Loss: 0.6746828556060791\n",
            "Epoch: 21, Batch: 92, test Batch Loss: 0.3344188630580902\n",
            "Epoch: 21, Batch: 93, test Batch Loss: 0.48172247409820557\n",
            "Epoch: 21, Batch: 94, test Batch Loss: 0.5201332569122314\n",
            "Epoch: 21, Batch: 95, test Batch Loss: 0.36785462498664856\n",
            "Epoch: 21, Batch: 96, test Batch Loss: 0.48344290256500244\n",
            "Epoch: 21, Batch: 97, test Batch Loss: 0.4395686686038971\n",
            "Epoch: 21, Batch: 98, test Batch Loss: 0.496573805809021\n",
            "Epoch: 21, Batch: 99, test Batch Loss: 0.4277333617210388\n",
            "Epoch: 21, Batch: 100, test Batch Loss: 0.5751639604568481\n",
            "Epoch: 21, Batch: 101, test Batch Loss: 0.4264278709888458\n",
            "Epoch: 21, Batch: 102, test Batch Loss: 0.4396434724330902\n",
            "Epoch: 21, Batch: 103, test Batch Loss: 0.5247579216957092\n",
            "Epoch: 21, Batch: 104, test Batch Loss: 0.49989408254623413\n",
            "Epoch: 21, Batch: 105, test Batch Loss: 0.3813292384147644\n",
            "Epoch: 21, Batch: 106, test Batch Loss: 0.47733479738235474\n",
            "Epoch: 21, Batch: 107, test Batch Loss: 0.4445071518421173\n",
            "Epoch: 21, Batch: 108, test Batch Loss: 0.43116503953933716\n",
            "Epoch: 21, Batch: 109, test Batch Loss: 0.4484054148197174\n",
            "Epoch: 21, Batch: 110, test Batch Loss: 0.49325886368751526\n",
            "Epoch: 21, Batch: 111, test Batch Loss: 0.5324302911758423\n",
            "Epoch: 21, Batch: 112, test Batch Loss: 0.5004472136497498\n",
            "Epoch: 21, Batch: 113, test Batch Loss: 0.8384873867034912\n",
            "Epoch: 21, Batch: 114, test Batch Loss: 0.33041149377822876\n",
            "Epoch: 21, Batch: 115, test Batch Loss: 0.4111367464065552\n",
            "Epoch: 21, Batch: 116, test Batch Loss: 0.49376624822616577\n",
            "Epoch: 21, Batch: 117, test Batch Loss: 0.5772864818572998\n",
            "Epoch: 21, Batch: 118, test Batch Loss: 0.4288160800933838\n",
            "Epoch: 21, Batch: 119, test Batch Loss: 0.7328058481216431\n",
            "Epoch: 21, Batch: 120, test Batch Loss: 0.49715662002563477\n",
            "Epoch: 21, Batch: 121, test Batch Loss: 0.809929370880127\n",
            "Epoch: 21, Batch: 122, test Batch Loss: 0.5191039443016052\n",
            "Epoch: 21, Batch: 123, test Batch Loss: 0.4423106908798218\n",
            "Epoch: 21, Batch: 124, test Batch Loss: 0.43879279494285583\n",
            "Epoch: 21, Batch: 125, test Batch Loss: 0.36964744329452515\n",
            "Epoch: 21, Batch: 126, test Batch Loss: 0.6265550255775452\n",
            "Epoch: 21, Batch: 127, test Batch Loss: 0.5368468761444092\n",
            "Epoch: 21, Batch: 128, test Batch Loss: 0.3750617802143097\n",
            "Epoch: 21, Batch: 129, test Batch Loss: 0.3055832087993622\n",
            "Epoch: 21, Batch: 130, test Batch Loss: 0.3704233169555664\n",
            "Epoch: 21, Batch: 131, test Batch Loss: 0.4864896237850189\n",
            "Epoch: 21, Batch: 132, test Batch Loss: 0.48718827962875366\n",
            "Epoch: 21, Batch: 133, test Batch Loss: 0.5738221406936646\n",
            "Epoch: 21, Batch: 134, test Batch Loss: 0.41366061568260193\n",
            "Epoch: 21, Batch: 135, test Batch Loss: 0.551017701625824\n",
            "Epoch: 21, Batch: 136, test Batch Loss: 0.4749320447444916\n",
            "Epoch: 21, Batch: 137, test Batch Loss: 0.3528454303741455\n",
            "Epoch: 21, Batch: 138, test Batch Loss: 0.6706346273422241\n",
            "Epoch: 21, Batch: 139, test Batch Loss: 0.7091627717018127\n",
            "Epoch: 21, Batch: 140, test Batch Loss: 0.6535201072692871\n",
            "Epoch: 21, Batch: 141, test Batch Loss: 0.45091763138771057\n",
            "Epoch: 21, Batch: 142, test Batch Loss: 0.5083461999893188\n",
            "Epoch: 21, Batch: 143, test Batch Loss: 0.3668109178543091\n",
            "Epoch: 21, Batch: 144, test Batch Loss: 0.37004706263542175\n",
            "Epoch: 21, Batch: 145, test Batch Loss: 0.5635157823562622\n",
            "Epoch: 21, Batch: 146, test Batch Loss: 0.4884667694568634\n",
            "Epoch: 21, Batch: 147, test Batch Loss: 0.47828054428100586\n",
            "Epoch: 21, Batch: 148, test Batch Loss: 0.6111487150192261\n",
            "Epoch: 21, Batch: 149, test Batch Loss: 0.3838105797767639\n",
            "Epoch: 21, Batch: 150, test Batch Loss: 0.6647063493728638\n",
            "Epoch: 21, Batch: 151, test Batch Loss: 0.650307297706604\n",
            "Epoch: 21, Batch: 152, test Batch Loss: 0.8368414044380188\n",
            "Epoch: 21, Batch: 153, test Batch Loss: 0.5206486582756042\n",
            "Epoch: 21, Batch: 154, test Batch Loss: 0.47692373394966125\n",
            "Epoch: 21, Batch: 155, test Batch Loss: 0.4221580922603607\n",
            "Epoch: 21, Batch: 156, test Batch Loss: 0.7572791576385498\n",
            "Accuracy of test set: 0.8242\n",
            "Epoch 22/25 - Train Loss: 0.4018, Train Acc: 0.8586, Test Loss: 0.5254, Test Acc: 0.8242\n",
            "Epoch: 22, Batch: 0, Batch Loss: 0.33131611347198486\n",
            "Epoch: 22, Batch: 1, Batch Loss: 0.4408893585205078\n",
            "Epoch: 22, Batch: 2, Batch Loss: 0.3705327808856964\n",
            "Epoch: 22, Batch: 3, Batch Loss: 0.38765761256217957\n",
            "Epoch: 22, Batch: 4, Batch Loss: 0.3299611508846283\n",
            "Epoch: 22, Batch: 5, Batch Loss: 0.438932865858078\n",
            "Epoch: 22, Batch: 6, Batch Loss: 0.3341740071773529\n",
            "Epoch: 22, Batch: 7, Batch Loss: 0.27132174372673035\n",
            "Epoch: 22, Batch: 8, Batch Loss: 0.3469780683517456\n",
            "Epoch: 22, Batch: 9, Batch Loss: 0.294416606426239\n",
            "Epoch: 22, Batch: 10, Batch Loss: 0.47807928919792175\n",
            "Epoch: 22, Batch: 11, Batch Loss: 0.4018622040748596\n",
            "Epoch: 22, Batch: 12, Batch Loss: 0.5424562096595764\n",
            "Epoch: 22, Batch: 13, Batch Loss: 0.34068799018859863\n",
            "Epoch: 22, Batch: 14, Batch Loss: 0.40657317638397217\n",
            "Epoch: 22, Batch: 15, Batch Loss: 0.6032662391662598\n",
            "Epoch: 22, Batch: 16, Batch Loss: 0.47392717003822327\n",
            "Epoch: 22, Batch: 17, Batch Loss: 0.38666701316833496\n",
            "Epoch: 22, Batch: 18, Batch Loss: 0.2857542335987091\n",
            "Epoch: 22, Batch: 19, Batch Loss: 0.37523382902145386\n",
            "Epoch: 22, Batch: 20, Batch Loss: 0.4513375461101532\n",
            "Epoch: 22, Batch: 21, Batch Loss: 0.4480912983417511\n",
            "Epoch: 22, Batch: 22, Batch Loss: 0.2918862998485565\n",
            "Epoch: 22, Batch: 23, Batch Loss: 0.3704366981983185\n",
            "Epoch: 22, Batch: 24, Batch Loss: 0.502371609210968\n",
            "Epoch: 22, Batch: 25, Batch Loss: 0.3908037841320038\n",
            "Epoch: 22, Batch: 26, Batch Loss: 0.4173862636089325\n",
            "Epoch: 22, Batch: 27, Batch Loss: 0.2885618805885315\n",
            "Epoch: 22, Batch: 28, Batch Loss: 0.37920522689819336\n",
            "Epoch: 22, Batch: 29, Batch Loss: 0.23729510605335236\n",
            "Epoch: 22, Batch: 30, Batch Loss: 0.37007734179496765\n",
            "Epoch: 22, Batch: 31, Batch Loss: 0.347188800573349\n",
            "Epoch: 22, Batch: 32, Batch Loss: 0.3610881567001343\n",
            "Epoch: 22, Batch: 33, Batch Loss: 0.31647539138793945\n",
            "Epoch: 22, Batch: 34, Batch Loss: 0.500731348991394\n",
            "Epoch: 22, Batch: 35, Batch Loss: 0.24219104647636414\n",
            "Epoch: 22, Batch: 36, Batch Loss: 0.29635947942733765\n",
            "Epoch: 22, Batch: 37, Batch Loss: 0.4783865213394165\n",
            "Epoch: 22, Batch: 38, Batch Loss: 0.24429526925086975\n",
            "Epoch: 22, Batch: 39, Batch Loss: 0.5699261426925659\n",
            "Epoch: 22, Batch: 40, Batch Loss: 0.6475139856338501\n",
            "Epoch: 22, Batch: 41, Batch Loss: 0.3853786587715149\n",
            "Epoch: 22, Batch: 42, Batch Loss: 0.7288748621940613\n",
            "Epoch: 22, Batch: 43, Batch Loss: 0.493269681930542\n",
            "Epoch: 22, Batch: 44, Batch Loss: 0.31325337290763855\n",
            "Epoch: 22, Batch: 45, Batch Loss: 0.3313719928264618\n",
            "Epoch: 22, Batch: 46, Batch Loss: 0.41576629877090454\n",
            "Epoch: 22, Batch: 47, Batch Loss: 0.45521849393844604\n",
            "Epoch: 22, Batch: 48, Batch Loss: 0.39513200521469116\n",
            "Epoch: 22, Batch: 49, Batch Loss: 0.3586074113845825\n",
            "Epoch: 22, Batch: 50, Batch Loss: 0.4308663010597229\n",
            "Epoch: 22, Batch: 51, Batch Loss: 0.4123520255088806\n",
            "Epoch: 22, Batch: 52, Batch Loss: 0.3657912611961365\n",
            "Epoch: 22, Batch: 53, Batch Loss: 0.26984286308288574\n",
            "Epoch: 22, Batch: 54, Batch Loss: 0.45577913522720337\n",
            "Epoch: 22, Batch: 55, Batch Loss: 0.4994646906852722\n",
            "Epoch: 22, Batch: 56, Batch Loss: 0.41806477308273315\n",
            "Epoch: 22, Batch: 57, Batch Loss: 0.41448232531547546\n",
            "Epoch: 22, Batch: 58, Batch Loss: 0.2083270400762558\n",
            "Epoch: 22, Batch: 59, Batch Loss: 0.27768152952194214\n",
            "Epoch: 22, Batch: 60, Batch Loss: 0.3678753972053528\n",
            "Epoch: 22, Batch: 61, Batch Loss: 0.4490356147289276\n",
            "Epoch: 22, Batch: 62, Batch Loss: 0.4437862038612366\n",
            "Epoch: 22, Batch: 63, Batch Loss: 0.43770715594291687\n",
            "Epoch: 22, Batch: 64, Batch Loss: 0.24749170243740082\n",
            "Epoch: 22, Batch: 65, Batch Loss: 0.6273629665374756\n",
            "Epoch: 22, Batch: 66, Batch Loss: 0.475748747587204\n",
            "Epoch: 22, Batch: 67, Batch Loss: 0.5813103318214417\n",
            "Epoch: 22, Batch: 68, Batch Loss: 0.354194313287735\n",
            "Epoch: 22, Batch: 69, Batch Loss: 0.3724868893623352\n",
            "Epoch: 22, Batch: 70, Batch Loss: 0.5397176742553711\n",
            "Epoch: 22, Batch: 71, Batch Loss: 0.3604000508785248\n",
            "Epoch: 22, Batch: 72, Batch Loss: 0.23944279551506042\n",
            "Epoch: 22, Batch: 73, Batch Loss: 0.405809223651886\n",
            "Epoch: 22, Batch: 74, Batch Loss: 0.35757169127464294\n",
            "Epoch: 22, Batch: 75, Batch Loss: 0.3203611373901367\n",
            "Epoch: 22, Batch: 76, Batch Loss: 0.4701133668422699\n",
            "Epoch: 22, Batch: 77, Batch Loss: 0.6675592064857483\n",
            "Epoch: 22, Batch: 78, Batch Loss: 0.47818633913993835\n",
            "Epoch: 22, Batch: 79, Batch Loss: 0.4338342547416687\n",
            "Epoch: 22, Batch: 80, Batch Loss: 0.2664205729961395\n",
            "Epoch: 22, Batch: 81, Batch Loss: 0.33873629570007324\n",
            "Epoch: 22, Batch: 82, Batch Loss: 0.3286191523075104\n",
            "Epoch: 22, Batch: 83, Batch Loss: 0.1616193801164627\n",
            "Epoch: 22, Batch: 84, Batch Loss: 0.2422613650560379\n",
            "Epoch: 22, Batch: 85, Batch Loss: 0.44077068567276\n",
            "Epoch: 22, Batch: 86, Batch Loss: 0.23744985461235046\n",
            "Epoch: 22, Batch: 87, Batch Loss: 0.33645099401474\n",
            "Epoch: 22, Batch: 88, Batch Loss: 0.3692241609096527\n",
            "Epoch: 22, Batch: 89, Batch Loss: 0.3081165552139282\n",
            "Epoch: 22, Batch: 90, Batch Loss: 0.3112972676753998\n",
            "Epoch: 22, Batch: 91, Batch Loss: 0.26483672857284546\n",
            "Epoch: 22, Batch: 92, Batch Loss: 0.3486529290676117\n",
            "Epoch: 22, Batch: 93, Batch Loss: 0.3143433630466461\n",
            "Epoch: 22, Batch: 94, Batch Loss: 0.24384650588035583\n",
            "Epoch: 22, Batch: 95, Batch Loss: 0.5510674118995667\n",
            "Epoch: 22, Batch: 96, Batch Loss: 0.34938326478004456\n",
            "Epoch: 22, Batch: 97, Batch Loss: 0.5598905086517334\n",
            "Epoch: 22, Batch: 98, Batch Loss: 0.4482426047325134\n",
            "Epoch: 22, Batch: 99, Batch Loss: 0.46636027097702026\n",
            "Epoch: 22, Batch: 100, Batch Loss: 0.37123438715934753\n",
            "Epoch: 22, Batch: 101, Batch Loss: 0.42102527618408203\n",
            "Epoch: 22, Batch: 102, Batch Loss: 0.3689337372779846\n",
            "Epoch: 22, Batch: 103, Batch Loss: 0.34215307235717773\n",
            "Epoch: 22, Batch: 104, Batch Loss: 0.3215808868408203\n",
            "Epoch: 22, Batch: 105, Batch Loss: 0.2892705798149109\n",
            "Epoch: 22, Batch: 106, Batch Loss: 0.29860734939575195\n",
            "Epoch: 22, Batch: 107, Batch Loss: 0.35910141468048096\n",
            "Epoch: 22, Batch: 108, Batch Loss: 0.23283608257770538\n",
            "Epoch: 22, Batch: 109, Batch Loss: 0.3447454869747162\n",
            "Epoch: 22, Batch: 110, Batch Loss: 0.3185512125492096\n",
            "Epoch: 22, Batch: 111, Batch Loss: 0.5317853093147278\n",
            "Epoch: 22, Batch: 112, Batch Loss: 0.4575195908546448\n",
            "Epoch: 22, Batch: 113, Batch Loss: 0.30845844745635986\n",
            "Epoch: 22, Batch: 114, Batch Loss: 0.39477959275245667\n",
            "Epoch: 22, Batch: 115, Batch Loss: 0.36888179183006287\n",
            "Epoch: 22, Batch: 116, Batch Loss: 0.29998981952667236\n",
            "Epoch: 22, Batch: 117, Batch Loss: 0.37132328748703003\n",
            "Epoch: 22, Batch: 118, Batch Loss: 0.27936968207359314\n",
            "Epoch: 22, Batch: 119, Batch Loss: 0.29820716381073\n",
            "Epoch: 22, Batch: 120, Batch Loss: 0.30694979429244995\n",
            "Epoch: 22, Batch: 121, Batch Loss: 0.3396304249763489\n",
            "Epoch: 22, Batch: 122, Batch Loss: 0.2565254271030426\n",
            "Epoch: 22, Batch: 123, Batch Loss: 0.32855477929115295\n",
            "Epoch: 22, Batch: 124, Batch Loss: 0.3136932849884033\n",
            "Epoch: 22, Batch: 125, Batch Loss: 0.42037439346313477\n",
            "Epoch: 22, Batch: 126, Batch Loss: 0.24297955632209778\n",
            "Epoch: 22, Batch: 127, Batch Loss: 0.4014545679092407\n",
            "Epoch: 22, Batch: 128, Batch Loss: 0.42372220754623413\n",
            "Epoch: 22, Batch: 129, Batch Loss: 0.3915942311286926\n",
            "Epoch: 22, Batch: 130, Batch Loss: 0.48859792947769165\n",
            "Epoch: 22, Batch: 131, Batch Loss: 0.41904595494270325\n",
            "Epoch: 22, Batch: 132, Batch Loss: 0.3560531735420227\n",
            "Epoch: 22, Batch: 133, Batch Loss: 0.46244364976882935\n",
            "Epoch: 22, Batch: 134, Batch Loss: 0.3262093663215637\n",
            "Epoch: 22, Batch: 135, Batch Loss: 0.40423911809921265\n",
            "Epoch: 22, Batch: 136, Batch Loss: 0.43949827551841736\n",
            "Epoch: 22, Batch: 137, Batch Loss: 0.3871456980705261\n",
            "Epoch: 22, Batch: 138, Batch Loss: 0.48704370856285095\n",
            "Epoch: 22, Batch: 139, Batch Loss: 0.5646018981933594\n",
            "Epoch: 22, Batch: 140, Batch Loss: 0.32903653383255005\n",
            "Epoch: 22, Batch: 141, Batch Loss: 0.3097821772098541\n",
            "Epoch: 22, Batch: 142, Batch Loss: 0.22969087958335876\n",
            "Epoch: 22, Batch: 143, Batch Loss: 0.42347052693367004\n",
            "Epoch: 22, Batch: 144, Batch Loss: 0.267136812210083\n",
            "Epoch: 22, Batch: 145, Batch Loss: 0.6275730729103088\n",
            "Epoch: 22, Batch: 146, Batch Loss: 0.2934814393520355\n",
            "Epoch: 22, Batch: 147, Batch Loss: 0.29836052656173706\n",
            "Epoch: 22, Batch: 148, Batch Loss: 0.3710164427757263\n",
            "Epoch: 22, Batch: 149, Batch Loss: 0.4314964711666107\n",
            "Epoch: 22, Batch: 150, Batch Loss: 0.5121768116950989\n",
            "Epoch: 22, Batch: 151, Batch Loss: 0.5735899806022644\n",
            "Epoch: 22, Batch: 152, Batch Loss: 0.31008121371269226\n",
            "Epoch: 22, Batch: 153, Batch Loss: 0.46813198924064636\n",
            "Epoch: 22, Batch: 154, Batch Loss: 0.32183194160461426\n",
            "Epoch: 22, Batch: 155, Batch Loss: 0.3527543842792511\n",
            "Epoch: 22, Batch: 156, Batch Loss: 0.3548140823841095\n",
            "Epoch: 22, Batch: 157, Batch Loss: 0.44816654920578003\n",
            "Epoch: 22, Batch: 158, Batch Loss: 0.3412567973136902\n",
            "Epoch: 22, Batch: 159, Batch Loss: 0.6262664794921875\n",
            "Epoch: 22, Batch: 160, Batch Loss: 0.5330893993377686\n",
            "Epoch: 22, Batch: 161, Batch Loss: 0.21101871132850647\n",
            "Epoch: 22, Batch: 162, Batch Loss: 0.39024725556373596\n",
            "Epoch: 22, Batch: 163, Batch Loss: 0.37044602632522583\n",
            "Epoch: 22, Batch: 164, Batch Loss: 0.40534424781799316\n",
            "Epoch: 22, Batch: 165, Batch Loss: 0.27255356311798096\n",
            "Epoch: 22, Batch: 166, Batch Loss: 0.3856811225414276\n",
            "Epoch: 22, Batch: 167, Batch Loss: 0.34153154492378235\n",
            "Epoch: 22, Batch: 168, Batch Loss: 0.34436556696891785\n",
            "Epoch: 22, Batch: 169, Batch Loss: 0.4827757775783539\n",
            "Epoch: 22, Batch: 170, Batch Loss: 0.3691520690917969\n",
            "Epoch: 22, Batch: 171, Batch Loss: 0.3067098557949066\n",
            "Epoch: 22, Batch: 172, Batch Loss: 0.4584583044052124\n",
            "Epoch: 22, Batch: 173, Batch Loss: 0.3528074324131012\n",
            "Epoch: 22, Batch: 174, Batch Loss: 0.4932185113430023\n",
            "Epoch: 22, Batch: 175, Batch Loss: 0.39573541283607483\n",
            "Epoch: 22, Batch: 176, Batch Loss: 0.48054879903793335\n",
            "Epoch: 22, Batch: 177, Batch Loss: 0.5187955498695374\n",
            "Epoch: 22, Batch: 178, Batch Loss: 0.5295812487602234\n",
            "Epoch: 22, Batch: 179, Batch Loss: 0.495094358921051\n",
            "Epoch: 22, Batch: 180, Batch Loss: 0.4468574523925781\n",
            "Epoch: 22, Batch: 181, Batch Loss: 0.5904953479766846\n",
            "Epoch: 22, Batch: 182, Batch Loss: 0.34774142503738403\n",
            "Epoch: 22, Batch: 183, Batch Loss: 0.2623772621154785\n",
            "Epoch: 22, Batch: 184, Batch Loss: 0.3097381293773651\n",
            "Epoch: 22, Batch: 185, Batch Loss: 0.2287660539150238\n",
            "Epoch: 22, Batch: 186, Batch Loss: 0.397918164730072\n",
            "Epoch: 22, Batch: 187, Batch Loss: 0.4270172119140625\n",
            "Epoch: 22, Batch: 188, Batch Loss: 0.2935798764228821\n",
            "Epoch: 22, Batch: 189, Batch Loss: 0.44283974170684814\n",
            "Epoch: 22, Batch: 190, Batch Loss: 0.2784821093082428\n",
            "Epoch: 22, Batch: 191, Batch Loss: 0.5537126660346985\n",
            "Epoch: 22, Batch: 192, Batch Loss: 0.2659991383552551\n",
            "Epoch: 22, Batch: 193, Batch Loss: 0.4388088285923004\n",
            "Epoch: 22, Batch: 194, Batch Loss: 0.35945236682891846\n",
            "Epoch: 22, Batch: 195, Batch Loss: 0.680295467376709\n",
            "Epoch: 22, Batch: 196, Batch Loss: 0.5241165161132812\n",
            "Epoch: 22, Batch: 197, Batch Loss: 0.42751359939575195\n",
            "Epoch: 22, Batch: 198, Batch Loss: 0.33999454975128174\n",
            "Epoch: 22, Batch: 199, Batch Loss: 0.4977218806743622\n",
            "Epoch: 22, Batch: 200, Batch Loss: 0.425506591796875\n",
            "Epoch: 22, Batch: 201, Batch Loss: 0.20699676871299744\n",
            "Epoch: 22, Batch: 202, Batch Loss: 0.32466283440589905\n",
            "Epoch: 22, Batch: 203, Batch Loss: 0.38376063108444214\n",
            "Epoch: 22, Batch: 204, Batch Loss: 0.2587387263774872\n",
            "Epoch: 22, Batch: 205, Batch Loss: 0.3493349254131317\n",
            "Epoch: 22, Batch: 206, Batch Loss: 0.5994633436203003\n",
            "Epoch: 22, Batch: 207, Batch Loss: 0.35086870193481445\n",
            "Epoch: 22, Batch: 208, Batch Loss: 0.43595871329307556\n",
            "Epoch: 22, Batch: 209, Batch Loss: 0.3389755189418793\n",
            "Epoch: 22, Batch: 210, Batch Loss: 0.4096716642379761\n",
            "Epoch: 22, Batch: 211, Batch Loss: 0.6857677698135376\n",
            "Epoch: 22, Batch: 212, Batch Loss: 0.5797334313392639\n",
            "Epoch: 22, Batch: 213, Batch Loss: 0.3922259211540222\n",
            "Epoch: 22, Batch: 214, Batch Loss: 0.4272545576095581\n",
            "Epoch: 22, Batch: 215, Batch Loss: 0.2685750424861908\n",
            "Epoch: 22, Batch: 216, Batch Loss: 0.6607677936553955\n",
            "Epoch: 22, Batch: 217, Batch Loss: 0.5880089402198792\n",
            "Epoch: 22, Batch: 218, Batch Loss: 0.29141560196876526\n",
            "Epoch: 22, Batch: 219, Batch Loss: 0.4008637070655823\n",
            "Epoch: 22, Batch: 220, Batch Loss: 0.5148673057556152\n",
            "Epoch: 22, Batch: 221, Batch Loss: 0.36984387040138245\n",
            "Epoch: 22, Batch: 222, Batch Loss: 0.21180963516235352\n",
            "Epoch: 22, Batch: 223, Batch Loss: 0.3684193789958954\n",
            "Epoch: 22, Batch: 224, Batch Loss: 0.4689342677593231\n",
            "Epoch: 22, Batch: 225, Batch Loss: 0.32070788741111755\n",
            "Epoch: 22, Batch: 226, Batch Loss: 0.44928357005119324\n",
            "Epoch: 22, Batch: 227, Batch Loss: 0.28670358657836914\n",
            "Epoch: 22, Batch: 228, Batch Loss: 0.29108625650405884\n",
            "Epoch: 22, Batch: 229, Batch Loss: 0.2880474627017975\n",
            "Epoch: 22, Batch: 230, Batch Loss: 0.5527116060256958\n",
            "Epoch: 22, Batch: 231, Batch Loss: 0.4677872061729431\n",
            "Epoch: 22, Batch: 232, Batch Loss: 0.37169232964515686\n",
            "Epoch: 22, Batch: 233, Batch Loss: 0.3802449703216553\n",
            "Epoch: 22, Batch: 234, Batch Loss: 0.5253283381462097\n",
            "Epoch: 22, Batch: 235, Batch Loss: 0.26743626594543457\n",
            "Epoch: 22, Batch: 236, Batch Loss: 0.23477226495742798\n",
            "Epoch: 22, Batch: 237, Batch Loss: 0.22041863203048706\n",
            "Epoch: 22, Batch: 238, Batch Loss: 0.3007732629776001\n",
            "Epoch: 22, Batch: 239, Batch Loss: 0.5055558681488037\n",
            "Epoch: 22, Batch: 240, Batch Loss: 0.4520860016345978\n",
            "Epoch: 22, Batch: 241, Batch Loss: 0.629687488079071\n",
            "Epoch: 22, Batch: 242, Batch Loss: 0.4800857901573181\n",
            "Epoch: 22, Batch: 243, Batch Loss: 0.5041027069091797\n",
            "Epoch: 22, Batch: 244, Batch Loss: 0.4853121340274811\n",
            "Epoch: 22, Batch: 245, Batch Loss: 0.5047087669372559\n",
            "Epoch: 22, Batch: 246, Batch Loss: 0.2860497832298279\n",
            "Epoch: 22, Batch: 247, Batch Loss: 0.4699908494949341\n",
            "Epoch: 22, Batch: 248, Batch Loss: 0.44498616456985474\n",
            "Epoch: 22, Batch: 249, Batch Loss: 0.30803459882736206\n",
            "Epoch: 22, Batch: 250, Batch Loss: 0.5745909214019775\n",
            "Epoch: 22, Batch: 251, Batch Loss: 0.2679538428783417\n",
            "Epoch: 22, Batch: 252, Batch Loss: 0.21055708825588226\n",
            "Epoch: 22, Batch: 253, Batch Loss: 0.4087429642677307\n",
            "Epoch: 22, Batch: 254, Batch Loss: 0.4455816149711609\n",
            "Epoch: 22, Batch: 255, Batch Loss: 0.4689027667045593\n",
            "Epoch: 22, Batch: 256, Batch Loss: 0.5117683410644531\n",
            "Epoch: 22, Batch: 257, Batch Loss: 0.38485270738601685\n",
            "Epoch: 22, Batch: 258, Batch Loss: 0.3777309060096741\n",
            "Epoch: 22, Batch: 259, Batch Loss: 0.28011563420295715\n",
            "Epoch: 22, Batch: 260, Batch Loss: 0.5330535173416138\n",
            "Epoch: 22, Batch: 261, Batch Loss: 0.3348749577999115\n",
            "Epoch: 22, Batch: 262, Batch Loss: 0.47133705019950867\n",
            "Epoch: 22, Batch: 263, Batch Loss: 0.3029889762401581\n",
            "Epoch: 22, Batch: 264, Batch Loss: 0.3938731551170349\n",
            "Epoch: 22, Batch: 265, Batch Loss: 0.25166821479797363\n",
            "Epoch: 22, Batch: 266, Batch Loss: 0.47183769941329956\n",
            "Epoch: 22, Batch: 267, Batch Loss: 0.21779568493366241\n",
            "Epoch: 22, Batch: 268, Batch Loss: 0.3372166156768799\n",
            "Epoch: 22, Batch: 269, Batch Loss: 0.24382589757442474\n",
            "Epoch: 22, Batch: 270, Batch Loss: 0.5203914642333984\n",
            "Epoch: 22, Batch: 271, Batch Loss: 0.22269423305988312\n",
            "Epoch: 22, Batch: 272, Batch Loss: 0.4508334994316101\n",
            "Epoch: 22, Batch: 273, Batch Loss: 0.4698512852191925\n",
            "Epoch: 22, Batch: 274, Batch Loss: 0.436201274394989\n",
            "Epoch: 22, Batch: 275, Batch Loss: 0.6521132588386536\n",
            "Epoch: 22, Batch: 276, Batch Loss: 0.4701322913169861\n",
            "Epoch: 22, Batch: 277, Batch Loss: 0.4771781265735626\n",
            "Epoch: 22, Batch: 278, Batch Loss: 0.4031684398651123\n",
            "Epoch: 22, Batch: 279, Batch Loss: 0.303499311208725\n",
            "Epoch: 22, Batch: 280, Batch Loss: 0.46696799993515015\n",
            "Epoch: 22, Batch: 281, Batch Loss: 0.3204520046710968\n",
            "Epoch: 22, Batch: 282, Batch Loss: 0.4240754544734955\n",
            "Epoch: 22, Batch: 283, Batch Loss: 0.28563031554222107\n",
            "Epoch: 22, Batch: 284, Batch Loss: 0.582900881767273\n",
            "Epoch: 22, Batch: 285, Batch Loss: 0.3653605282306671\n",
            "Epoch: 22, Batch: 286, Batch Loss: 0.3664243519306183\n",
            "Epoch: 22, Batch: 287, Batch Loss: 0.4451451897621155\n",
            "Epoch: 22, Batch: 288, Batch Loss: 0.34219807386398315\n",
            "Epoch: 22, Batch: 289, Batch Loss: 0.25938114523887634\n",
            "Epoch: 22, Batch: 290, Batch Loss: 0.4271402359008789\n",
            "Epoch: 22, Batch: 291, Batch Loss: 0.2644946873188019\n",
            "Epoch: 22, Batch: 292, Batch Loss: 0.5954403877258301\n",
            "Epoch: 22, Batch: 293, Batch Loss: 0.431426078081131\n",
            "Epoch: 22, Batch: 294, Batch Loss: 0.26225876808166504\n",
            "Epoch: 22, Batch: 295, Batch Loss: 0.39989417791366577\n",
            "Epoch: 22, Batch: 296, Batch Loss: 0.21158480644226074\n",
            "Epoch: 22, Batch: 297, Batch Loss: 0.44938886165618896\n",
            "Epoch: 22, Batch: 298, Batch Loss: 0.4150354862213135\n",
            "Epoch: 22, Batch: 299, Batch Loss: 0.6859540939331055\n",
            "Epoch: 22, Batch: 300, Batch Loss: 0.3275846242904663\n",
            "Epoch: 22, Batch: 301, Batch Loss: 0.5485573410987854\n",
            "Epoch: 22, Batch: 302, Batch Loss: 0.33932289481163025\n",
            "Epoch: 22, Batch: 303, Batch Loss: 0.3148661255836487\n",
            "Epoch: 22, Batch: 304, Batch Loss: 0.3621653914451599\n",
            "Epoch: 22, Batch: 305, Batch Loss: 0.44396811723709106\n",
            "Epoch: 22, Batch: 306, Batch Loss: 0.42004626989364624\n",
            "Epoch: 22, Batch: 307, Batch Loss: 0.4583171308040619\n",
            "Epoch: 22, Batch: 308, Batch Loss: 0.31995534896850586\n",
            "Epoch: 22, Batch: 309, Batch Loss: 0.3592385947704315\n",
            "Epoch: 22, Batch: 310, Batch Loss: 0.4301135838031769\n",
            "Epoch: 22, Batch: 311, Batch Loss: 0.4755670726299286\n",
            "Epoch: 22, Batch: 312, Batch Loss: 0.42628014087677\n",
            "Epoch: 22, Batch: 313, Batch Loss: 0.4040772318840027\n",
            "Epoch: 22, Batch: 314, Batch Loss: 0.4314282536506653\n",
            "Epoch: 22, Batch: 315, Batch Loss: 0.3085932731628418\n",
            "Epoch: 22, Batch: 316, Batch Loss: 0.37558019161224365\n",
            "Epoch: 22, Batch: 317, Batch Loss: 0.4387281537055969\n",
            "Epoch: 22, Batch: 318, Batch Loss: 0.4914039969444275\n",
            "Epoch: 22, Batch: 319, Batch Loss: 0.5781817436218262\n",
            "Epoch: 22, Batch: 320, Batch Loss: 0.6111260652542114\n",
            "Epoch: 22, Batch: 321, Batch Loss: 0.6144249439239502\n",
            "Epoch: 22, Batch: 322, Batch Loss: 0.3713501989841461\n",
            "Epoch: 22, Batch: 323, Batch Loss: 0.32360076904296875\n",
            "Epoch: 22, Batch: 324, Batch Loss: 0.3719107508659363\n",
            "Epoch: 22, Batch: 325, Batch Loss: 0.4521622359752655\n",
            "Epoch: 22, Batch: 326, Batch Loss: 0.5392757654190063\n",
            "Epoch: 22, Batch: 327, Batch Loss: 0.38740769028663635\n",
            "Epoch: 22, Batch: 328, Batch Loss: 0.4780726432800293\n",
            "Epoch: 22, Batch: 329, Batch Loss: 0.40563878417015076\n",
            "Epoch: 22, Batch: 330, Batch Loss: 0.518955647945404\n",
            "Epoch: 22, Batch: 331, Batch Loss: 0.372290700674057\n",
            "Epoch: 22, Batch: 332, Batch Loss: 0.5992339253425598\n",
            "Epoch: 22, Batch: 333, Batch Loss: 0.3181280493736267\n",
            "Epoch: 22, Batch: 334, Batch Loss: 0.4574376940727234\n",
            "Epoch: 22, Batch: 335, Batch Loss: 0.18823865056037903\n",
            "Epoch: 22, Batch: 336, Batch Loss: 0.4831002354621887\n",
            "Epoch: 22, Batch: 337, Batch Loss: 0.4369388818740845\n",
            "Epoch: 22, Batch: 338, Batch Loss: 0.4147561490535736\n",
            "Epoch: 22, Batch: 339, Batch Loss: 0.31061822175979614\n",
            "Epoch: 22, Batch: 340, Batch Loss: 0.4928748905658722\n",
            "Epoch: 22, Batch: 341, Batch Loss: 0.3678849935531616\n",
            "Epoch: 22, Batch: 342, Batch Loss: 0.4796789586544037\n",
            "Epoch: 22, Batch: 343, Batch Loss: 0.4735705256462097\n",
            "Epoch: 22, Batch: 344, Batch Loss: 0.23102432489395142\n",
            "Epoch: 22, Batch: 345, Batch Loss: 0.4463796019554138\n",
            "Epoch: 22, Batch: 346, Batch Loss: 0.6082309484481812\n",
            "Epoch: 22, Batch: 347, Batch Loss: 0.23467963933944702\n",
            "Epoch: 22, Batch: 348, Batch Loss: 0.43971216678619385\n",
            "Epoch: 22, Batch: 349, Batch Loss: 0.3367686867713928\n",
            "Epoch: 22, Batch: 350, Batch Loss: 0.4533446729183197\n",
            "Epoch: 22, Batch: 351, Batch Loss: 0.3358877897262573\n",
            "Epoch: 22, Batch: 352, Batch Loss: 0.5289067029953003\n",
            "Epoch: 22, Batch: 353, Batch Loss: 0.520295262336731\n",
            "Epoch: 22, Batch: 354, Batch Loss: 0.3613798916339874\n",
            "Epoch: 22, Batch: 355, Batch Loss: 0.36943721771240234\n",
            "Epoch: 22, Batch: 356, Batch Loss: 0.41317158937454224\n",
            "Epoch: 22, Batch: 357, Batch Loss: 0.27748245000839233\n",
            "Epoch: 22, Batch: 358, Batch Loss: 0.5403481721878052\n",
            "Epoch: 22, Batch: 359, Batch Loss: 0.3582962155342102\n",
            "Epoch: 22, Batch: 360, Batch Loss: 0.46675020456314087\n",
            "Epoch: 22, Batch: 361, Batch Loss: 0.265094518661499\n",
            "Epoch: 22, Batch: 362, Batch Loss: 0.27496758103370667\n",
            "Epoch: 22, Batch: 363, Batch Loss: 0.5697686672210693\n",
            "Epoch: 22, Batch: 364, Batch Loss: 0.39655038714408875\n",
            "Epoch: 22, Batch: 365, Batch Loss: 0.5101428627967834\n",
            "Epoch: 22, Batch: 366, Batch Loss: 0.31128597259521484\n",
            "Epoch: 22, Batch: 367, Batch Loss: 0.2315964251756668\n",
            "Epoch: 22, Batch: 368, Batch Loss: 0.4159541726112366\n",
            "Epoch: 22, Batch: 369, Batch Loss: 0.42468589544296265\n",
            "Epoch: 22, Batch: 370, Batch Loss: 0.45444023609161377\n",
            "Epoch: 22, Batch: 371, Batch Loss: 0.34375813603401184\n",
            "Epoch: 22, Batch: 372, Batch Loss: 0.4715285301208496\n",
            "Epoch: 22, Batch: 373, Batch Loss: 0.3557887077331543\n",
            "Epoch: 22, Batch: 374, Batch Loss: 0.4673561155796051\n",
            "Epoch: 22, Batch: 375, Batch Loss: 0.35268065333366394\n",
            "Epoch: 22, Batch: 376, Batch Loss: 0.3503079414367676\n",
            "Epoch: 22, Batch: 377, Batch Loss: 0.33786678314208984\n",
            "Epoch: 22, Batch: 378, Batch Loss: 0.29695621132850647\n",
            "Epoch: 22, Batch: 379, Batch Loss: 0.3397575914859772\n",
            "Epoch: 22, Batch: 380, Batch Loss: 0.4057902991771698\n",
            "Epoch: 22, Batch: 381, Batch Loss: 0.34162643551826477\n",
            "Epoch: 22, Batch: 382, Batch Loss: 0.3667411208152771\n",
            "Epoch: 22, Batch: 383, Batch Loss: 0.3077079653739929\n",
            "Epoch: 22, Batch: 384, Batch Loss: 0.3913387656211853\n",
            "Epoch: 22, Batch: 385, Batch Loss: 0.34902122616767883\n",
            "Epoch: 22, Batch: 386, Batch Loss: 0.2668724060058594\n",
            "Epoch: 22, Batch: 387, Batch Loss: 0.28528547286987305\n",
            "Epoch: 22, Batch: 388, Batch Loss: 0.5126216411590576\n",
            "Epoch: 22, Batch: 389, Batch Loss: 0.26628226041793823\n",
            "Epoch: 22, Batch: 390, Batch Loss: 0.2987755239009857\n",
            "Epoch: 22, Batch: 391, Batch Loss: 0.30694520473480225\n",
            "Epoch: 22, Batch: 392, Batch Loss: 0.38916805386543274\n",
            "Epoch: 22, Batch: 393, Batch Loss: 0.28850895166397095\n",
            "Epoch: 22, Batch: 394, Batch Loss: 0.20630502700805664\n",
            "Epoch: 22, Batch: 395, Batch Loss: 0.293698251247406\n",
            "Epoch: 22, Batch: 396, Batch Loss: 0.30816423892974854\n",
            "Epoch: 22, Batch: 397, Batch Loss: 0.32316333055496216\n",
            "Epoch: 22, Batch: 398, Batch Loss: 0.31329357624053955\n",
            "Epoch: 22, Batch: 399, Batch Loss: 0.5557260513305664\n",
            "Epoch: 22, Batch: 400, Batch Loss: 0.3622153699398041\n",
            "Epoch: 22, Batch: 401, Batch Loss: 0.4162474274635315\n",
            "Epoch: 22, Batch: 402, Batch Loss: 0.4536452889442444\n",
            "Epoch: 22, Batch: 403, Batch Loss: 0.3810023069381714\n",
            "Epoch: 22, Batch: 404, Batch Loss: 0.37932953238487244\n",
            "Epoch: 22, Batch: 405, Batch Loss: 0.45430660247802734\n",
            "Epoch: 22, Batch: 406, Batch Loss: 0.4036490321159363\n",
            "Epoch: 22, Batch: 407, Batch Loss: 0.3560381531715393\n",
            "Epoch: 22, Batch: 408, Batch Loss: 0.4110986590385437\n",
            "Epoch: 22, Batch: 409, Batch Loss: 0.47746342420578003\n",
            "Epoch: 22, Batch: 410, Batch Loss: 0.37610936164855957\n",
            "Epoch: 22, Batch: 411, Batch Loss: 0.37996822595596313\n",
            "Epoch: 22, Batch: 412, Batch Loss: 0.32845908403396606\n",
            "Epoch: 22, Batch: 413, Batch Loss: 0.47897982597351074\n",
            "Epoch: 22, Batch: 414, Batch Loss: 0.31592631340026855\n",
            "Epoch: 22, Batch: 415, Batch Loss: 0.5767987966537476\n",
            "Epoch: 22, Batch: 416, Batch Loss: 0.44649481773376465\n",
            "Epoch: 22, Batch: 417, Batch Loss: 0.33130574226379395\n",
            "Epoch: 22, Batch: 418, Batch Loss: 0.3870466351509094\n",
            "Epoch: 22, Batch: 419, Batch Loss: 0.33766406774520874\n",
            "Epoch: 22, Batch: 420, Batch Loss: 0.447801411151886\n",
            "Epoch: 22, Batch: 421, Batch Loss: 0.3770546615123749\n",
            "Epoch: 22, Batch: 422, Batch Loss: 0.32255107164382935\n",
            "Epoch: 22, Batch: 423, Batch Loss: 0.3517581820487976\n",
            "Epoch: 22, Batch: 424, Batch Loss: 0.3934652805328369\n",
            "Epoch: 22, Batch: 425, Batch Loss: 0.3226063847541809\n",
            "Epoch: 22, Batch: 426, Batch Loss: 0.35396504402160645\n",
            "Epoch: 22, Batch: 427, Batch Loss: 0.3609837293624878\n",
            "Epoch: 22, Batch: 428, Batch Loss: 0.3728911280632019\n",
            "Epoch: 22, Batch: 429, Batch Loss: 0.46855616569519043\n",
            "Epoch: 22, Batch: 430, Batch Loss: 0.2479521781206131\n",
            "Epoch: 22, Batch: 431, Batch Loss: 0.4570389986038208\n",
            "Epoch: 22, Batch: 432, Batch Loss: 0.5720750689506531\n",
            "Epoch: 22, Batch: 433, Batch Loss: 0.4891834557056427\n",
            "Epoch: 22, Batch: 434, Batch Loss: 0.43858128786087036\n",
            "Epoch: 22, Batch: 435, Batch Loss: 0.2696966528892517\n",
            "Epoch: 22, Batch: 436, Batch Loss: 0.4269399642944336\n",
            "Epoch: 22, Batch: 437, Batch Loss: 0.3688782751560211\n",
            "Epoch: 22, Batch: 438, Batch Loss: 0.3773556649684906\n",
            "Epoch: 22, Batch: 439, Batch Loss: 0.4460653066635132\n",
            "Epoch: 22, Batch: 440, Batch Loss: 0.4080483615398407\n",
            "Epoch: 22, Batch: 441, Batch Loss: 0.6523730158805847\n",
            "Epoch: 22, Batch: 442, Batch Loss: 0.3009937107563019\n",
            "Epoch: 22, Batch: 443, Batch Loss: 0.6152700185775757\n",
            "Epoch: 22, Batch: 444, Batch Loss: 0.6245927810668945\n",
            "Epoch: 22, Batch: 445, Batch Loss: 0.3153465986251831\n",
            "Epoch: 22, Batch: 446, Batch Loss: 0.3818749189376831\n",
            "Epoch: 22, Batch: 447, Batch Loss: 0.30861493945121765\n",
            "Epoch: 22, Batch: 448, Batch Loss: 0.30600616335868835\n",
            "Epoch: 22, Batch: 449, Batch Loss: 0.411231130361557\n",
            "Epoch: 22, Batch: 450, Batch Loss: 0.26454007625579834\n",
            "Epoch: 22, Batch: 451, Batch Loss: 0.338233083486557\n",
            "Epoch: 22, Batch: 452, Batch Loss: 0.3851001560688019\n",
            "Epoch: 22, Batch: 453, Batch Loss: 0.32383424043655396\n",
            "Epoch: 22, Batch: 454, Batch Loss: 0.466474324464798\n",
            "Epoch: 22, Batch: 455, Batch Loss: 0.4358808696269989\n",
            "Epoch: 22, Batch: 456, Batch Loss: 0.6289666295051575\n",
            "Epoch: 22, Batch: 457, Batch Loss: 0.4206388592720032\n",
            "Epoch: 22, Batch: 458, Batch Loss: 0.34527525305747986\n",
            "Epoch: 22, Batch: 459, Batch Loss: 0.30794286727905273\n",
            "Epoch: 22, Batch: 460, Batch Loss: 0.35365039110183716\n",
            "Epoch: 22, Batch: 461, Batch Loss: 0.2372831553220749\n",
            "Epoch: 22, Batch: 462, Batch Loss: 0.47980159521102905\n",
            "Epoch: 22, Batch: 463, Batch Loss: 0.5178414583206177\n",
            "Epoch: 22, Batch: 464, Batch Loss: 0.4571380913257599\n",
            "Epoch: 22, Batch: 465, Batch Loss: 0.36941108107566833\n",
            "Epoch: 22, Batch: 466, Batch Loss: 0.35359397530555725\n",
            "Epoch: 22, Batch: 467, Batch Loss: 0.459808886051178\n",
            "Epoch: 22, Batch: 468, Batch Loss: 0.24246184527873993\n",
            "Epoch: 22, Batch: 469, Batch Loss: 0.5194554328918457\n",
            "Epoch: 22, Batch: 470, Batch Loss: 0.3774007558822632\n",
            "Epoch: 22, Batch: 471, Batch Loss: 0.4416472613811493\n",
            "Epoch: 22, Batch: 472, Batch Loss: 0.4749220609664917\n",
            "Epoch: 22, Batch: 473, Batch Loss: 0.6376315355300903\n",
            "Epoch: 22, Batch: 474, Batch Loss: 0.4790729582309723\n",
            "Epoch: 22, Batch: 475, Batch Loss: 0.4292444884777069\n",
            "Epoch: 22, Batch: 476, Batch Loss: 0.4682542085647583\n",
            "Epoch: 22, Batch: 477, Batch Loss: 0.4387539029121399\n",
            "Epoch: 22, Batch: 478, Batch Loss: 0.43507659435272217\n",
            "Epoch: 22, Batch: 479, Batch Loss: 0.3405389189720154\n",
            "Epoch: 22, Batch: 480, Batch Loss: 0.4514329731464386\n",
            "Epoch: 22, Batch: 481, Batch Loss: 0.3072974979877472\n",
            "Epoch: 22, Batch: 482, Batch Loss: 0.3332251310348511\n",
            "Epoch: 22, Batch: 483, Batch Loss: 0.31384333968162537\n",
            "Epoch: 22, Batch: 484, Batch Loss: 0.3537434935569763\n",
            "Epoch: 22, Batch: 485, Batch Loss: 0.5082013607025146\n",
            "Epoch: 22, Batch: 486, Batch Loss: 0.4169468283653259\n",
            "Epoch: 22, Batch: 487, Batch Loss: 0.5446219444274902\n",
            "Epoch: 22, Batch: 488, Batch Loss: 0.22191065549850464\n",
            "Epoch: 22, Batch: 489, Batch Loss: 0.4124494791030884\n",
            "Epoch: 22, Batch: 490, Batch Loss: 0.3030249774456024\n",
            "Epoch: 22, Batch: 491, Batch Loss: 0.3827558159828186\n",
            "Epoch: 22, Batch: 492, Batch Loss: 0.6000989675521851\n",
            "Epoch: 22, Batch: 493, Batch Loss: 0.2079281359910965\n",
            "Epoch: 22, Batch: 494, Batch Loss: 0.2106172889471054\n",
            "Epoch: 22, Batch: 495, Batch Loss: 0.31641456484794617\n",
            "Epoch: 22, Batch: 496, Batch Loss: 0.3963639438152313\n",
            "Epoch: 22, Batch: 497, Batch Loss: 0.3992696702480316\n",
            "Epoch: 22, Batch: 498, Batch Loss: 0.38469505310058594\n",
            "Epoch: 22, Batch: 499, Batch Loss: 0.5235930681228638\n",
            "Epoch: 22, Batch: 500, Batch Loss: 0.5834450721740723\n",
            "Epoch: 22, Batch: 501, Batch Loss: 0.3608413338661194\n",
            "Epoch: 22, Batch: 502, Batch Loss: 0.3257523477077484\n",
            "Epoch: 22, Batch: 503, Batch Loss: 0.4095444679260254\n",
            "Epoch: 22, Batch: 504, Batch Loss: 0.5126835107803345\n",
            "Epoch: 22, Batch: 505, Batch Loss: 0.3738754689693451\n",
            "Epoch: 22, Batch: 506, Batch Loss: 0.3733168840408325\n",
            "Epoch: 22, Batch: 507, Batch Loss: 0.32465091347694397\n",
            "Epoch: 22, Batch: 508, Batch Loss: 0.35418954491615295\n",
            "Epoch: 22, Batch: 509, Batch Loss: 0.6585181951522827\n",
            "Epoch: 22, Batch: 510, Batch Loss: 0.24702534079551697\n",
            "Epoch: 22, Batch: 511, Batch Loss: 0.5644102096557617\n",
            "Epoch: 22, Batch: 512, Batch Loss: 0.4767295718193054\n",
            "Epoch: 22, Batch: 513, Batch Loss: 0.681812584400177\n",
            "Epoch: 22, Batch: 514, Batch Loss: 0.4699733257293701\n",
            "Epoch: 22, Batch: 515, Batch Loss: 0.3871641755104065\n",
            "Epoch: 22, Batch: 516, Batch Loss: 0.335794061422348\n",
            "Epoch: 22, Batch: 517, Batch Loss: 0.3249681890010834\n",
            "Epoch: 22, Batch: 518, Batch Loss: 0.5023322701454163\n",
            "Epoch: 22, Batch: 519, Batch Loss: 0.42115846276283264\n",
            "Epoch: 22, Batch: 520, Batch Loss: 0.34033218026161194\n",
            "Epoch: 22, Batch: 521, Batch Loss: 0.560211181640625\n",
            "Epoch: 22, Batch: 522, Batch Loss: 0.36113184690475464\n",
            "Epoch: 22, Batch: 523, Batch Loss: 0.3556055426597595\n",
            "Epoch: 22, Batch: 524, Batch Loss: 0.3198688328266144\n",
            "Epoch: 22, Batch: 525, Batch Loss: 0.3550884425640106\n",
            "Epoch: 22, Batch: 526, Batch Loss: 0.4082777500152588\n",
            "Epoch: 22, Batch: 527, Batch Loss: 0.4447314143180847\n",
            "Epoch: 22, Batch: 528, Batch Loss: 0.33384448289871216\n",
            "Epoch: 22, Batch: 529, Batch Loss: 0.4271659851074219\n",
            "Epoch: 22, Batch: 530, Batch Loss: 0.28505954146385193\n",
            "Epoch: 22, Batch: 531, Batch Loss: 0.35702288150787354\n",
            "Epoch: 22, Batch: 532, Batch Loss: 0.29149389266967773\n",
            "Epoch: 22, Batch: 533, Batch Loss: 0.4159335792064667\n",
            "Epoch: 22, Batch: 534, Batch Loss: 0.2987038195133209\n",
            "Epoch: 22, Batch: 535, Batch Loss: 0.5064659714698792\n",
            "Epoch: 22, Batch: 536, Batch Loss: 0.43945860862731934\n",
            "Epoch: 22, Batch: 537, Batch Loss: 0.4177584648132324\n",
            "Epoch: 22, Batch: 538, Batch Loss: 0.33093011379241943\n",
            "Epoch: 22, Batch: 539, Batch Loss: 0.32140833139419556\n",
            "Epoch: 22, Batch: 540, Batch Loss: 0.3511861562728882\n",
            "Epoch: 22, Batch: 541, Batch Loss: 0.4248376488685608\n",
            "Epoch: 22, Batch: 542, Batch Loss: 0.35811007022857666\n",
            "Epoch: 22, Batch: 543, Batch Loss: 0.6550337076187134\n",
            "Epoch: 22, Batch: 544, Batch Loss: 0.5491724014282227\n",
            "Epoch: 22, Batch: 545, Batch Loss: 0.456657737493515\n",
            "Epoch: 22, Batch: 546, Batch Loss: 0.40004363656044006\n",
            "Epoch: 22, Batch: 547, Batch Loss: 0.4378439784049988\n",
            "Epoch: 22, Batch: 548, Batch Loss: 0.3570135533809662\n",
            "Epoch: 22, Batch: 549, Batch Loss: 0.313491553068161\n",
            "Epoch: 22, Batch: 550, Batch Loss: 0.22075533866882324\n",
            "Epoch: 22, Batch: 551, Batch Loss: 0.3457585573196411\n",
            "Epoch: 22, Batch: 552, Batch Loss: 0.3227466642856598\n",
            "Epoch: 22, Batch: 553, Batch Loss: 0.4161511957645416\n",
            "Epoch: 22, Batch: 554, Batch Loss: 0.2501886785030365\n",
            "Epoch: 22, Batch: 555, Batch Loss: 0.24200744926929474\n",
            "Epoch: 22, Batch: 556, Batch Loss: 0.46473217010498047\n",
            "Epoch: 22, Batch: 557, Batch Loss: 0.2848605215549469\n",
            "Epoch: 22, Batch: 558, Batch Loss: 0.30421993136405945\n",
            "Epoch: 22, Batch: 559, Batch Loss: 0.34633466601371765\n",
            "Epoch: 22, Batch: 560, Batch Loss: 0.39950037002563477\n",
            "Epoch: 22, Batch: 561, Batch Loss: 0.3752945363521576\n",
            "Epoch: 22, Batch: 562, Batch Loss: 0.4023694694042206\n",
            "Epoch: 22, Batch: 563, Batch Loss: 0.3935689926147461\n",
            "Epoch: 22, Batch: 564, Batch Loss: 0.30349159240722656\n",
            "Epoch: 22, Batch: 565, Batch Loss: 0.46088847517967224\n",
            "Epoch: 22, Batch: 566, Batch Loss: 0.45317208766937256\n",
            "Epoch: 22, Batch: 567, Batch Loss: 0.3941480815410614\n",
            "Epoch: 22, Batch: 568, Batch Loss: 0.5338786840438843\n",
            "Epoch: 22, Batch: 569, Batch Loss: 0.3804296553134918\n",
            "Epoch: 22, Batch: 570, Batch Loss: 0.44734373688697815\n",
            "Epoch: 22, Batch: 571, Batch Loss: 0.4392210841178894\n",
            "Epoch: 22, Batch: 572, Batch Loss: 0.24047306180000305\n",
            "Epoch: 22, Batch: 573, Batch Loss: 0.33919912576675415\n",
            "Epoch: 22, Batch: 574, Batch Loss: 0.3770231008529663\n",
            "Epoch: 22, Batch: 575, Batch Loss: 0.5022980570793152\n",
            "Epoch: 22, Batch: 576, Batch Loss: 0.38919878005981445\n",
            "Epoch: 22, Batch: 577, Batch Loss: 0.3631156086921692\n",
            "Epoch: 22, Batch: 578, Batch Loss: 0.4851526618003845\n",
            "Epoch: 22, Batch: 579, Batch Loss: 0.4582536220550537\n",
            "Epoch: 22, Batch: 580, Batch Loss: 0.38399648666381836\n",
            "Epoch: 22, Batch: 581, Batch Loss: 0.286827027797699\n",
            "Epoch: 22, Batch: 582, Batch Loss: 0.37140440940856934\n",
            "Epoch: 22, Batch: 583, Batch Loss: 0.3535997271537781\n",
            "Epoch: 22, Batch: 584, Batch Loss: 0.35623839497566223\n",
            "Epoch: 22, Batch: 585, Batch Loss: 0.3281959593296051\n",
            "Epoch: 22, Batch: 586, Batch Loss: 0.2572309076786041\n",
            "Epoch: 22, Batch: 587, Batch Loss: 0.4347165524959564\n",
            "Epoch: 22, Batch: 588, Batch Loss: 0.5082306861877441\n",
            "Epoch: 22, Batch: 589, Batch Loss: 0.366899698972702\n",
            "Epoch: 22, Batch: 590, Batch Loss: 0.6289437413215637\n",
            "Epoch: 22, Batch: 591, Batch Loss: 0.4291273057460785\n",
            "Epoch: 22, Batch: 592, Batch Loss: 0.2685941755771637\n",
            "Epoch: 22, Batch: 593, Batch Loss: 0.48189008235931396\n",
            "Epoch: 22, Batch: 594, Batch Loss: 0.3872799873352051\n",
            "Epoch: 22, Batch: 595, Batch Loss: 0.43159377574920654\n",
            "Epoch: 22, Batch: 596, Batch Loss: 0.5602625608444214\n",
            "Epoch: 22, Batch: 597, Batch Loss: 0.5076603889465332\n",
            "Epoch: 22, Batch: 598, Batch Loss: 0.33742329478263855\n",
            "Epoch: 22, Batch: 599, Batch Loss: 0.3159526586532593\n",
            "Epoch: 22, Batch: 600, Batch Loss: 0.32111656665802\n",
            "Epoch: 22, Batch: 601, Batch Loss: 0.5901049971580505\n",
            "Epoch: 22, Batch: 602, Batch Loss: 0.3127594590187073\n",
            "Epoch: 22, Batch: 603, Batch Loss: 0.47836312651634216\n",
            "Epoch: 22, Batch: 604, Batch Loss: 0.29412293434143066\n",
            "Epoch: 22, Batch: 605, Batch Loss: 0.3685283064842224\n",
            "Epoch: 22, Batch: 606, Batch Loss: 0.19646520912647247\n",
            "Epoch: 22, Batch: 607, Batch Loss: 0.31638631224632263\n",
            "Epoch: 22, Batch: 608, Batch Loss: 0.27228742837905884\n",
            "Epoch: 22, Batch: 609, Batch Loss: 0.35477814078330994\n",
            "Epoch: 22, Batch: 610, Batch Loss: 0.5222502946853638\n",
            "Epoch: 22, Batch: 611, Batch Loss: 0.3064148724079132\n",
            "Epoch: 22, Batch: 612, Batch Loss: 0.25631245970726013\n",
            "Epoch: 22, Batch: 613, Batch Loss: 0.24400873482227325\n",
            "Epoch: 22, Batch: 614, Batch Loss: 0.464973509311676\n",
            "Epoch: 22, Batch: 615, Batch Loss: 0.5271245241165161\n",
            "Epoch: 22, Batch: 616, Batch Loss: 0.575984001159668\n",
            "Epoch: 22, Batch: 617, Batch Loss: 0.3160605728626251\n",
            "Epoch: 22, Batch: 618, Batch Loss: 0.2780495882034302\n",
            "Epoch: 22, Batch: 619, Batch Loss: 0.24832239747047424\n",
            "Epoch: 22, Batch: 620, Batch Loss: 0.2654549777507782\n",
            "Epoch: 22, Batch: 621, Batch Loss: 0.4762556552886963\n",
            "Epoch: 22, Batch: 622, Batch Loss: 0.22855423390865326\n",
            "Epoch: 22, Batch: 623, Batch Loss: 0.37336382269859314\n",
            "Epoch: 22, Batch: 624, Batch Loss: 0.3922951817512512\n",
            "Epoch: 22, Batch: 625, Batch Loss: 0.38011324405670166\n",
            "Epoch: 22, Batch: 626, Batch Loss: 0.5213440656661987\n",
            "Epoch: 22, Batch: 627, Batch Loss: 0.4703978896141052\n",
            "Epoch: 22, Batch: 628, Batch Loss: 0.35630548000335693\n",
            "Epoch: 22, Batch: 629, Batch Loss: 0.3362698554992676\n",
            "Epoch: 22, Batch: 630, Batch Loss: 0.5738521218299866\n",
            "Epoch: 22, Batch: 631, Batch Loss: 0.3508891463279724\n",
            "Epoch: 22, Batch: 632, Batch Loss: 0.3961339592933655\n",
            "Epoch: 22, Batch: 633, Batch Loss: 0.3675602078437805\n",
            "Epoch: 22, Batch: 634, Batch Loss: 0.5455676913261414\n",
            "Epoch: 22, Batch: 635, Batch Loss: 0.2599056363105774\n",
            "Epoch: 22, Batch: 636, Batch Loss: 0.5050584077835083\n",
            "Epoch: 22, Batch: 637, Batch Loss: 0.4672974646091461\n",
            "Epoch: 22, Batch: 638, Batch Loss: 0.5838572382926941\n",
            "Epoch: 22, Batch: 639, Batch Loss: 0.4060131311416626\n",
            "Epoch: 22, Batch: 640, Batch Loss: 0.4257483184337616\n",
            "Epoch: 22, Batch: 641, Batch Loss: 0.5143195986747742\n",
            "Epoch: 22, Batch: 642, Batch Loss: 0.3729515075683594\n",
            "Epoch: 22, Batch: 643, Batch Loss: 0.48133307695388794\n",
            "Epoch: 22, Batch: 644, Batch Loss: 0.41459038853645325\n",
            "Epoch: 22, Batch: 645, Batch Loss: 0.5418267846107483\n",
            "Epoch: 22, Batch: 646, Batch Loss: 0.45722049474716187\n",
            "Epoch: 22, Batch: 647, Batch Loss: 0.4009464383125305\n",
            "Epoch: 22, Batch: 648, Batch Loss: 0.27202075719833374\n",
            "Epoch: 22, Batch: 649, Batch Loss: 0.416132390499115\n",
            "Epoch: 22, Batch: 650, Batch Loss: 0.4492397904396057\n",
            "Epoch: 22, Batch: 651, Batch Loss: 0.25627851486206055\n",
            "Epoch: 22, Batch: 652, Batch Loss: 0.22793647646903992\n",
            "Epoch: 22, Batch: 653, Batch Loss: 0.6199022531509399\n",
            "Epoch: 22, Batch: 654, Batch Loss: 0.4945293664932251\n",
            "Epoch: 22, Batch: 655, Batch Loss: 0.5407651662826538\n",
            "Epoch: 22, Batch: 656, Batch Loss: 0.3690844178199768\n",
            "Epoch: 22, Batch: 657, Batch Loss: 0.4602402448654175\n",
            "Epoch: 22, Batch: 658, Batch Loss: 0.434491902589798\n",
            "Epoch: 22, Batch: 659, Batch Loss: 0.34303098917007446\n",
            "Epoch: 22, Batch: 660, Batch Loss: 0.38484737277030945\n",
            "Epoch: 22, Batch: 661, Batch Loss: 0.46821311116218567\n",
            "Epoch: 22, Batch: 662, Batch Loss: 0.311795711517334\n",
            "Epoch: 22, Batch: 663, Batch Loss: 0.37452244758605957\n",
            "Epoch: 22, Batch: 664, Batch Loss: 0.43519070744514465\n",
            "Epoch: 22, Batch: 665, Batch Loss: 0.5597670078277588\n",
            "Epoch: 22, Batch: 666, Batch Loss: 0.4688393473625183\n",
            "Epoch: 22, Batch: 667, Batch Loss: 0.5749660730361938\n",
            "Epoch: 22, Batch: 668, Batch Loss: 0.3876441419124603\n",
            "Epoch: 22, Batch: 669, Batch Loss: 0.3988984227180481\n",
            "Epoch: 22, Batch: 670, Batch Loss: 0.36007362604141235\n",
            "Epoch: 22, Batch: 671, Batch Loss: 0.42894062399864197\n",
            "Epoch: 22, Batch: 672, Batch Loss: 0.5511558651924133\n",
            "Epoch: 22, Batch: 673, Batch Loss: 0.20392508804798126\n",
            "Epoch: 22, Batch: 674, Batch Loss: 0.36456844210624695\n",
            "Epoch: 22, Batch: 675, Batch Loss: 0.3998165726661682\n",
            "Epoch: 22, Batch: 676, Batch Loss: 0.3017749786376953\n",
            "Epoch: 22, Batch: 677, Batch Loss: 0.2832810878753662\n",
            "Epoch: 22, Batch: 678, Batch Loss: 0.24934521317481995\n",
            "Epoch: 22, Batch: 679, Batch Loss: 0.2874950170516968\n",
            "Epoch: 22, Batch: 680, Batch Loss: 0.4033193588256836\n",
            "Epoch: 22, Batch: 681, Batch Loss: 0.5513923764228821\n",
            "Epoch: 22, Batch: 682, Batch Loss: 0.34039998054504395\n",
            "Epoch: 22, Batch: 683, Batch Loss: 0.3493425250053406\n",
            "Epoch: 22, Batch: 684, Batch Loss: 0.1363326609134674\n",
            "Epoch: 22, Batch: 685, Batch Loss: 0.33809131383895874\n",
            "Epoch: 22, Batch: 686, Batch Loss: 0.5338706970214844\n",
            "Epoch: 22, Batch: 687, Batch Loss: 0.3200596570968628\n",
            "Epoch: 22, Batch: 688, Batch Loss: 0.3670324683189392\n",
            "Epoch: 22, Batch: 689, Batch Loss: 0.3643256723880768\n",
            "Epoch: 22, Batch: 690, Batch Loss: 0.4090218245983124\n",
            "Epoch: 22, Batch: 691, Batch Loss: 0.39625275135040283\n",
            "Epoch: 22, Batch: 692, Batch Loss: 0.48290857672691345\n",
            "Epoch: 22, Batch: 693, Batch Loss: 0.4238843619823456\n",
            "Epoch: 22, Batch: 694, Batch Loss: 0.3441030979156494\n",
            "Epoch: 22, Batch: 695, Batch Loss: 0.3467693030834198\n",
            "Epoch: 22, Batch: 696, Batch Loss: 0.2888243794441223\n",
            "Epoch: 22, Batch: 697, Batch Loss: 0.4097791910171509\n",
            "Epoch: 22, Batch: 698, Batch Loss: 0.3357524871826172\n",
            "Epoch: 22, Batch: 699, Batch Loss: 0.38647934794425964\n",
            "Epoch: 22, Batch: 700, Batch Loss: 0.1451016515493393\n",
            "Epoch: 22, Batch: 701, Batch Loss: 0.664925217628479\n",
            "Epoch: 22, Batch: 702, Batch Loss: 0.38553398847579956\n",
            "Epoch: 22, Batch: 703, Batch Loss: 0.27287542819976807\n",
            "Epoch: 22, Batch: 704, Batch Loss: 0.38797834515571594\n",
            "Epoch: 22, Batch: 705, Batch Loss: 0.33593693375587463\n",
            "Epoch: 22, Batch: 706, Batch Loss: 0.27548015117645264\n",
            "Epoch: 22, Batch: 707, Batch Loss: 0.33496421575546265\n",
            "Epoch: 22, Batch: 708, Batch Loss: 0.3439297378063202\n",
            "Epoch: 22, Batch: 709, Batch Loss: 0.30383849143981934\n",
            "Epoch: 22, Batch: 710, Batch Loss: 0.40261539816856384\n",
            "Epoch: 22, Batch: 711, Batch Loss: 0.4096187651157379\n",
            "Epoch: 22, Batch: 712, Batch Loss: 0.45694705843925476\n",
            "Epoch: 22, Batch: 713, Batch Loss: 0.47915855050086975\n",
            "Epoch: 22, Batch: 714, Batch Loss: 0.40139877796173096\n",
            "Epoch: 22, Batch: 715, Batch Loss: 0.2864067554473877\n",
            "Epoch: 22, Batch: 716, Batch Loss: 0.255777508020401\n",
            "Epoch: 22, Batch: 717, Batch Loss: 0.3939523696899414\n",
            "Epoch: 22, Batch: 718, Batch Loss: 0.45347338914871216\n",
            "Epoch: 22, Batch: 719, Batch Loss: 0.33632487058639526\n",
            "Epoch: 22, Batch: 720, Batch Loss: 0.42353999614715576\n",
            "Epoch: 22, Batch: 721, Batch Loss: 0.38300251960754395\n",
            "Epoch: 22, Batch: 722, Batch Loss: 0.4063231348991394\n",
            "Epoch: 22, Batch: 723, Batch Loss: 0.3741627037525177\n",
            "Epoch: 22, Batch: 724, Batch Loss: 0.346772164106369\n",
            "Epoch: 22, Batch: 725, Batch Loss: 0.5792974233627319\n",
            "Epoch: 22, Batch: 726, Batch Loss: 0.35136544704437256\n",
            "Epoch: 22, Batch: 727, Batch Loss: 0.44184666872024536\n",
            "Epoch: 22, Batch: 728, Batch Loss: 0.3076601028442383\n",
            "Epoch: 22, Batch: 729, Batch Loss: 0.3040323257446289\n",
            "Epoch: 22, Batch: 730, Batch Loss: 0.4079563021659851\n",
            "Epoch: 22, Batch: 731, Batch Loss: 0.3705410659313202\n",
            "Epoch: 22, Batch: 732, Batch Loss: 0.3107340633869171\n",
            "Epoch: 22, Batch: 733, Batch Loss: 0.4397783577442169\n",
            "Epoch: 22, Batch: 734, Batch Loss: 0.40749529004096985\n",
            "Epoch: 22, Batch: 735, Batch Loss: 0.5409385561943054\n",
            "Epoch: 22, Batch: 736, Batch Loss: 0.5163111686706543\n",
            "Epoch: 22, Batch: 737, Batch Loss: 0.34732669591903687\n",
            "Epoch: 22, Batch: 738, Batch Loss: 0.31214070320129395\n",
            "Epoch: 22, Batch: 739, Batch Loss: 0.3408331573009491\n",
            "Epoch: 22, Batch: 740, Batch Loss: 0.2584231495857239\n",
            "Epoch: 22, Batch: 741, Batch Loss: 0.37110602855682373\n",
            "Epoch: 22, Batch: 742, Batch Loss: 0.3690570294857025\n",
            "Epoch: 22, Batch: 743, Batch Loss: 0.30383461713790894\n",
            "Epoch: 22, Batch: 744, Batch Loss: 0.6081225872039795\n",
            "Epoch: 22, Batch: 745, Batch Loss: 0.5073672533035278\n",
            "Epoch: 22, Batch: 746, Batch Loss: 0.5622497200965881\n",
            "Epoch: 22, Batch: 747, Batch Loss: 0.4250269830226898\n",
            "Epoch: 22, Batch: 748, Batch Loss: 0.3371078073978424\n",
            "Epoch: 22, Batch: 749, Batch Loss: 0.47426214814186096\n",
            "Epoch: 22, Batch: 750, Batch Loss: 0.42138999700546265\n",
            "Epoch: 22, Batch: 751, Batch Loss: 0.4051242470741272\n",
            "Epoch: 22, Batch: 752, Batch Loss: 0.3839734196662903\n",
            "Epoch: 22, Batch: 753, Batch Loss: 0.3875398635864258\n",
            "Epoch: 22, Batch: 754, Batch Loss: 0.4617311954498291\n",
            "Epoch: 22, Batch: 755, Batch Loss: 0.3696649968624115\n",
            "Epoch: 22, Batch: 756, Batch Loss: 0.363991916179657\n",
            "Epoch: 22, Batch: 757, Batch Loss: 0.3583718538284302\n",
            "Epoch: 22, Batch: 758, Batch Loss: 0.3120298683643341\n",
            "Epoch: 22, Batch: 759, Batch Loss: 0.30156680941581726\n",
            "Epoch: 22, Batch: 760, Batch Loss: 0.4578556418418884\n",
            "Epoch: 22, Batch: 761, Batch Loss: 0.5574464797973633\n",
            "Epoch: 22, Batch: 762, Batch Loss: 0.48314642906188965\n",
            "Epoch: 22, Batch: 763, Batch Loss: 0.43937933444976807\n",
            "Epoch: 22, Batch: 764, Batch Loss: 0.41618794202804565\n",
            "Epoch: 22, Batch: 765, Batch Loss: 0.2878296673297882\n",
            "Epoch: 22, Batch: 766, Batch Loss: 0.3409707546234131\n",
            "Epoch: 22, Batch: 767, Batch Loss: 0.4028303623199463\n",
            "Epoch: 22, Batch: 768, Batch Loss: 0.3640589714050293\n",
            "Epoch: 22, Batch: 769, Batch Loss: 0.28726404905319214\n",
            "Epoch: 22, Batch: 770, Batch Loss: 0.396109938621521\n",
            "Epoch: 22, Batch: 771, Batch Loss: 0.25556856393814087\n",
            "Epoch: 22, Batch: 772, Batch Loss: 0.39299464225769043\n",
            "Epoch: 22, Batch: 773, Batch Loss: 0.2911075949668884\n",
            "Epoch: 22, Batch: 774, Batch Loss: 0.34192731976509094\n",
            "Epoch: 22, Batch: 775, Batch Loss: 0.3846926987171173\n",
            "Epoch: 22, Batch: 776, Batch Loss: 0.2651006579399109\n",
            "Epoch: 22, Batch: 777, Batch Loss: 0.37544792890548706\n",
            "Epoch: 22, Batch: 778, Batch Loss: 0.3175370991230011\n",
            "Epoch: 22, Batch: 779, Batch Loss: 0.22774328291416168\n",
            "Epoch: 22, Batch: 780, Batch Loss: 0.3808194696903229\n",
            "Epoch: 22, Batch: 781, Batch Loss: 0.3711380362510681\n",
            "Epoch: 22, Batch: 782, Batch Loss: 0.3947807550430298\n",
            "Epoch: 22, Batch: 783, Batch Loss: 0.43865615129470825\n",
            "Epoch: 22, Batch: 784, Batch Loss: 0.31529325246810913\n",
            "Epoch: 22, Batch: 785, Batch Loss: 0.2734166979789734\n",
            "Epoch: 22, Batch: 786, Batch Loss: 0.5373855829238892\n",
            "Epoch: 22, Batch: 787, Batch Loss: 0.2508396804332733\n",
            "Epoch: 22, Batch: 788, Batch Loss: 0.4917539656162262\n",
            "Epoch: 22, Batch: 789, Batch Loss: 0.26879560947418213\n",
            "Epoch: 22, Batch: 790, Batch Loss: 0.30140772461891174\n",
            "Epoch: 22, Batch: 791, Batch Loss: 0.3989976644515991\n",
            "Epoch: 22, Batch: 792, Batch Loss: 0.47278571128845215\n",
            "Epoch: 22, Batch: 793, Batch Loss: 0.4489520192146301\n",
            "Epoch: 22, Batch: 794, Batch Loss: 0.49974337220191956\n",
            "Epoch: 22, Batch: 795, Batch Loss: 0.2947348654270172\n",
            "Epoch: 22, Batch: 796, Batch Loss: 0.46263790130615234\n",
            "Epoch: 22, Batch: 797, Batch Loss: 0.36985576152801514\n",
            "Epoch: 22, Batch: 798, Batch Loss: 0.3861818015575409\n",
            "Epoch: 22, Batch: 799, Batch Loss: 0.2334568053483963\n",
            "Epoch: 22, Batch: 800, Batch Loss: 0.2445257306098938\n",
            "Epoch: 22, Batch: 801, Batch Loss: 0.2535334527492523\n",
            "Epoch: 22, Batch: 802, Batch Loss: 0.5562140345573425\n",
            "Epoch: 22, Batch: 803, Batch Loss: 0.5654570460319519\n",
            "Epoch: 22, Batch: 804, Batch Loss: 0.38157105445861816\n",
            "Epoch: 22, Batch: 805, Batch Loss: 0.46870946884155273\n",
            "Epoch: 22, Batch: 806, Batch Loss: 0.2977122664451599\n",
            "Epoch: 22, Batch: 807, Batch Loss: 0.34255605936050415\n",
            "Epoch: 22, Batch: 808, Batch Loss: 0.30324065685272217\n",
            "Epoch: 22, Batch: 809, Batch Loss: 0.4070284068584442\n",
            "Epoch: 22, Batch: 810, Batch Loss: 0.3448737859725952\n",
            "Epoch: 22, Batch: 811, Batch Loss: 0.3338206112384796\n",
            "Epoch: 22, Batch: 812, Batch Loss: 0.5073831677436829\n",
            "Epoch: 22, Batch: 813, Batch Loss: 0.32064440846443176\n",
            "Epoch: 22, Batch: 814, Batch Loss: 0.26748597621917725\n",
            "Epoch: 22, Batch: 815, Batch Loss: 0.40626153349876404\n",
            "Epoch: 22, Batch: 816, Batch Loss: 0.49665069580078125\n",
            "Epoch: 22, Batch: 817, Batch Loss: 0.23700477182865143\n",
            "Epoch: 22, Batch: 818, Batch Loss: 0.3746200203895569\n",
            "Epoch: 22, Batch: 819, Batch Loss: 0.4414323568344116\n",
            "Epoch: 22, Batch: 820, Batch Loss: 0.3421904444694519\n",
            "Epoch: 22, Batch: 821, Batch Loss: 0.41877657175064087\n",
            "Epoch: 22, Batch: 822, Batch Loss: 0.4137929379940033\n",
            "Epoch: 22, Batch: 823, Batch Loss: 0.46536552906036377\n",
            "Epoch: 22, Batch: 824, Batch Loss: 0.31598103046417236\n",
            "Epoch: 22, Batch: 825, Batch Loss: 0.27407220005989075\n",
            "Epoch: 22, Batch: 826, Batch Loss: 0.43206891417503357\n",
            "Epoch: 22, Batch: 827, Batch Loss: 0.524867594242096\n",
            "Epoch: 22, Batch: 828, Batch Loss: 0.3698296546936035\n",
            "Epoch: 22, Batch: 829, Batch Loss: 0.2685084939002991\n",
            "Epoch: 22, Batch: 830, Batch Loss: 0.39960914850234985\n",
            "Epoch: 22, Batch: 831, Batch Loss: 0.3498065173625946\n",
            "Epoch: 22, Batch: 832, Batch Loss: 0.3846483528614044\n",
            "Epoch: 22, Batch: 833, Batch Loss: 0.3724605143070221\n",
            "Epoch: 22, Batch: 834, Batch Loss: 0.405026912689209\n",
            "Epoch: 22, Batch: 835, Batch Loss: 0.35722675919532776\n",
            "Epoch: 22, Batch: 836, Batch Loss: 0.37215110659599304\n",
            "Epoch: 22, Batch: 837, Batch Loss: 0.2339848130941391\n",
            "Epoch: 22, Batch: 838, Batch Loss: 0.2769719958305359\n",
            "Epoch: 22, Batch: 839, Batch Loss: 0.47910940647125244\n",
            "Epoch: 22, Batch: 840, Batch Loss: 0.23121410608291626\n",
            "Epoch: 22, Batch: 841, Batch Loss: 0.4965692162513733\n",
            "Epoch: 22, Batch: 842, Batch Loss: 0.49541908502578735\n",
            "Epoch: 22, Batch: 843, Batch Loss: 0.5354266166687012\n",
            "Epoch: 22, Batch: 844, Batch Loss: 0.3434542417526245\n",
            "Epoch: 22, Batch: 845, Batch Loss: 0.3611064851284027\n",
            "Epoch: 22, Batch: 846, Batch Loss: 0.444857120513916\n",
            "Epoch: 22, Batch: 847, Batch Loss: 0.26306483149528503\n",
            "Epoch: 22, Batch: 848, Batch Loss: 0.4536600112915039\n",
            "Epoch: 22, Batch: 849, Batch Loss: 0.397783488035202\n",
            "Epoch: 22, Batch: 850, Batch Loss: 0.3021688759326935\n",
            "Epoch: 22, Batch: 851, Batch Loss: 0.4779779613018036\n",
            "Epoch: 22, Batch: 852, Batch Loss: 0.52915358543396\n",
            "Epoch: 22, Batch: 853, Batch Loss: 0.3172744810581207\n",
            "Epoch: 22, Batch: 854, Batch Loss: 0.6357444524765015\n",
            "Epoch: 22, Batch: 855, Batch Loss: 0.3304990231990814\n",
            "Epoch: 22, Batch: 856, Batch Loss: 0.4030609726905823\n",
            "Epoch: 22, Batch: 857, Batch Loss: 0.3740735650062561\n",
            "Epoch: 22, Batch: 858, Batch Loss: 0.40939807891845703\n",
            "Epoch: 22, Batch: 859, Batch Loss: 0.45193880796432495\n",
            "Epoch: 22, Batch: 860, Batch Loss: 0.35204753279685974\n",
            "Epoch: 22, Batch: 861, Batch Loss: 0.49193766713142395\n",
            "Epoch: 22, Batch: 862, Batch Loss: 0.38417407870292664\n",
            "Epoch: 22, Batch: 863, Batch Loss: 0.5704836845397949\n",
            "Epoch: 22, Batch: 864, Batch Loss: 0.19670523703098297\n",
            "Epoch: 22, Batch: 865, Batch Loss: 0.4263731837272644\n",
            "Epoch: 22, Batch: 866, Batch Loss: 0.524451732635498\n",
            "Epoch: 22, Batch: 867, Batch Loss: 0.4577859044075012\n",
            "Epoch: 22, Batch: 868, Batch Loss: 0.3949051797389984\n",
            "Epoch: 22, Batch: 869, Batch Loss: 0.42314648628234863\n",
            "Epoch: 22, Batch: 870, Batch Loss: 0.4485965967178345\n",
            "Epoch: 22, Batch: 871, Batch Loss: 0.341061532497406\n",
            "Epoch: 22, Batch: 872, Batch Loss: 0.3418469727039337\n",
            "Epoch: 22, Batch: 873, Batch Loss: 0.3537483811378479\n",
            "Epoch: 22, Batch: 874, Batch Loss: 0.31390616297721863\n",
            "Epoch: 22, Batch: 875, Batch Loss: 0.34965837001800537\n",
            "Epoch: 22, Batch: 876, Batch Loss: 0.5057742595672607\n",
            "Epoch: 22, Batch: 877, Batch Loss: 0.3997717797756195\n",
            "Epoch: 22, Batch: 878, Batch Loss: 0.28957074880599976\n",
            "Epoch: 22, Batch: 879, Batch Loss: 0.5176152586936951\n",
            "Epoch: 22, Batch: 880, Batch Loss: 0.24805548787117004\n",
            "Epoch: 22, Batch: 881, Batch Loss: 0.37801820039749146\n",
            "Epoch: 22, Batch: 882, Batch Loss: 0.23194852471351624\n",
            "Epoch: 22, Batch: 883, Batch Loss: 0.7294744849205017\n",
            "Epoch: 22, Batch: 884, Batch Loss: 0.39065030217170715\n",
            "Epoch: 22, Batch: 885, Batch Loss: 0.41929611563682556\n",
            "Epoch: 22, Batch: 886, Batch Loss: 0.3612823784351349\n",
            "Epoch: 22, Batch: 887, Batch Loss: 0.32905513048171997\n",
            "Epoch: 22, Batch: 888, Batch Loss: 0.23859184980392456\n",
            "Epoch: 22, Batch: 889, Batch Loss: 0.31778886914253235\n",
            "Epoch: 22, Batch: 890, Batch Loss: 0.46445056796073914\n",
            "Epoch: 22, Batch: 891, Batch Loss: 0.3741926848888397\n",
            "Epoch: 22, Batch: 892, Batch Loss: 0.31685078144073486\n",
            "Epoch: 22, Batch: 893, Batch Loss: 0.3532853424549103\n",
            "Epoch: 22, Batch: 894, Batch Loss: 0.32310327887535095\n",
            "Epoch: 22, Batch: 895, Batch Loss: 0.3913542330265045\n",
            "Epoch: 22, Batch: 896, Batch Loss: 0.38444429636001587\n",
            "Epoch: 22, Batch: 897, Batch Loss: 0.3287276029586792\n",
            "Epoch: 22, Batch: 898, Batch Loss: 0.30439022183418274\n",
            "Epoch: 22, Batch: 899, Batch Loss: 0.4292052984237671\n",
            "Epoch: 22, Batch: 900, Batch Loss: 0.37618061900138855\n",
            "Epoch: 22, Batch: 901, Batch Loss: 0.20182183384895325\n",
            "Epoch: 22, Batch: 902, Batch Loss: 0.34620776772499084\n",
            "Epoch: 22, Batch: 903, Batch Loss: 0.5748913884162903\n",
            "Epoch: 22, Batch: 904, Batch Loss: 0.40985307097435\n",
            "Epoch: 22, Batch: 905, Batch Loss: 0.4195772111415863\n",
            "Epoch: 22, Batch: 906, Batch Loss: 0.2776798903942108\n",
            "Epoch: 22, Batch: 907, Batch Loss: 0.37606701254844666\n",
            "Epoch: 22, Batch: 908, Batch Loss: 0.26958295702934265\n",
            "Epoch: 22, Batch: 909, Batch Loss: 0.38194993138313293\n",
            "Epoch: 22, Batch: 910, Batch Loss: 0.2597712278366089\n",
            "Epoch: 22, Batch: 911, Batch Loss: 0.221350759267807\n",
            "Epoch: 22, Batch: 912, Batch Loss: 0.33857306838035583\n",
            "Epoch: 22, Batch: 913, Batch Loss: 0.3491978943347931\n",
            "Epoch: 22, Batch: 914, Batch Loss: 0.36375483870506287\n",
            "Epoch: 22, Batch: 915, Batch Loss: 0.3623962700366974\n",
            "Epoch: 22, Batch: 916, Batch Loss: 0.4130914807319641\n",
            "Epoch: 22, Batch: 917, Batch Loss: 0.4792305529117584\n",
            "Epoch: 22, Batch: 918, Batch Loss: 0.39369720220565796\n",
            "Epoch: 22, Batch: 919, Batch Loss: 0.3851050138473511\n",
            "Epoch: 22, Batch: 920, Batch Loss: 0.27207711338996887\n",
            "Epoch: 22, Batch: 921, Batch Loss: 0.35487842559814453\n",
            "Epoch: 22, Batch: 922, Batch Loss: 0.4939633011817932\n",
            "Epoch: 22, Batch: 923, Batch Loss: 0.48697349429130554\n",
            "Epoch: 22, Batch: 924, Batch Loss: 0.3676341474056244\n",
            "Epoch: 22, Batch: 925, Batch Loss: 0.46221688389778137\n",
            "Epoch: 22, Batch: 926, Batch Loss: 0.5586762428283691\n",
            "Epoch: 22, Batch: 927, Batch Loss: 0.4589806795120239\n",
            "Epoch: 22, Batch: 928, Batch Loss: 0.40941330790519714\n",
            "Epoch: 22, Batch: 929, Batch Loss: 0.22813521325588226\n",
            "Epoch: 22, Batch: 930, Batch Loss: 0.4821207821369171\n",
            "Epoch: 22, Batch: 931, Batch Loss: 0.45585930347442627\n",
            "Epoch: 22, Batch: 932, Batch Loss: 0.5730122327804565\n",
            "Epoch: 22, Batch: 933, Batch Loss: 0.2944178581237793\n",
            "Epoch: 22, Batch: 934, Batch Loss: 0.32556861639022827\n",
            "Epoch: 22, Batch: 935, Batch Loss: 0.6542694568634033\n",
            "Epoch: 22, Batch: 936, Batch Loss: 0.5002490282058716\n",
            "Epoch: 22, Batch: 937, Batch Loss: 0.2590135931968689\n",
            "Accuracy of train set: 0.8617166666666667\n",
            "Epoch: 22, Batch: 0, test Batch Loss: 0.48655474185943604\n",
            "Epoch: 22, Batch: 1, test Batch Loss: 0.37297675013542175\n",
            "Epoch: 22, Batch: 2, test Batch Loss: 0.44037988781929016\n",
            "Epoch: 22, Batch: 3, test Batch Loss: 0.44818931818008423\n",
            "Epoch: 22, Batch: 4, test Batch Loss: 0.5087092518806458\n",
            "Epoch: 22, Batch: 5, test Batch Loss: 0.4073669910430908\n",
            "Epoch: 22, Batch: 6, test Batch Loss: 0.30962303280830383\n",
            "Epoch: 22, Batch: 7, test Batch Loss: 0.5654125213623047\n",
            "Epoch: 22, Batch: 8, test Batch Loss: 0.437950998544693\n",
            "Epoch: 22, Batch: 9, test Batch Loss: 0.44361817836761475\n",
            "Epoch: 22, Batch: 10, test Batch Loss: 0.42799466848373413\n",
            "Epoch: 22, Batch: 11, test Batch Loss: 0.3592441976070404\n",
            "Epoch: 22, Batch: 12, test Batch Loss: 0.3050718307495117\n",
            "Epoch: 22, Batch: 13, test Batch Loss: 0.5284097194671631\n",
            "Epoch: 22, Batch: 14, test Batch Loss: 0.46833980083465576\n",
            "Epoch: 22, Batch: 15, test Batch Loss: 0.36824584007263184\n",
            "Epoch: 22, Batch: 16, test Batch Loss: 0.5220223665237427\n",
            "Epoch: 22, Batch: 17, test Batch Loss: 0.2916179597377777\n",
            "Epoch: 22, Batch: 18, test Batch Loss: 0.4517420828342438\n",
            "Epoch: 22, Batch: 19, test Batch Loss: 0.5327144265174866\n",
            "Epoch: 22, Batch: 20, test Batch Loss: 0.4178690016269684\n",
            "Epoch: 22, Batch: 21, test Batch Loss: 0.62476646900177\n",
            "Epoch: 22, Batch: 22, test Batch Loss: 0.3374992609024048\n",
            "Epoch: 22, Batch: 23, test Batch Loss: 0.4580589234828949\n",
            "Epoch: 22, Batch: 24, test Batch Loss: 0.5944021344184875\n",
            "Epoch: 22, Batch: 25, test Batch Loss: 0.48372143507003784\n",
            "Epoch: 22, Batch: 26, test Batch Loss: 0.39741283655166626\n",
            "Epoch: 22, Batch: 27, test Batch Loss: 0.36493852734565735\n",
            "Epoch: 22, Batch: 28, test Batch Loss: 0.508496105670929\n",
            "Epoch: 22, Batch: 29, test Batch Loss: 0.572550892829895\n",
            "Epoch: 22, Batch: 30, test Batch Loss: 0.5096418857574463\n",
            "Epoch: 22, Batch: 31, test Batch Loss: 0.3476552665233612\n",
            "Epoch: 22, Batch: 32, test Batch Loss: 0.42567113041877747\n",
            "Epoch: 22, Batch: 33, test Batch Loss: 0.3525090217590332\n",
            "Epoch: 22, Batch: 34, test Batch Loss: 0.7210079431533813\n",
            "Epoch: 22, Batch: 35, test Batch Loss: 0.3764204680919647\n",
            "Epoch: 22, Batch: 36, test Batch Loss: 0.4440353810787201\n",
            "Epoch: 22, Batch: 37, test Batch Loss: 0.2711912989616394\n",
            "Epoch: 22, Batch: 38, test Batch Loss: 0.2630487084388733\n",
            "Epoch: 22, Batch: 39, test Batch Loss: 0.3030548691749573\n",
            "Epoch: 22, Batch: 40, test Batch Loss: 0.5566054582595825\n",
            "Epoch: 22, Batch: 41, test Batch Loss: 0.3395485579967499\n",
            "Epoch: 22, Batch: 42, test Batch Loss: 0.33791854977607727\n",
            "Epoch: 22, Batch: 43, test Batch Loss: 0.37422192096710205\n",
            "Epoch: 22, Batch: 44, test Batch Loss: 0.45739221572875977\n",
            "Epoch: 22, Batch: 45, test Batch Loss: 0.44477471709251404\n",
            "Epoch: 22, Batch: 46, test Batch Loss: 0.8542129993438721\n",
            "Epoch: 22, Batch: 47, test Batch Loss: 0.25626489520072937\n",
            "Epoch: 22, Batch: 48, test Batch Loss: 0.42487573623657227\n",
            "Epoch: 22, Batch: 49, test Batch Loss: 0.3236294388771057\n",
            "Epoch: 22, Batch: 50, test Batch Loss: 0.2594570219516754\n",
            "Epoch: 22, Batch: 51, test Batch Loss: 0.5662450790405273\n",
            "Epoch: 22, Batch: 52, test Batch Loss: 0.5088989734649658\n",
            "Epoch: 22, Batch: 53, test Batch Loss: 0.4986060559749603\n",
            "Epoch: 22, Batch: 54, test Batch Loss: 0.4119192957878113\n",
            "Epoch: 22, Batch: 55, test Batch Loss: 0.6091507077217102\n",
            "Epoch: 22, Batch: 56, test Batch Loss: 0.5448019504547119\n",
            "Epoch: 22, Batch: 57, test Batch Loss: 0.3277566730976105\n",
            "Epoch: 22, Batch: 58, test Batch Loss: 0.5915954113006592\n",
            "Epoch: 22, Batch: 59, test Batch Loss: 0.5595271587371826\n",
            "Epoch: 22, Batch: 60, test Batch Loss: 0.4294818937778473\n",
            "Epoch: 22, Batch: 61, test Batch Loss: 0.44997549057006836\n",
            "Epoch: 22, Batch: 62, test Batch Loss: 0.5132219791412354\n",
            "Epoch: 22, Batch: 63, test Batch Loss: 0.7200610637664795\n",
            "Epoch: 22, Batch: 64, test Batch Loss: 0.4194639027118683\n",
            "Epoch: 22, Batch: 65, test Batch Loss: 0.34319886565208435\n",
            "Epoch: 22, Batch: 66, test Batch Loss: 0.5311061143875122\n",
            "Epoch: 22, Batch: 67, test Batch Loss: 0.44702568650245667\n",
            "Epoch: 22, Batch: 68, test Batch Loss: 0.40902817249298096\n",
            "Epoch: 22, Batch: 69, test Batch Loss: 0.3766513466835022\n",
            "Epoch: 22, Batch: 70, test Batch Loss: 0.4740528464317322\n",
            "Epoch: 22, Batch: 71, test Batch Loss: 0.6166258454322815\n",
            "Epoch: 22, Batch: 72, test Batch Loss: 0.37562546133995056\n",
            "Epoch: 22, Batch: 73, test Batch Loss: 0.5258347392082214\n",
            "Epoch: 22, Batch: 74, test Batch Loss: 0.4881192445755005\n",
            "Epoch: 22, Batch: 75, test Batch Loss: 0.35992881655693054\n",
            "Epoch: 22, Batch: 76, test Batch Loss: 0.37179821729660034\n",
            "Epoch: 22, Batch: 77, test Batch Loss: 0.5143365859985352\n",
            "Epoch: 22, Batch: 78, test Batch Loss: 0.5110868215560913\n",
            "Epoch: 22, Batch: 79, test Batch Loss: 0.49027219414711\n",
            "Epoch: 22, Batch: 80, test Batch Loss: 0.36446869373321533\n",
            "Epoch: 22, Batch: 81, test Batch Loss: 0.5002211332321167\n",
            "Epoch: 22, Batch: 82, test Batch Loss: 0.512509822845459\n",
            "Epoch: 22, Batch: 83, test Batch Loss: 0.412964403629303\n",
            "Epoch: 22, Batch: 84, test Batch Loss: 0.35047370195388794\n",
            "Epoch: 22, Batch: 85, test Batch Loss: 0.4698227643966675\n",
            "Epoch: 22, Batch: 86, test Batch Loss: 0.5740243792533875\n",
            "Epoch: 22, Batch: 87, test Batch Loss: 0.3447530269622803\n",
            "Epoch: 22, Batch: 88, test Batch Loss: 0.3554411232471466\n",
            "Epoch: 22, Batch: 89, test Batch Loss: 0.41251927614212036\n",
            "Epoch: 22, Batch: 90, test Batch Loss: 0.5493196845054626\n",
            "Epoch: 22, Batch: 91, test Batch Loss: 0.4663531482219696\n",
            "Epoch: 22, Batch: 92, test Batch Loss: 0.640119194984436\n",
            "Epoch: 22, Batch: 93, test Batch Loss: 0.2340087741613388\n",
            "Epoch: 22, Batch: 94, test Batch Loss: 0.3769090175628662\n",
            "Epoch: 22, Batch: 95, test Batch Loss: 0.5488972067832947\n",
            "Epoch: 22, Batch: 96, test Batch Loss: 0.17926909029483795\n",
            "Epoch: 22, Batch: 97, test Batch Loss: 0.6008820533752441\n",
            "Epoch: 22, Batch: 98, test Batch Loss: 0.4174308180809021\n",
            "Epoch: 22, Batch: 99, test Batch Loss: 0.3969619572162628\n",
            "Epoch: 22, Batch: 100, test Batch Loss: 0.39014750719070435\n",
            "Epoch: 22, Batch: 101, test Batch Loss: 0.4837186336517334\n",
            "Epoch: 22, Batch: 102, test Batch Loss: 0.384915828704834\n",
            "Epoch: 22, Batch: 103, test Batch Loss: 0.5310364365577698\n",
            "Epoch: 22, Batch: 104, test Batch Loss: 0.4500434994697571\n",
            "Epoch: 22, Batch: 105, test Batch Loss: 0.22490115463733673\n",
            "Epoch: 22, Batch: 106, test Batch Loss: 0.4397120475769043\n",
            "Epoch: 22, Batch: 107, test Batch Loss: 0.5494598150253296\n",
            "Epoch: 22, Batch: 108, test Batch Loss: 0.40252745151519775\n",
            "Epoch: 22, Batch: 109, test Batch Loss: 0.35275423526763916\n",
            "Epoch: 22, Batch: 110, test Batch Loss: 0.43895432353019714\n",
            "Epoch: 22, Batch: 111, test Batch Loss: 0.44131991267204285\n",
            "Epoch: 22, Batch: 112, test Batch Loss: 0.5493588447570801\n",
            "Epoch: 22, Batch: 113, test Batch Loss: 0.5042305588722229\n",
            "Epoch: 22, Batch: 114, test Batch Loss: 0.41059404611587524\n",
            "Epoch: 22, Batch: 115, test Batch Loss: 0.49409520626068115\n",
            "Epoch: 22, Batch: 116, test Batch Loss: 0.3214705288410187\n",
            "Epoch: 22, Batch: 117, test Batch Loss: 0.445164293050766\n",
            "Epoch: 22, Batch: 118, test Batch Loss: 0.343838632106781\n",
            "Epoch: 22, Batch: 119, test Batch Loss: 0.34618985652923584\n",
            "Epoch: 22, Batch: 120, test Batch Loss: 0.5153223276138306\n",
            "Epoch: 22, Batch: 121, test Batch Loss: 0.31913965940475464\n",
            "Epoch: 22, Batch: 122, test Batch Loss: 0.662115216255188\n",
            "Epoch: 22, Batch: 123, test Batch Loss: 0.3529624938964844\n",
            "Epoch: 22, Batch: 124, test Batch Loss: 0.606178343296051\n",
            "Epoch: 22, Batch: 125, test Batch Loss: 0.4225175082683563\n",
            "Epoch: 22, Batch: 126, test Batch Loss: 0.6363590359687805\n",
            "Epoch: 22, Batch: 127, test Batch Loss: 0.6641168594360352\n",
            "Epoch: 22, Batch: 128, test Batch Loss: 0.5800148844718933\n",
            "Epoch: 22, Batch: 129, test Batch Loss: 0.661025881767273\n",
            "Epoch: 22, Batch: 130, test Batch Loss: 0.5586056113243103\n",
            "Epoch: 22, Batch: 131, test Batch Loss: 0.4716565012931824\n",
            "Epoch: 22, Batch: 132, test Batch Loss: 0.4486164450645447\n",
            "Epoch: 22, Batch: 133, test Batch Loss: 0.46457844972610474\n",
            "Epoch: 22, Batch: 134, test Batch Loss: 0.2544337213039398\n",
            "Epoch: 22, Batch: 135, test Batch Loss: 0.47845637798309326\n",
            "Epoch: 22, Batch: 136, test Batch Loss: 0.6676292419433594\n",
            "Epoch: 22, Batch: 137, test Batch Loss: 0.3947674036026001\n",
            "Epoch: 22, Batch: 138, test Batch Loss: 0.5543472766876221\n",
            "Epoch: 22, Batch: 139, test Batch Loss: 0.22796811163425446\n",
            "Epoch: 22, Batch: 140, test Batch Loss: 0.5990865230560303\n",
            "Epoch: 22, Batch: 141, test Batch Loss: 0.2575371265411377\n",
            "Epoch: 22, Batch: 142, test Batch Loss: 0.27576035261154175\n",
            "Epoch: 22, Batch: 143, test Batch Loss: 0.42417633533477783\n",
            "Epoch: 22, Batch: 144, test Batch Loss: 0.6161935329437256\n",
            "Epoch: 22, Batch: 145, test Batch Loss: 0.5313512086868286\n",
            "Epoch: 22, Batch: 146, test Batch Loss: 0.34000658988952637\n",
            "Epoch: 22, Batch: 147, test Batch Loss: 0.3205777406692505\n",
            "Epoch: 22, Batch: 148, test Batch Loss: 0.5524358153343201\n",
            "Epoch: 22, Batch: 149, test Batch Loss: 0.6023992896080017\n",
            "Epoch: 22, Batch: 150, test Batch Loss: 0.620769202709198\n",
            "Epoch: 22, Batch: 151, test Batch Loss: 0.6292006969451904\n",
            "Epoch: 22, Batch: 152, test Batch Loss: 0.3271056115627289\n",
            "Epoch: 22, Batch: 153, test Batch Loss: 0.4149878919124603\n",
            "Epoch: 22, Batch: 154, test Batch Loss: 0.5577426552772522\n",
            "Epoch: 22, Batch: 155, test Batch Loss: 0.659905195236206\n",
            "Epoch: 22, Batch: 156, test Batch Loss: 0.3518226742744446\n",
            "Accuracy of test set: 0.8392\n",
            "Epoch 23/25 - Train Loss: 0.3934, Train Acc: 0.8617, Test Loss: 0.4546, Test Acc: 0.8392\n",
            "Epoch: 23, Batch: 0, Batch Loss: 0.456866055727005\n",
            "Epoch: 23, Batch: 1, Batch Loss: 0.4335021674633026\n",
            "Epoch: 23, Batch: 2, Batch Loss: 0.2868143320083618\n",
            "Epoch: 23, Batch: 3, Batch Loss: 0.35032957792282104\n",
            "Epoch: 23, Batch: 4, Batch Loss: 0.26625263690948486\n",
            "Epoch: 23, Batch: 5, Batch Loss: 0.4299142360687256\n",
            "Epoch: 23, Batch: 6, Batch Loss: 0.23918162286281586\n",
            "Epoch: 23, Batch: 7, Batch Loss: 0.33450156450271606\n",
            "Epoch: 23, Batch: 8, Batch Loss: 0.5185054540634155\n",
            "Epoch: 23, Batch: 9, Batch Loss: 0.31210923194885254\n",
            "Epoch: 23, Batch: 10, Batch Loss: 0.2630600929260254\n",
            "Epoch: 23, Batch: 11, Batch Loss: 0.7314592003822327\n",
            "Epoch: 23, Batch: 12, Batch Loss: 0.33178144693374634\n",
            "Epoch: 23, Batch: 13, Batch Loss: 0.3503722846508026\n",
            "Epoch: 23, Batch: 14, Batch Loss: 0.24883966147899628\n",
            "Epoch: 23, Batch: 15, Batch Loss: 0.37765228748321533\n",
            "Epoch: 23, Batch: 16, Batch Loss: 0.3218155801296234\n",
            "Epoch: 23, Batch: 17, Batch Loss: 0.4744884967803955\n",
            "Epoch: 23, Batch: 18, Batch Loss: 0.24035918712615967\n",
            "Epoch: 23, Batch: 19, Batch Loss: 0.5713358521461487\n",
            "Epoch: 23, Batch: 20, Batch Loss: 0.4137483537197113\n",
            "Epoch: 23, Batch: 21, Batch Loss: 0.3666965663433075\n",
            "Epoch: 23, Batch: 22, Batch Loss: 0.33258944749832153\n",
            "Epoch: 23, Batch: 23, Batch Loss: 0.23096661269664764\n",
            "Epoch: 23, Batch: 24, Batch Loss: 0.20790010690689087\n",
            "Epoch: 23, Batch: 25, Batch Loss: 0.4259093701839447\n",
            "Epoch: 23, Batch: 26, Batch Loss: 0.27390483021736145\n",
            "Epoch: 23, Batch: 27, Batch Loss: 0.532478928565979\n",
            "Epoch: 23, Batch: 28, Batch Loss: 0.5668419599533081\n",
            "Epoch: 23, Batch: 29, Batch Loss: 0.4028480052947998\n",
            "Epoch: 23, Batch: 30, Batch Loss: 0.26093852519989014\n",
            "Epoch: 23, Batch: 31, Batch Loss: 0.26363518834114075\n",
            "Epoch: 23, Batch: 32, Batch Loss: 0.6309694647789001\n",
            "Epoch: 23, Batch: 33, Batch Loss: 0.4464113116264343\n",
            "Epoch: 23, Batch: 34, Batch Loss: 0.3393579423427582\n",
            "Epoch: 23, Batch: 35, Batch Loss: 0.5241473317146301\n",
            "Epoch: 23, Batch: 36, Batch Loss: 0.441691517829895\n",
            "Epoch: 23, Batch: 37, Batch Loss: 0.2362074851989746\n",
            "Epoch: 23, Batch: 38, Batch Loss: 0.5108689069747925\n",
            "Epoch: 23, Batch: 39, Batch Loss: 0.2625548541545868\n",
            "Epoch: 23, Batch: 40, Batch Loss: 0.6079809665679932\n",
            "Epoch: 23, Batch: 41, Batch Loss: 0.32465195655822754\n",
            "Epoch: 23, Batch: 42, Batch Loss: 0.3832955062389374\n",
            "Epoch: 23, Batch: 43, Batch Loss: 0.3035934865474701\n",
            "Epoch: 23, Batch: 44, Batch Loss: 0.2931605577468872\n",
            "Epoch: 23, Batch: 45, Batch Loss: 0.427937775850296\n",
            "Epoch: 23, Batch: 46, Batch Loss: 0.3610672950744629\n",
            "Epoch: 23, Batch: 47, Batch Loss: 0.8126381635665894\n",
            "Epoch: 23, Batch: 48, Batch Loss: 0.39653104543685913\n",
            "Epoch: 23, Batch: 49, Batch Loss: 0.29201561212539673\n",
            "Epoch: 23, Batch: 50, Batch Loss: 0.4349200129508972\n",
            "Epoch: 23, Batch: 51, Batch Loss: 0.32792845368385315\n",
            "Epoch: 23, Batch: 52, Batch Loss: 0.33283114433288574\n",
            "Epoch: 23, Batch: 53, Batch Loss: 0.27569517493247986\n",
            "Epoch: 23, Batch: 54, Batch Loss: 0.28744134306907654\n",
            "Epoch: 23, Batch: 55, Batch Loss: 0.3632269501686096\n",
            "Epoch: 23, Batch: 56, Batch Loss: 0.5991266965866089\n",
            "Epoch: 23, Batch: 57, Batch Loss: 0.24331802129745483\n",
            "Epoch: 23, Batch: 58, Batch Loss: 0.6038082242012024\n",
            "Epoch: 23, Batch: 59, Batch Loss: 0.3595040440559387\n",
            "Epoch: 23, Batch: 60, Batch Loss: 0.3260415494441986\n",
            "Epoch: 23, Batch: 61, Batch Loss: 0.23521918058395386\n",
            "Epoch: 23, Batch: 62, Batch Loss: 0.2608090937137604\n",
            "Epoch: 23, Batch: 63, Batch Loss: 0.17079655826091766\n",
            "Epoch: 23, Batch: 64, Batch Loss: 0.3525325059890747\n",
            "Epoch: 23, Batch: 65, Batch Loss: 0.29080766439437866\n",
            "Epoch: 23, Batch: 66, Batch Loss: 0.6320484280586243\n",
            "Epoch: 23, Batch: 67, Batch Loss: 0.5062282681465149\n",
            "Epoch: 23, Batch: 68, Batch Loss: 0.26047688722610474\n",
            "Epoch: 23, Batch: 69, Batch Loss: 0.64674973487854\n",
            "Epoch: 23, Batch: 70, Batch Loss: 0.2328600436449051\n",
            "Epoch: 23, Batch: 71, Batch Loss: 0.517205536365509\n",
            "Epoch: 23, Batch: 72, Batch Loss: 0.24554912745952606\n",
            "Epoch: 23, Batch: 73, Batch Loss: 0.2657005786895752\n",
            "Epoch: 23, Batch: 74, Batch Loss: 0.2370745688676834\n",
            "Epoch: 23, Batch: 75, Batch Loss: 0.6701027750968933\n",
            "Epoch: 23, Batch: 76, Batch Loss: 0.4122036099433899\n",
            "Epoch: 23, Batch: 77, Batch Loss: 0.25266626477241516\n",
            "Epoch: 23, Batch: 78, Batch Loss: 0.41086581349372864\n",
            "Epoch: 23, Batch: 79, Batch Loss: 0.3969137668609619\n",
            "Epoch: 23, Batch: 80, Batch Loss: 0.4303762912750244\n",
            "Epoch: 23, Batch: 81, Batch Loss: 0.2992601990699768\n",
            "Epoch: 23, Batch: 82, Batch Loss: 0.4162665009498596\n",
            "Epoch: 23, Batch: 83, Batch Loss: 0.2900266945362091\n",
            "Epoch: 23, Batch: 84, Batch Loss: 0.4222310781478882\n",
            "Epoch: 23, Batch: 85, Batch Loss: 0.5052711963653564\n",
            "Epoch: 23, Batch: 86, Batch Loss: 0.33226144313812256\n",
            "Epoch: 23, Batch: 87, Batch Loss: 0.5859266519546509\n",
            "Epoch: 23, Batch: 88, Batch Loss: 0.4609900116920471\n",
            "Epoch: 23, Batch: 89, Batch Loss: 0.4340944290161133\n",
            "Epoch: 23, Batch: 90, Batch Loss: 0.22815605998039246\n",
            "Epoch: 23, Batch: 91, Batch Loss: 0.1765306144952774\n",
            "Epoch: 23, Batch: 92, Batch Loss: 0.2528075873851776\n",
            "Epoch: 23, Batch: 93, Batch Loss: 0.28937819600105286\n",
            "Epoch: 23, Batch: 94, Batch Loss: 0.42973577976226807\n",
            "Epoch: 23, Batch: 95, Batch Loss: 0.3719920217990875\n",
            "Epoch: 23, Batch: 96, Batch Loss: 0.25576090812683105\n",
            "Epoch: 23, Batch: 97, Batch Loss: 0.25782909989356995\n",
            "Epoch: 23, Batch: 98, Batch Loss: 0.32584136724472046\n",
            "Epoch: 23, Batch: 99, Batch Loss: 0.3781293034553528\n",
            "Epoch: 23, Batch: 100, Batch Loss: 0.3724091351032257\n",
            "Epoch: 23, Batch: 101, Batch Loss: 0.40406426787376404\n",
            "Epoch: 23, Batch: 102, Batch Loss: 0.4125419557094574\n",
            "Epoch: 23, Batch: 103, Batch Loss: 0.45894911885261536\n",
            "Epoch: 23, Batch: 104, Batch Loss: 0.5592867136001587\n",
            "Epoch: 23, Batch: 105, Batch Loss: 0.4362768828868866\n",
            "Epoch: 23, Batch: 106, Batch Loss: 0.347483366727829\n",
            "Epoch: 23, Batch: 107, Batch Loss: 0.4036139249801636\n",
            "Epoch: 23, Batch: 108, Batch Loss: 0.28550854325294495\n",
            "Epoch: 23, Batch: 109, Batch Loss: 0.4644888639450073\n",
            "Epoch: 23, Batch: 110, Batch Loss: 0.37736329436302185\n",
            "Epoch: 23, Batch: 111, Batch Loss: 0.25532540678977966\n",
            "Epoch: 23, Batch: 112, Batch Loss: 0.28707754611968994\n",
            "Epoch: 23, Batch: 113, Batch Loss: 0.48222994804382324\n",
            "Epoch: 23, Batch: 114, Batch Loss: 0.3799929618835449\n",
            "Epoch: 23, Batch: 115, Batch Loss: 0.282882422208786\n",
            "Epoch: 23, Batch: 116, Batch Loss: 0.436728835105896\n",
            "Epoch: 23, Batch: 117, Batch Loss: 0.4581024944782257\n",
            "Epoch: 23, Batch: 118, Batch Loss: 0.513950765132904\n",
            "Epoch: 23, Batch: 119, Batch Loss: 0.3805044889450073\n",
            "Epoch: 23, Batch: 120, Batch Loss: 0.3495987057685852\n",
            "Epoch: 23, Batch: 121, Batch Loss: 0.5414703488349915\n",
            "Epoch: 23, Batch: 122, Batch Loss: 0.40940630435943604\n",
            "Epoch: 23, Batch: 123, Batch Loss: 0.6222324967384338\n",
            "Epoch: 23, Batch: 124, Batch Loss: 0.3888266384601593\n",
            "Epoch: 23, Batch: 125, Batch Loss: 0.4627631604671478\n",
            "Epoch: 23, Batch: 126, Batch Loss: 0.4111280143260956\n",
            "Epoch: 23, Batch: 127, Batch Loss: 0.2786727547645569\n",
            "Epoch: 23, Batch: 128, Batch Loss: 0.3962046504020691\n",
            "Epoch: 23, Batch: 129, Batch Loss: 0.330633282661438\n",
            "Epoch: 23, Batch: 130, Batch Loss: 0.6123984456062317\n",
            "Epoch: 23, Batch: 131, Batch Loss: 0.5657159090042114\n",
            "Epoch: 23, Batch: 132, Batch Loss: 0.3243531286716461\n",
            "Epoch: 23, Batch: 133, Batch Loss: 0.31059372425079346\n",
            "Epoch: 23, Batch: 134, Batch Loss: 0.2980618476867676\n",
            "Epoch: 23, Batch: 135, Batch Loss: 0.38900166749954224\n",
            "Epoch: 23, Batch: 136, Batch Loss: 0.23158520460128784\n",
            "Epoch: 23, Batch: 137, Batch Loss: 0.27695563435554504\n",
            "Epoch: 23, Batch: 138, Batch Loss: 0.3477849066257477\n",
            "Epoch: 23, Batch: 139, Batch Loss: 0.425939679145813\n",
            "Epoch: 23, Batch: 140, Batch Loss: 0.2512637674808502\n",
            "Epoch: 23, Batch: 141, Batch Loss: 0.33081305027008057\n",
            "Epoch: 23, Batch: 142, Batch Loss: 0.7171200513839722\n",
            "Epoch: 23, Batch: 143, Batch Loss: 0.37293481826782227\n",
            "Epoch: 23, Batch: 144, Batch Loss: 0.31031113862991333\n",
            "Epoch: 23, Batch: 145, Batch Loss: 0.3474186956882477\n",
            "Epoch: 23, Batch: 146, Batch Loss: 0.34786456823349\n",
            "Epoch: 23, Batch: 147, Batch Loss: 0.29232072830200195\n",
            "Epoch: 23, Batch: 148, Batch Loss: 0.4990835189819336\n",
            "Epoch: 23, Batch: 149, Batch Loss: 0.466398149728775\n",
            "Epoch: 23, Batch: 150, Batch Loss: 0.36124077439308167\n",
            "Epoch: 23, Batch: 151, Batch Loss: 0.2734111547470093\n",
            "Epoch: 23, Batch: 152, Batch Loss: 0.23170113563537598\n",
            "Epoch: 23, Batch: 153, Batch Loss: 0.5562083721160889\n",
            "Epoch: 23, Batch: 154, Batch Loss: 0.3283926844596863\n",
            "Epoch: 23, Batch: 155, Batch Loss: 0.4190289378166199\n",
            "Epoch: 23, Batch: 156, Batch Loss: 0.5576971769332886\n",
            "Epoch: 23, Batch: 157, Batch Loss: 0.48718029260635376\n",
            "Epoch: 23, Batch: 158, Batch Loss: 0.35821375250816345\n",
            "Epoch: 23, Batch: 159, Batch Loss: 0.5676401853561401\n",
            "Epoch: 23, Batch: 160, Batch Loss: 0.6080241203308105\n",
            "Epoch: 23, Batch: 161, Batch Loss: 0.25299692153930664\n",
            "Epoch: 23, Batch: 162, Batch Loss: 0.2869345247745514\n",
            "Epoch: 23, Batch: 163, Batch Loss: 0.4938095808029175\n",
            "Epoch: 23, Batch: 164, Batch Loss: 0.34820836782455444\n",
            "Epoch: 23, Batch: 165, Batch Loss: 0.4089077115058899\n",
            "Epoch: 23, Batch: 166, Batch Loss: 0.43186259269714355\n",
            "Epoch: 23, Batch: 167, Batch Loss: 0.45051637291908264\n",
            "Epoch: 23, Batch: 168, Batch Loss: 0.4540749490261078\n",
            "Epoch: 23, Batch: 169, Batch Loss: 0.33737465739250183\n",
            "Epoch: 23, Batch: 170, Batch Loss: 0.41022375226020813\n",
            "Epoch: 23, Batch: 171, Batch Loss: 0.3581191301345825\n",
            "Epoch: 23, Batch: 172, Batch Loss: 0.35732534527778625\n",
            "Epoch: 23, Batch: 173, Batch Loss: 0.35519689321517944\n",
            "Epoch: 23, Batch: 174, Batch Loss: 0.46317556500434875\n",
            "Epoch: 23, Batch: 175, Batch Loss: 0.8358011245727539\n",
            "Epoch: 23, Batch: 176, Batch Loss: 0.3238963186740875\n",
            "Epoch: 23, Batch: 177, Batch Loss: 0.32123133540153503\n",
            "Epoch: 23, Batch: 178, Batch Loss: 0.4008241295814514\n",
            "Epoch: 23, Batch: 179, Batch Loss: 0.3348408341407776\n",
            "Epoch: 23, Batch: 180, Batch Loss: 0.4401915371417999\n",
            "Epoch: 23, Batch: 181, Batch Loss: 0.3049772083759308\n",
            "Epoch: 23, Batch: 182, Batch Loss: 0.4173637330532074\n",
            "Epoch: 23, Batch: 183, Batch Loss: 0.42332541942596436\n",
            "Epoch: 23, Batch: 184, Batch Loss: 0.22897371649742126\n",
            "Epoch: 23, Batch: 185, Batch Loss: 0.4561118185520172\n",
            "Epoch: 23, Batch: 186, Batch Loss: 0.41190052032470703\n",
            "Epoch: 23, Batch: 187, Batch Loss: 0.159166619181633\n",
            "Epoch: 23, Batch: 188, Batch Loss: 0.32057616114616394\n",
            "Epoch: 23, Batch: 189, Batch Loss: 0.4567026197910309\n",
            "Epoch: 23, Batch: 190, Batch Loss: 0.3271535634994507\n",
            "Epoch: 23, Batch: 191, Batch Loss: 0.27736735343933105\n",
            "Epoch: 23, Batch: 192, Batch Loss: 0.37871792912483215\n",
            "Epoch: 23, Batch: 193, Batch Loss: 0.2766426205635071\n",
            "Epoch: 23, Batch: 194, Batch Loss: 0.3638249635696411\n",
            "Epoch: 23, Batch: 195, Batch Loss: 0.2733914256095886\n",
            "Epoch: 23, Batch: 196, Batch Loss: 0.32199397683143616\n",
            "Epoch: 23, Batch: 197, Batch Loss: 0.6016352772712708\n",
            "Epoch: 23, Batch: 198, Batch Loss: 0.4375568628311157\n",
            "Epoch: 23, Batch: 199, Batch Loss: 0.36655354499816895\n",
            "Epoch: 23, Batch: 200, Batch Loss: 0.37910717725753784\n",
            "Epoch: 23, Batch: 201, Batch Loss: 0.3333171308040619\n",
            "Epoch: 23, Batch: 202, Batch Loss: 0.4405456483364105\n",
            "Epoch: 23, Batch: 203, Batch Loss: 0.5312725901603699\n",
            "Epoch: 23, Batch: 204, Batch Loss: 0.44208937883377075\n",
            "Epoch: 23, Batch: 205, Batch Loss: 0.4453074634075165\n",
            "Epoch: 23, Batch: 206, Batch Loss: 0.38656672835350037\n",
            "Epoch: 23, Batch: 207, Batch Loss: 0.26262950897216797\n",
            "Epoch: 23, Batch: 208, Batch Loss: 0.3970814645290375\n",
            "Epoch: 23, Batch: 209, Batch Loss: 0.3429458439350128\n",
            "Epoch: 23, Batch: 210, Batch Loss: 0.35709092020988464\n",
            "Epoch: 23, Batch: 211, Batch Loss: 0.34714338183403015\n",
            "Epoch: 23, Batch: 212, Batch Loss: 0.3248192071914673\n",
            "Epoch: 23, Batch: 213, Batch Loss: 0.5658406019210815\n",
            "Epoch: 23, Batch: 214, Batch Loss: 0.4285920262336731\n",
            "Epoch: 23, Batch: 215, Batch Loss: 0.31603267788887024\n",
            "Epoch: 23, Batch: 216, Batch Loss: 0.42540574073791504\n",
            "Epoch: 23, Batch: 217, Batch Loss: 0.3811618983745575\n",
            "Epoch: 23, Batch: 218, Batch Loss: 0.44571539759635925\n",
            "Epoch: 23, Batch: 219, Batch Loss: 0.4023975729942322\n",
            "Epoch: 23, Batch: 220, Batch Loss: 0.31058570742607117\n",
            "Epoch: 23, Batch: 221, Batch Loss: 0.4621961712837219\n",
            "Epoch: 23, Batch: 222, Batch Loss: 0.3658910393714905\n",
            "Epoch: 23, Batch: 223, Batch Loss: 0.4190390706062317\n",
            "Epoch: 23, Batch: 224, Batch Loss: 0.3844236135482788\n",
            "Epoch: 23, Batch: 225, Batch Loss: 0.29480451345443726\n",
            "Epoch: 23, Batch: 226, Batch Loss: 0.3666972517967224\n",
            "Epoch: 23, Batch: 227, Batch Loss: 0.3497903048992157\n",
            "Epoch: 23, Batch: 228, Batch Loss: 0.4053840637207031\n",
            "Epoch: 23, Batch: 229, Batch Loss: 0.4011807143688202\n",
            "Epoch: 23, Batch: 230, Batch Loss: 0.30700114369392395\n",
            "Epoch: 23, Batch: 231, Batch Loss: 0.21417272090911865\n",
            "Epoch: 23, Batch: 232, Batch Loss: 0.45089107751846313\n",
            "Epoch: 23, Batch: 233, Batch Loss: 0.27247878909111023\n",
            "Epoch: 23, Batch: 234, Batch Loss: 0.5119804739952087\n",
            "Epoch: 23, Batch: 235, Batch Loss: 0.5520817637443542\n",
            "Epoch: 23, Batch: 236, Batch Loss: 0.3474404811859131\n",
            "Epoch: 23, Batch: 237, Batch Loss: 0.3468171954154968\n",
            "Epoch: 23, Batch: 238, Batch Loss: 0.2904439866542816\n",
            "Epoch: 23, Batch: 239, Batch Loss: 0.3272051215171814\n",
            "Epoch: 23, Batch: 240, Batch Loss: 0.396724134683609\n",
            "Epoch: 23, Batch: 241, Batch Loss: 0.3816484212875366\n",
            "Epoch: 23, Batch: 242, Batch Loss: 0.4291057884693146\n",
            "Epoch: 23, Batch: 243, Batch Loss: 0.38318488001823425\n",
            "Epoch: 23, Batch: 244, Batch Loss: 0.40972158312797546\n",
            "Epoch: 23, Batch: 245, Batch Loss: 0.3234768211841583\n",
            "Epoch: 23, Batch: 246, Batch Loss: 0.5737224817276001\n",
            "Epoch: 23, Batch: 247, Batch Loss: 0.4062685966491699\n",
            "Epoch: 23, Batch: 248, Batch Loss: 0.3628285527229309\n",
            "Epoch: 23, Batch: 249, Batch Loss: 0.3006691336631775\n",
            "Epoch: 23, Batch: 250, Batch Loss: 0.33197078108787537\n",
            "Epoch: 23, Batch: 251, Batch Loss: 0.24469973146915436\n",
            "Epoch: 23, Batch: 252, Batch Loss: 0.2946473956108093\n",
            "Epoch: 23, Batch: 253, Batch Loss: 0.4247109293937683\n",
            "Epoch: 23, Batch: 254, Batch Loss: 0.5767742991447449\n",
            "Epoch: 23, Batch: 255, Batch Loss: 0.6095653176307678\n",
            "Epoch: 23, Batch: 256, Batch Loss: 0.23305726051330566\n",
            "Epoch: 23, Batch: 257, Batch Loss: 0.2771645486354828\n",
            "Epoch: 23, Batch: 258, Batch Loss: 0.34182459115982056\n",
            "Epoch: 23, Batch: 259, Batch Loss: 0.35885727405548096\n",
            "Epoch: 23, Batch: 260, Batch Loss: 0.46686887741088867\n",
            "Epoch: 23, Batch: 261, Batch Loss: 0.34791117906570435\n",
            "Epoch: 23, Batch: 262, Batch Loss: 0.3225899934768677\n",
            "Epoch: 23, Batch: 263, Batch Loss: 0.36423635482788086\n",
            "Epoch: 23, Batch: 264, Batch Loss: 0.5243159532546997\n",
            "Epoch: 23, Batch: 265, Batch Loss: 0.3469691276550293\n",
            "Epoch: 23, Batch: 266, Batch Loss: 0.3874994218349457\n",
            "Epoch: 23, Batch: 267, Batch Loss: 0.346523255109787\n",
            "Epoch: 23, Batch: 268, Batch Loss: 0.1671527922153473\n",
            "Epoch: 23, Batch: 269, Batch Loss: 0.3348367512226105\n",
            "Epoch: 23, Batch: 270, Batch Loss: 0.34532400965690613\n",
            "Epoch: 23, Batch: 271, Batch Loss: 0.5359339118003845\n",
            "Epoch: 23, Batch: 272, Batch Loss: 0.5103688836097717\n",
            "Epoch: 23, Batch: 273, Batch Loss: 0.5164006948471069\n",
            "Epoch: 23, Batch: 274, Batch Loss: 0.3416692614555359\n",
            "Epoch: 23, Batch: 275, Batch Loss: 0.3774670660495758\n",
            "Epoch: 23, Batch: 276, Batch Loss: 0.4221474528312683\n",
            "Epoch: 23, Batch: 277, Batch Loss: 0.27656829357147217\n",
            "Epoch: 23, Batch: 278, Batch Loss: 0.4099726676940918\n",
            "Epoch: 23, Batch: 279, Batch Loss: 0.41592341661453247\n",
            "Epoch: 23, Batch: 280, Batch Loss: 0.3702714145183563\n",
            "Epoch: 23, Batch: 281, Batch Loss: 0.46948447823524475\n",
            "Epoch: 23, Batch: 282, Batch Loss: 0.43182918429374695\n",
            "Epoch: 23, Batch: 283, Batch Loss: 0.48874643445014954\n",
            "Epoch: 23, Batch: 284, Batch Loss: 0.43322473764419556\n",
            "Epoch: 23, Batch: 285, Batch Loss: 0.355038046836853\n",
            "Epoch: 23, Batch: 286, Batch Loss: 0.6131036281585693\n",
            "Epoch: 23, Batch: 287, Batch Loss: 0.40265458822250366\n",
            "Epoch: 23, Batch: 288, Batch Loss: 0.5047765374183655\n",
            "Epoch: 23, Batch: 289, Batch Loss: 0.41179388761520386\n",
            "Epoch: 23, Batch: 290, Batch Loss: 0.27786439657211304\n",
            "Epoch: 23, Batch: 291, Batch Loss: 0.33644500374794006\n",
            "Epoch: 23, Batch: 292, Batch Loss: 0.302190363407135\n",
            "Epoch: 23, Batch: 293, Batch Loss: 0.32324671745300293\n",
            "Epoch: 23, Batch: 294, Batch Loss: 0.209714874625206\n",
            "Epoch: 23, Batch: 295, Batch Loss: 0.3657960593700409\n",
            "Epoch: 23, Batch: 296, Batch Loss: 0.25991469621658325\n",
            "Epoch: 23, Batch: 297, Batch Loss: 0.3064709007740021\n",
            "Epoch: 23, Batch: 298, Batch Loss: 0.4277430772781372\n",
            "Epoch: 23, Batch: 299, Batch Loss: 0.34285032749176025\n",
            "Epoch: 23, Batch: 300, Batch Loss: 0.4009993076324463\n",
            "Epoch: 23, Batch: 301, Batch Loss: 0.30201956629753113\n",
            "Epoch: 23, Batch: 302, Batch Loss: 0.3040924668312073\n",
            "Epoch: 23, Batch: 303, Batch Loss: 0.35926589369773865\n",
            "Epoch: 23, Batch: 304, Batch Loss: 0.4781476855278015\n",
            "Epoch: 23, Batch: 305, Batch Loss: 0.4082038998603821\n",
            "Epoch: 23, Batch: 306, Batch Loss: 0.40786194801330566\n",
            "Epoch: 23, Batch: 307, Batch Loss: 0.33004429936408997\n",
            "Epoch: 23, Batch: 308, Batch Loss: 0.3541955053806305\n",
            "Epoch: 23, Batch: 309, Batch Loss: 0.2454007863998413\n",
            "Epoch: 23, Batch: 310, Batch Loss: 0.4895823895931244\n",
            "Epoch: 23, Batch: 311, Batch Loss: 0.3539566993713379\n",
            "Epoch: 23, Batch: 312, Batch Loss: 0.2923189401626587\n",
            "Epoch: 23, Batch: 313, Batch Loss: 0.5740147829055786\n",
            "Epoch: 23, Batch: 314, Batch Loss: 0.4681148827075958\n",
            "Epoch: 23, Batch: 315, Batch Loss: 0.4297443926334381\n",
            "Epoch: 23, Batch: 316, Batch Loss: 0.2310374528169632\n",
            "Epoch: 23, Batch: 317, Batch Loss: 0.3057827353477478\n",
            "Epoch: 23, Batch: 318, Batch Loss: 0.3246288001537323\n",
            "Epoch: 23, Batch: 319, Batch Loss: 0.5396464467048645\n",
            "Epoch: 23, Batch: 320, Batch Loss: 0.3037327527999878\n",
            "Epoch: 23, Batch: 321, Batch Loss: 0.38260316848754883\n",
            "Epoch: 23, Batch: 322, Batch Loss: 0.39284855127334595\n",
            "Epoch: 23, Batch: 323, Batch Loss: 0.6446457505226135\n",
            "Epoch: 23, Batch: 324, Batch Loss: 0.5664768815040588\n",
            "Epoch: 23, Batch: 325, Batch Loss: 0.232254296541214\n",
            "Epoch: 23, Batch: 326, Batch Loss: 0.4221636950969696\n",
            "Epoch: 23, Batch: 327, Batch Loss: 0.3452826738357544\n",
            "Epoch: 23, Batch: 328, Batch Loss: 0.4194774031639099\n",
            "Epoch: 23, Batch: 329, Batch Loss: 0.25163596868515015\n",
            "Epoch: 23, Batch: 330, Batch Loss: 0.47501206398010254\n",
            "Epoch: 23, Batch: 331, Batch Loss: 0.5727049708366394\n",
            "Epoch: 23, Batch: 332, Batch Loss: 0.2931346893310547\n",
            "Epoch: 23, Batch: 333, Batch Loss: 0.42785295844078064\n",
            "Epoch: 23, Batch: 334, Batch Loss: 0.3467251658439636\n",
            "Epoch: 23, Batch: 335, Batch Loss: 0.5586326122283936\n",
            "Epoch: 23, Batch: 336, Batch Loss: 0.3607816696166992\n",
            "Epoch: 23, Batch: 337, Batch Loss: 0.3312193751335144\n",
            "Epoch: 23, Batch: 338, Batch Loss: 0.44821324944496155\n",
            "Epoch: 23, Batch: 339, Batch Loss: 0.4038715362548828\n",
            "Epoch: 23, Batch: 340, Batch Loss: 0.3705444931983948\n",
            "Epoch: 23, Batch: 341, Batch Loss: 0.5575547218322754\n",
            "Epoch: 23, Batch: 342, Batch Loss: 0.349809467792511\n",
            "Epoch: 23, Batch: 343, Batch Loss: 0.2880645990371704\n",
            "Epoch: 23, Batch: 344, Batch Loss: 0.437020480632782\n",
            "Epoch: 23, Batch: 345, Batch Loss: 0.46517935395240784\n",
            "Epoch: 23, Batch: 346, Batch Loss: 0.34814363718032837\n",
            "Epoch: 23, Batch: 347, Batch Loss: 0.2736070156097412\n",
            "Epoch: 23, Batch: 348, Batch Loss: 0.4180561304092407\n",
            "Epoch: 23, Batch: 349, Batch Loss: 0.39043039083480835\n",
            "Epoch: 23, Batch: 350, Batch Loss: 0.3835066258907318\n",
            "Epoch: 23, Batch: 351, Batch Loss: 0.3455095887184143\n",
            "Epoch: 23, Batch: 352, Batch Loss: 0.3369956314563751\n",
            "Epoch: 23, Batch: 353, Batch Loss: 0.2789961099624634\n",
            "Epoch: 23, Batch: 354, Batch Loss: 0.4480971097946167\n",
            "Epoch: 23, Batch: 355, Batch Loss: 0.4850434958934784\n",
            "Epoch: 23, Batch: 356, Batch Loss: 0.446552574634552\n",
            "Epoch: 23, Batch: 357, Batch Loss: 0.34631600975990295\n",
            "Epoch: 23, Batch: 358, Batch Loss: 0.4379209280014038\n",
            "Epoch: 23, Batch: 359, Batch Loss: 0.4956822991371155\n",
            "Epoch: 23, Batch: 360, Batch Loss: 0.31615349650382996\n",
            "Epoch: 23, Batch: 361, Batch Loss: 0.4690748155117035\n",
            "Epoch: 23, Batch: 362, Batch Loss: 0.3537404239177704\n",
            "Epoch: 23, Batch: 363, Batch Loss: 0.3802023231983185\n",
            "Epoch: 23, Batch: 364, Batch Loss: 0.3722940683364868\n",
            "Epoch: 23, Batch: 365, Batch Loss: 0.3161594271659851\n",
            "Epoch: 23, Batch: 366, Batch Loss: 0.23238028585910797\n",
            "Epoch: 23, Batch: 367, Batch Loss: 0.4361259937286377\n",
            "Epoch: 23, Batch: 368, Batch Loss: 0.48416781425476074\n",
            "Epoch: 23, Batch: 369, Batch Loss: 0.3523324131965637\n",
            "Epoch: 23, Batch: 370, Batch Loss: 0.33698657155036926\n",
            "Epoch: 23, Batch: 371, Batch Loss: 0.38824209570884705\n",
            "Epoch: 23, Batch: 372, Batch Loss: 0.28887248039245605\n",
            "Epoch: 23, Batch: 373, Batch Loss: 0.2760050892829895\n",
            "Epoch: 23, Batch: 374, Batch Loss: 0.4488571286201477\n",
            "Epoch: 23, Batch: 375, Batch Loss: 0.48845547437667847\n",
            "Epoch: 23, Batch: 376, Batch Loss: 0.4335496127605438\n",
            "Epoch: 23, Batch: 377, Batch Loss: 0.2924565374851227\n",
            "Epoch: 23, Batch: 378, Batch Loss: 0.42399775981903076\n",
            "Epoch: 23, Batch: 379, Batch Loss: 0.4789923131465912\n",
            "Epoch: 23, Batch: 380, Batch Loss: 0.3895226716995239\n",
            "Epoch: 23, Batch: 381, Batch Loss: 0.2806416153907776\n",
            "Epoch: 23, Batch: 382, Batch Loss: 0.24267534911632538\n",
            "Epoch: 23, Batch: 383, Batch Loss: 0.27395278215408325\n",
            "Epoch: 23, Batch: 384, Batch Loss: 0.42500191926956177\n",
            "Epoch: 23, Batch: 385, Batch Loss: 0.46578097343444824\n",
            "Epoch: 23, Batch: 386, Batch Loss: 0.5919163823127747\n",
            "Epoch: 23, Batch: 387, Batch Loss: 0.2820456624031067\n",
            "Epoch: 23, Batch: 388, Batch Loss: 0.41442644596099854\n",
            "Epoch: 23, Batch: 389, Batch Loss: 0.3989316523075104\n",
            "Epoch: 23, Batch: 390, Batch Loss: 0.23697584867477417\n",
            "Epoch: 23, Batch: 391, Batch Loss: 0.4370829463005066\n",
            "Epoch: 23, Batch: 392, Batch Loss: 0.43078720569610596\n",
            "Epoch: 23, Batch: 393, Batch Loss: 0.3586174249649048\n",
            "Epoch: 23, Batch: 394, Batch Loss: 0.36949726939201355\n",
            "Epoch: 23, Batch: 395, Batch Loss: 0.3168140649795532\n",
            "Epoch: 23, Batch: 396, Batch Loss: 0.5818465948104858\n",
            "Epoch: 23, Batch: 397, Batch Loss: 0.44642698764801025\n",
            "Epoch: 23, Batch: 398, Batch Loss: 0.3766281008720398\n",
            "Epoch: 23, Batch: 399, Batch Loss: 0.4546234607696533\n",
            "Epoch: 23, Batch: 400, Batch Loss: 0.3975977599620819\n",
            "Epoch: 23, Batch: 401, Batch Loss: 0.3323667645454407\n",
            "Epoch: 23, Batch: 402, Batch Loss: 0.7304128408432007\n",
            "Epoch: 23, Batch: 403, Batch Loss: 0.3286776542663574\n",
            "Epoch: 23, Batch: 404, Batch Loss: 0.24871587753295898\n",
            "Epoch: 23, Batch: 405, Batch Loss: 0.29557135701179504\n",
            "Epoch: 23, Batch: 406, Batch Loss: 0.3587011396884918\n",
            "Epoch: 23, Batch: 407, Batch Loss: 0.3019976317882538\n",
            "Epoch: 23, Batch: 408, Batch Loss: 0.3000442087650299\n",
            "Epoch: 23, Batch: 409, Batch Loss: 0.41864490509033203\n",
            "Epoch: 23, Batch: 410, Batch Loss: 0.6432819366455078\n",
            "Epoch: 23, Batch: 411, Batch Loss: 0.4322245121002197\n",
            "Epoch: 23, Batch: 412, Batch Loss: 0.3813808560371399\n",
            "Epoch: 23, Batch: 413, Batch Loss: 0.43537524342536926\n",
            "Epoch: 23, Batch: 414, Batch Loss: 0.5746145844459534\n",
            "Epoch: 23, Batch: 415, Batch Loss: 0.4144347310066223\n",
            "Epoch: 23, Batch: 416, Batch Loss: 0.28930288553237915\n",
            "Epoch: 23, Batch: 417, Batch Loss: 0.31647130846977234\n",
            "Epoch: 23, Batch: 418, Batch Loss: 0.4288683235645294\n",
            "Epoch: 23, Batch: 419, Batch Loss: 0.3782993257045746\n",
            "Epoch: 23, Batch: 420, Batch Loss: 0.31533825397491455\n",
            "Epoch: 23, Batch: 421, Batch Loss: 0.5247344374656677\n",
            "Epoch: 23, Batch: 422, Batch Loss: 0.3980579078197479\n",
            "Epoch: 23, Batch: 423, Batch Loss: 0.5938732028007507\n",
            "Epoch: 23, Batch: 424, Batch Loss: 0.5328965783119202\n",
            "Epoch: 23, Batch: 425, Batch Loss: 0.5063912868499756\n",
            "Epoch: 23, Batch: 426, Batch Loss: 0.4168618321418762\n",
            "Epoch: 23, Batch: 427, Batch Loss: 0.40536659955978394\n",
            "Epoch: 23, Batch: 428, Batch Loss: 0.38908278942108154\n",
            "Epoch: 23, Batch: 429, Batch Loss: 0.3914344310760498\n",
            "Epoch: 23, Batch: 430, Batch Loss: 0.5354357957839966\n",
            "Epoch: 23, Batch: 431, Batch Loss: 0.4901277720928192\n",
            "Epoch: 23, Batch: 432, Batch Loss: 0.42247191071510315\n",
            "Epoch: 23, Batch: 433, Batch Loss: 0.39320793747901917\n",
            "Epoch: 23, Batch: 434, Batch Loss: 0.37636345624923706\n",
            "Epoch: 23, Batch: 435, Batch Loss: 0.23120322823524475\n",
            "Epoch: 23, Batch: 436, Batch Loss: 0.34956541657447815\n",
            "Epoch: 23, Batch: 437, Batch Loss: 0.483271062374115\n",
            "Epoch: 23, Batch: 438, Batch Loss: 0.5613865852355957\n",
            "Epoch: 23, Batch: 439, Batch Loss: 0.4058939218521118\n",
            "Epoch: 23, Batch: 440, Batch Loss: 0.4462379217147827\n",
            "Epoch: 23, Batch: 441, Batch Loss: 0.32352036237716675\n",
            "Epoch: 23, Batch: 442, Batch Loss: 0.28224074840545654\n",
            "Epoch: 23, Batch: 443, Batch Loss: 0.3947961628437042\n",
            "Epoch: 23, Batch: 444, Batch Loss: 0.4771614074707031\n",
            "Epoch: 23, Batch: 445, Batch Loss: 0.30982840061187744\n",
            "Epoch: 23, Batch: 446, Batch Loss: 0.4250480532646179\n",
            "Epoch: 23, Batch: 447, Batch Loss: 0.3329424560070038\n",
            "Epoch: 23, Batch: 448, Batch Loss: 0.25175410509109497\n",
            "Epoch: 23, Batch: 449, Batch Loss: 0.34263333678245544\n",
            "Epoch: 23, Batch: 450, Batch Loss: 0.36259809136390686\n",
            "Epoch: 23, Batch: 451, Batch Loss: 0.46720582246780396\n",
            "Epoch: 23, Batch: 452, Batch Loss: 0.27299201488494873\n",
            "Epoch: 23, Batch: 453, Batch Loss: 0.304460346698761\n",
            "Epoch: 23, Batch: 454, Batch Loss: 0.42021653056144714\n",
            "Epoch: 23, Batch: 455, Batch Loss: 0.4342033863067627\n",
            "Epoch: 23, Batch: 456, Batch Loss: 0.42798835039138794\n",
            "Epoch: 23, Batch: 457, Batch Loss: 0.38573384284973145\n",
            "Epoch: 23, Batch: 458, Batch Loss: 0.4578937590122223\n",
            "Epoch: 23, Batch: 459, Batch Loss: 0.36847245693206787\n",
            "Epoch: 23, Batch: 460, Batch Loss: 0.47442322969436646\n",
            "Epoch: 23, Batch: 461, Batch Loss: 0.3812786042690277\n",
            "Epoch: 23, Batch: 462, Batch Loss: 0.23908813297748566\n",
            "Epoch: 23, Batch: 463, Batch Loss: 0.19435861706733704\n",
            "Epoch: 23, Batch: 464, Batch Loss: 0.25766992568969727\n",
            "Epoch: 23, Batch: 465, Batch Loss: 0.336681604385376\n",
            "Epoch: 23, Batch: 466, Batch Loss: 0.46411997079849243\n",
            "Epoch: 23, Batch: 467, Batch Loss: 0.4129723012447357\n",
            "Epoch: 23, Batch: 468, Batch Loss: 0.3269331157207489\n",
            "Epoch: 23, Batch: 469, Batch Loss: 0.564540445804596\n",
            "Epoch: 23, Batch: 470, Batch Loss: 0.4121783971786499\n",
            "Epoch: 23, Batch: 471, Batch Loss: 0.4015547037124634\n",
            "Epoch: 23, Batch: 472, Batch Loss: 0.44165077805519104\n",
            "Epoch: 23, Batch: 473, Batch Loss: 0.48627835512161255\n",
            "Epoch: 23, Batch: 474, Batch Loss: 0.451241135597229\n",
            "Epoch: 23, Batch: 475, Batch Loss: 0.3890361487865448\n",
            "Epoch: 23, Batch: 476, Batch Loss: 0.40641307830810547\n",
            "Epoch: 23, Batch: 477, Batch Loss: 0.3028743267059326\n",
            "Epoch: 23, Batch: 478, Batch Loss: 0.46334123611450195\n",
            "Epoch: 23, Batch: 479, Batch Loss: 0.33349302411079407\n",
            "Epoch: 23, Batch: 480, Batch Loss: 0.22162547707557678\n",
            "Epoch: 23, Batch: 481, Batch Loss: 0.25676292181015015\n",
            "Epoch: 23, Batch: 482, Batch Loss: 0.286114901304245\n",
            "Epoch: 23, Batch: 483, Batch Loss: 0.39700281620025635\n",
            "Epoch: 23, Batch: 484, Batch Loss: 0.20821477472782135\n",
            "Epoch: 23, Batch: 485, Batch Loss: 0.6050734519958496\n",
            "Epoch: 23, Batch: 486, Batch Loss: 0.205217644572258\n",
            "Epoch: 23, Batch: 487, Batch Loss: 0.35496169328689575\n",
            "Epoch: 23, Batch: 488, Batch Loss: 0.22854505479335785\n",
            "Epoch: 23, Batch: 489, Batch Loss: 0.4666140079498291\n",
            "Epoch: 23, Batch: 490, Batch Loss: 0.34018605947494507\n",
            "Epoch: 23, Batch: 491, Batch Loss: 0.3193396329879761\n",
            "Epoch: 23, Batch: 492, Batch Loss: 0.5310248732566833\n",
            "Epoch: 23, Batch: 493, Batch Loss: 0.2505428194999695\n",
            "Epoch: 23, Batch: 494, Batch Loss: 0.33822035789489746\n",
            "Epoch: 23, Batch: 495, Batch Loss: 0.6261530518531799\n",
            "Epoch: 23, Batch: 496, Batch Loss: 0.3425375819206238\n",
            "Epoch: 23, Batch: 497, Batch Loss: 0.3401464819908142\n",
            "Epoch: 23, Batch: 498, Batch Loss: 0.36659979820251465\n",
            "Epoch: 23, Batch: 499, Batch Loss: 0.30207714438438416\n",
            "Epoch: 23, Batch: 500, Batch Loss: 0.45217087864875793\n",
            "Epoch: 23, Batch: 501, Batch Loss: 0.266412615776062\n",
            "Epoch: 23, Batch: 502, Batch Loss: 0.314080148935318\n",
            "Epoch: 23, Batch: 503, Batch Loss: 0.5261480808258057\n",
            "Epoch: 23, Batch: 504, Batch Loss: 0.43682578206062317\n",
            "Epoch: 23, Batch: 505, Batch Loss: 0.43205931782722473\n",
            "Epoch: 23, Batch: 506, Batch Loss: 0.3843131363391876\n",
            "Epoch: 23, Batch: 507, Batch Loss: 0.5292765498161316\n",
            "Epoch: 23, Batch: 508, Batch Loss: 0.36593714356422424\n",
            "Epoch: 23, Batch: 509, Batch Loss: 0.27306443452835083\n",
            "Epoch: 23, Batch: 510, Batch Loss: 0.42854923009872437\n",
            "Epoch: 23, Batch: 511, Batch Loss: 0.44865021109580994\n",
            "Epoch: 23, Batch: 512, Batch Loss: 0.5297676920890808\n",
            "Epoch: 23, Batch: 513, Batch Loss: 0.4415980577468872\n",
            "Epoch: 23, Batch: 514, Batch Loss: 0.22497409582138062\n",
            "Epoch: 23, Batch: 515, Batch Loss: 0.4041556119918823\n",
            "Epoch: 23, Batch: 516, Batch Loss: 0.4736250638961792\n",
            "Epoch: 23, Batch: 517, Batch Loss: 0.4989134669303894\n",
            "Epoch: 23, Batch: 518, Batch Loss: 0.602768063545227\n",
            "Epoch: 23, Batch: 519, Batch Loss: 0.3061985671520233\n",
            "Epoch: 23, Batch: 520, Batch Loss: 0.3451005518436432\n",
            "Epoch: 23, Batch: 521, Batch Loss: 0.4051276743412018\n",
            "Epoch: 23, Batch: 522, Batch Loss: 0.3877875506877899\n",
            "Epoch: 23, Batch: 523, Batch Loss: 0.3250129818916321\n",
            "Epoch: 23, Batch: 524, Batch Loss: 0.4682561457157135\n",
            "Epoch: 23, Batch: 525, Batch Loss: 0.3553187847137451\n",
            "Epoch: 23, Batch: 526, Batch Loss: 0.3168259561061859\n",
            "Epoch: 23, Batch: 527, Batch Loss: 0.4054480493068695\n",
            "Epoch: 23, Batch: 528, Batch Loss: 0.37482669949531555\n",
            "Epoch: 23, Batch: 529, Batch Loss: 0.4423074424266815\n",
            "Epoch: 23, Batch: 530, Batch Loss: 0.47315189242362976\n",
            "Epoch: 23, Batch: 531, Batch Loss: 0.6127595901489258\n",
            "Epoch: 23, Batch: 532, Batch Loss: 0.41874977946281433\n",
            "Epoch: 23, Batch: 533, Batch Loss: 0.3144589960575104\n",
            "Epoch: 23, Batch: 534, Batch Loss: 0.569843053817749\n",
            "Epoch: 23, Batch: 535, Batch Loss: 0.4643282890319824\n",
            "Epoch: 23, Batch: 536, Batch Loss: 0.4852822422981262\n",
            "Epoch: 23, Batch: 537, Batch Loss: 0.38657569885253906\n",
            "Epoch: 23, Batch: 538, Batch Loss: 0.34749841690063477\n",
            "Epoch: 23, Batch: 539, Batch Loss: 0.37618446350097656\n",
            "Epoch: 23, Batch: 540, Batch Loss: 0.38879239559173584\n",
            "Epoch: 23, Batch: 541, Batch Loss: 0.369869589805603\n",
            "Epoch: 23, Batch: 542, Batch Loss: 0.36861687898635864\n",
            "Epoch: 23, Batch: 543, Batch Loss: 0.47336119413375854\n",
            "Epoch: 23, Batch: 544, Batch Loss: 0.45483753085136414\n",
            "Epoch: 23, Batch: 545, Batch Loss: 0.34728094935417175\n",
            "Epoch: 23, Batch: 546, Batch Loss: 0.3224794864654541\n",
            "Epoch: 23, Batch: 547, Batch Loss: 0.2741275429725647\n",
            "Epoch: 23, Batch: 548, Batch Loss: 0.43290746212005615\n",
            "Epoch: 23, Batch: 549, Batch Loss: 0.4730014204978943\n",
            "Epoch: 23, Batch: 550, Batch Loss: 0.3097456395626068\n",
            "Epoch: 23, Batch: 551, Batch Loss: 0.31574559211730957\n",
            "Epoch: 23, Batch: 552, Batch Loss: 0.5223231315612793\n",
            "Epoch: 23, Batch: 553, Batch Loss: 0.3996562659740448\n",
            "Epoch: 23, Batch: 554, Batch Loss: 0.5955023169517517\n",
            "Epoch: 23, Batch: 555, Batch Loss: 0.5614005327224731\n",
            "Epoch: 23, Batch: 556, Batch Loss: 0.31603458523750305\n",
            "Epoch: 23, Batch: 557, Batch Loss: 0.18752720952033997\n",
            "Epoch: 23, Batch: 558, Batch Loss: 0.4065149426460266\n",
            "Epoch: 23, Batch: 559, Batch Loss: 0.37314605712890625\n",
            "Epoch: 23, Batch: 560, Batch Loss: 0.4829782545566559\n",
            "Epoch: 23, Batch: 561, Batch Loss: 0.32561150193214417\n",
            "Epoch: 23, Batch: 562, Batch Loss: 0.3964850902557373\n",
            "Epoch: 23, Batch: 563, Batch Loss: 0.3414168953895569\n",
            "Epoch: 23, Batch: 564, Batch Loss: 0.28775155544281006\n",
            "Epoch: 23, Batch: 565, Batch Loss: 0.34322965145111084\n",
            "Epoch: 23, Batch: 566, Batch Loss: 0.3947772681713104\n",
            "Epoch: 23, Batch: 567, Batch Loss: 0.45021024346351624\n",
            "Epoch: 23, Batch: 568, Batch Loss: 0.4109213352203369\n",
            "Epoch: 23, Batch: 569, Batch Loss: 0.3929620385169983\n",
            "Epoch: 23, Batch: 570, Batch Loss: 0.28448978066444397\n",
            "Epoch: 23, Batch: 571, Batch Loss: 0.48661795258522034\n",
            "Epoch: 23, Batch: 572, Batch Loss: 0.4222278296947479\n",
            "Epoch: 23, Batch: 573, Batch Loss: 0.32670533657073975\n",
            "Epoch: 23, Batch: 574, Batch Loss: 0.32947877049446106\n",
            "Epoch: 23, Batch: 575, Batch Loss: 0.4206755459308624\n",
            "Epoch: 23, Batch: 576, Batch Loss: 0.28218305110931396\n",
            "Epoch: 23, Batch: 577, Batch Loss: 0.43257227540016174\n",
            "Epoch: 23, Batch: 578, Batch Loss: 0.3448735177516937\n",
            "Epoch: 23, Batch: 579, Batch Loss: 0.3475385904312134\n",
            "Epoch: 23, Batch: 580, Batch Loss: 0.27881669998168945\n",
            "Epoch: 23, Batch: 581, Batch Loss: 0.3197421431541443\n",
            "Epoch: 23, Batch: 582, Batch Loss: 0.4562033712863922\n",
            "Epoch: 23, Batch: 583, Batch Loss: 0.40947985649108887\n",
            "Epoch: 23, Batch: 584, Batch Loss: 0.3366025686264038\n",
            "Epoch: 23, Batch: 585, Batch Loss: 0.4104563593864441\n",
            "Epoch: 23, Batch: 586, Batch Loss: 0.45750781893730164\n",
            "Epoch: 23, Batch: 587, Batch Loss: 0.3883592188358307\n",
            "Epoch: 23, Batch: 588, Batch Loss: 0.27454572916030884\n",
            "Epoch: 23, Batch: 589, Batch Loss: 0.42628321051597595\n",
            "Epoch: 23, Batch: 590, Batch Loss: 0.4628036320209503\n",
            "Epoch: 23, Batch: 591, Batch Loss: 0.35416558384895325\n",
            "Epoch: 23, Batch: 592, Batch Loss: 0.3728068470954895\n",
            "Epoch: 23, Batch: 593, Batch Loss: 0.3224679231643677\n",
            "Epoch: 23, Batch: 594, Batch Loss: 0.2261485904455185\n",
            "Epoch: 23, Batch: 595, Batch Loss: 0.43684402108192444\n",
            "Epoch: 23, Batch: 596, Batch Loss: 0.436288058757782\n",
            "Epoch: 23, Batch: 597, Batch Loss: 0.41712629795074463\n",
            "Epoch: 23, Batch: 598, Batch Loss: 0.5880734920501709\n",
            "Epoch: 23, Batch: 599, Batch Loss: 0.25779277086257935\n",
            "Epoch: 23, Batch: 600, Batch Loss: 0.30525603890419006\n",
            "Epoch: 23, Batch: 601, Batch Loss: 0.49565669894218445\n",
            "Epoch: 23, Batch: 602, Batch Loss: 0.5644205808639526\n",
            "Epoch: 23, Batch: 603, Batch Loss: 0.46033668518066406\n",
            "Epoch: 23, Batch: 604, Batch Loss: 0.32876694202423096\n",
            "Epoch: 23, Batch: 605, Batch Loss: 0.3025771975517273\n",
            "Epoch: 23, Batch: 606, Batch Loss: 0.3518053889274597\n",
            "Epoch: 23, Batch: 607, Batch Loss: 0.24619945883750916\n",
            "Epoch: 23, Batch: 608, Batch Loss: 0.3251121938228607\n",
            "Epoch: 23, Batch: 609, Batch Loss: 0.42172926664352417\n",
            "Epoch: 23, Batch: 610, Batch Loss: 0.32415544986724854\n",
            "Epoch: 23, Batch: 611, Batch Loss: 0.37682098150253296\n",
            "Epoch: 23, Batch: 612, Batch Loss: 0.45595645904541016\n",
            "Epoch: 23, Batch: 613, Batch Loss: 0.3234538435935974\n",
            "Epoch: 23, Batch: 614, Batch Loss: 0.2605207562446594\n",
            "Epoch: 23, Batch: 615, Batch Loss: 0.4632985591888428\n",
            "Epoch: 23, Batch: 616, Batch Loss: 0.5592107772827148\n",
            "Epoch: 23, Batch: 617, Batch Loss: 0.3197578489780426\n",
            "Epoch: 23, Batch: 618, Batch Loss: 0.34138011932373047\n",
            "Epoch: 23, Batch: 619, Batch Loss: 0.3292332589626312\n",
            "Epoch: 23, Batch: 620, Batch Loss: 0.41490671038627625\n",
            "Epoch: 23, Batch: 621, Batch Loss: 0.21520578861236572\n",
            "Epoch: 23, Batch: 622, Batch Loss: 0.27302423119544983\n",
            "Epoch: 23, Batch: 623, Batch Loss: 0.29979076981544495\n",
            "Epoch: 23, Batch: 624, Batch Loss: 0.39882001280784607\n",
            "Epoch: 23, Batch: 625, Batch Loss: 0.22776120901107788\n",
            "Epoch: 23, Batch: 626, Batch Loss: 0.42421478033065796\n",
            "Epoch: 23, Batch: 627, Batch Loss: 0.35175296664237976\n",
            "Epoch: 23, Batch: 628, Batch Loss: 0.2523888349533081\n",
            "Epoch: 23, Batch: 629, Batch Loss: 0.511846661567688\n",
            "Epoch: 23, Batch: 630, Batch Loss: 0.45393234491348267\n",
            "Epoch: 23, Batch: 631, Batch Loss: 0.33316856622695923\n",
            "Epoch: 23, Batch: 632, Batch Loss: 0.45869114995002747\n",
            "Epoch: 23, Batch: 633, Batch Loss: 0.3983651101589203\n",
            "Epoch: 23, Batch: 634, Batch Loss: 0.31763800978660583\n",
            "Epoch: 23, Batch: 635, Batch Loss: 0.2983810305595398\n",
            "Epoch: 23, Batch: 636, Batch Loss: 0.26828593015670776\n",
            "Epoch: 23, Batch: 637, Batch Loss: 0.49011898040771484\n",
            "Epoch: 23, Batch: 638, Batch Loss: 0.35390788316726685\n",
            "Epoch: 23, Batch: 639, Batch Loss: 0.40711158514022827\n",
            "Epoch: 23, Batch: 640, Batch Loss: 0.5941205024719238\n",
            "Epoch: 23, Batch: 641, Batch Loss: 0.23899510502815247\n",
            "Epoch: 23, Batch: 642, Batch Loss: 0.27756887674331665\n",
            "Epoch: 23, Batch: 643, Batch Loss: 0.42055872082710266\n",
            "Epoch: 23, Batch: 644, Batch Loss: 0.49577653408050537\n",
            "Epoch: 23, Batch: 645, Batch Loss: 0.4401545226573944\n",
            "Epoch: 23, Batch: 646, Batch Loss: 0.2834736704826355\n",
            "Epoch: 23, Batch: 647, Batch Loss: 0.25642552971839905\n",
            "Epoch: 23, Batch: 648, Batch Loss: 0.484868586063385\n",
            "Epoch: 23, Batch: 649, Batch Loss: 0.49716678261756897\n",
            "Epoch: 23, Batch: 650, Batch Loss: 0.35350483655929565\n",
            "Epoch: 23, Batch: 651, Batch Loss: 0.29917699098587036\n",
            "Epoch: 23, Batch: 652, Batch Loss: 0.3312870264053345\n",
            "Epoch: 23, Batch: 653, Batch Loss: 0.3473515808582306\n",
            "Epoch: 23, Batch: 654, Batch Loss: 0.2785535454750061\n",
            "Epoch: 23, Batch: 655, Batch Loss: 0.4412480592727661\n",
            "Epoch: 23, Batch: 656, Batch Loss: 0.3869594931602478\n",
            "Epoch: 23, Batch: 657, Batch Loss: 0.4019758105278015\n",
            "Epoch: 23, Batch: 658, Batch Loss: 0.34407949447631836\n",
            "Epoch: 23, Batch: 659, Batch Loss: 0.2514001131057739\n",
            "Epoch: 23, Batch: 660, Batch Loss: 0.2621798515319824\n",
            "Epoch: 23, Batch: 661, Batch Loss: 0.5116028189659119\n",
            "Epoch: 23, Batch: 662, Batch Loss: 0.26035362482070923\n",
            "Epoch: 23, Batch: 663, Batch Loss: 0.27661997079849243\n",
            "Epoch: 23, Batch: 664, Batch Loss: 0.2985151410102844\n",
            "Epoch: 23, Batch: 665, Batch Loss: 0.3886491358280182\n",
            "Epoch: 23, Batch: 666, Batch Loss: 0.5669410824775696\n",
            "Epoch: 23, Batch: 667, Batch Loss: 0.2708803713321686\n",
            "Epoch: 23, Batch: 668, Batch Loss: 0.39208826422691345\n",
            "Epoch: 23, Batch: 669, Batch Loss: 0.3732340931892395\n",
            "Epoch: 23, Batch: 670, Batch Loss: 0.42669302225112915\n",
            "Epoch: 23, Batch: 671, Batch Loss: 0.3775063157081604\n",
            "Epoch: 23, Batch: 672, Batch Loss: 0.4994952380657196\n",
            "Epoch: 23, Batch: 673, Batch Loss: 0.40734463930130005\n",
            "Epoch: 23, Batch: 674, Batch Loss: 0.4042484164237976\n",
            "Epoch: 23, Batch: 675, Batch Loss: 0.5120149850845337\n",
            "Epoch: 23, Batch: 676, Batch Loss: 0.513076901435852\n",
            "Epoch: 23, Batch: 677, Batch Loss: 0.2625250518321991\n",
            "Epoch: 23, Batch: 678, Batch Loss: 0.28151369094848633\n",
            "Epoch: 23, Batch: 679, Batch Loss: 0.3317536413669586\n",
            "Epoch: 23, Batch: 680, Batch Loss: 0.48776599764823914\n",
            "Epoch: 23, Batch: 681, Batch Loss: 0.7446833848953247\n",
            "Epoch: 23, Batch: 682, Batch Loss: 0.633874237537384\n",
            "Epoch: 23, Batch: 683, Batch Loss: 0.3832066059112549\n",
            "Epoch: 23, Batch: 684, Batch Loss: 0.4811587929725647\n",
            "Epoch: 23, Batch: 685, Batch Loss: 0.2799266278743744\n",
            "Epoch: 23, Batch: 686, Batch Loss: 0.32485851645469666\n",
            "Epoch: 23, Batch: 687, Batch Loss: 0.2925034165382385\n",
            "Epoch: 23, Batch: 688, Batch Loss: 0.5281819105148315\n",
            "Epoch: 23, Batch: 689, Batch Loss: 0.2667364776134491\n",
            "Epoch: 23, Batch: 690, Batch Loss: 0.3504981994628906\n",
            "Epoch: 23, Batch: 691, Batch Loss: 0.5348107218742371\n",
            "Epoch: 23, Batch: 692, Batch Loss: 0.32419589161872864\n",
            "Epoch: 23, Batch: 693, Batch Loss: 0.2321455180644989\n",
            "Epoch: 23, Batch: 694, Batch Loss: 0.1858195960521698\n",
            "Epoch: 23, Batch: 695, Batch Loss: 0.5499134659767151\n",
            "Epoch: 23, Batch: 696, Batch Loss: 0.6046540141105652\n",
            "Epoch: 23, Batch: 697, Batch Loss: 0.44160497188568115\n",
            "Epoch: 23, Batch: 698, Batch Loss: 0.36812490224838257\n",
            "Epoch: 23, Batch: 699, Batch Loss: 0.3687000870704651\n",
            "Epoch: 23, Batch: 700, Batch Loss: 0.3190934956073761\n",
            "Epoch: 23, Batch: 701, Batch Loss: 0.21772500872612\n",
            "Epoch: 23, Batch: 702, Batch Loss: 0.2849516272544861\n",
            "Epoch: 23, Batch: 703, Batch Loss: 0.3799331784248352\n",
            "Epoch: 23, Batch: 704, Batch Loss: 0.32330816984176636\n",
            "Epoch: 23, Batch: 705, Batch Loss: 0.26908522844314575\n",
            "Epoch: 23, Batch: 706, Batch Loss: 0.40129050612449646\n",
            "Epoch: 23, Batch: 707, Batch Loss: 0.506537914276123\n",
            "Epoch: 23, Batch: 708, Batch Loss: 0.18201041221618652\n",
            "Epoch: 23, Batch: 709, Batch Loss: 0.17615194618701935\n",
            "Epoch: 23, Batch: 710, Batch Loss: 0.3756369352340698\n",
            "Epoch: 23, Batch: 711, Batch Loss: 0.5333055853843689\n",
            "Epoch: 23, Batch: 712, Batch Loss: 0.300701379776001\n",
            "Epoch: 23, Batch: 713, Batch Loss: 0.48931512236595154\n",
            "Epoch: 23, Batch: 714, Batch Loss: 0.300137460231781\n",
            "Epoch: 23, Batch: 715, Batch Loss: 0.2493208348751068\n",
            "Epoch: 23, Batch: 716, Batch Loss: 0.556694507598877\n",
            "Epoch: 23, Batch: 717, Batch Loss: 0.5763254165649414\n",
            "Epoch: 23, Batch: 718, Batch Loss: 0.2699012756347656\n",
            "Epoch: 23, Batch: 719, Batch Loss: 0.3903924226760864\n",
            "Epoch: 23, Batch: 720, Batch Loss: 0.3240954279899597\n",
            "Epoch: 23, Batch: 721, Batch Loss: 0.5595793128013611\n",
            "Epoch: 23, Batch: 722, Batch Loss: 0.5181944966316223\n",
            "Epoch: 23, Batch: 723, Batch Loss: 0.35338178277015686\n",
            "Epoch: 23, Batch: 724, Batch Loss: 0.364321231842041\n",
            "Epoch: 23, Batch: 725, Batch Loss: 0.37073785066604614\n",
            "Epoch: 23, Batch: 726, Batch Loss: 0.3565042018890381\n",
            "Epoch: 23, Batch: 727, Batch Loss: 0.5015720725059509\n",
            "Epoch: 23, Batch: 728, Batch Loss: 0.5173523426055908\n",
            "Epoch: 23, Batch: 729, Batch Loss: 0.33996930718421936\n",
            "Epoch: 23, Batch: 730, Batch Loss: 0.660751223564148\n",
            "Epoch: 23, Batch: 731, Batch Loss: 0.351288765668869\n",
            "Epoch: 23, Batch: 732, Batch Loss: 0.35288041830062866\n",
            "Epoch: 23, Batch: 733, Batch Loss: 0.3148963451385498\n",
            "Epoch: 23, Batch: 734, Batch Loss: 0.39196163415908813\n",
            "Epoch: 23, Batch: 735, Batch Loss: 0.4776647686958313\n",
            "Epoch: 23, Batch: 736, Batch Loss: 0.40323930978775024\n",
            "Epoch: 23, Batch: 737, Batch Loss: 0.5891609191894531\n",
            "Epoch: 23, Batch: 738, Batch Loss: 0.7370663285255432\n",
            "Epoch: 23, Batch: 739, Batch Loss: 0.421860933303833\n",
            "Epoch: 23, Batch: 740, Batch Loss: 0.3942004442214966\n",
            "Epoch: 23, Batch: 741, Batch Loss: 0.3619350790977478\n",
            "Epoch: 23, Batch: 742, Batch Loss: 0.31903696060180664\n",
            "Epoch: 23, Batch: 743, Batch Loss: 0.21849669516086578\n",
            "Epoch: 23, Batch: 744, Batch Loss: 0.26385340094566345\n",
            "Epoch: 23, Batch: 745, Batch Loss: 0.3278588056564331\n",
            "Epoch: 23, Batch: 746, Batch Loss: 0.32665085792541504\n",
            "Epoch: 23, Batch: 747, Batch Loss: 0.3472830355167389\n",
            "Epoch: 23, Batch: 748, Batch Loss: 0.32043352723121643\n",
            "Epoch: 23, Batch: 749, Batch Loss: 0.30614081025123596\n",
            "Epoch: 23, Batch: 750, Batch Loss: 0.3167206048965454\n",
            "Epoch: 23, Batch: 751, Batch Loss: 0.39729148149490356\n",
            "Epoch: 23, Batch: 752, Batch Loss: 0.32182663679122925\n",
            "Epoch: 23, Batch: 753, Batch Loss: 0.29472798109054565\n",
            "Epoch: 23, Batch: 754, Batch Loss: 0.4753471314907074\n",
            "Epoch: 23, Batch: 755, Batch Loss: 0.38836437463760376\n",
            "Epoch: 23, Batch: 756, Batch Loss: 0.37105509638786316\n",
            "Epoch: 23, Batch: 757, Batch Loss: 0.4353545904159546\n",
            "Epoch: 23, Batch: 758, Batch Loss: 0.337594598531723\n",
            "Epoch: 23, Batch: 759, Batch Loss: 0.38411495089530945\n",
            "Epoch: 23, Batch: 760, Batch Loss: 0.42142951488494873\n",
            "Epoch: 23, Batch: 761, Batch Loss: 0.3853563368320465\n",
            "Epoch: 23, Batch: 762, Batch Loss: 0.3709466755390167\n",
            "Epoch: 23, Batch: 763, Batch Loss: 0.30471813678741455\n",
            "Epoch: 23, Batch: 764, Batch Loss: 0.4255116581916809\n",
            "Epoch: 23, Batch: 765, Batch Loss: 0.3933209776878357\n",
            "Epoch: 23, Batch: 766, Batch Loss: 0.47564399242401123\n",
            "Epoch: 23, Batch: 767, Batch Loss: 0.7138628363609314\n",
            "Epoch: 23, Batch: 768, Batch Loss: 0.4310556948184967\n",
            "Epoch: 23, Batch: 769, Batch Loss: 0.30355340242385864\n",
            "Epoch: 23, Batch: 770, Batch Loss: 0.39479583501815796\n",
            "Epoch: 23, Batch: 771, Batch Loss: 0.3063764274120331\n",
            "Epoch: 23, Batch: 772, Batch Loss: 0.2708975076675415\n",
            "Epoch: 23, Batch: 773, Batch Loss: 0.2825489342212677\n",
            "Epoch: 23, Batch: 774, Batch Loss: 0.376666784286499\n",
            "Epoch: 23, Batch: 775, Batch Loss: 0.42548811435699463\n",
            "Epoch: 23, Batch: 776, Batch Loss: 0.3928068280220032\n",
            "Epoch: 23, Batch: 777, Batch Loss: 0.2590959370136261\n",
            "Epoch: 23, Batch: 778, Batch Loss: 0.40111789107322693\n",
            "Epoch: 23, Batch: 779, Batch Loss: 0.2852422893047333\n",
            "Epoch: 23, Batch: 780, Batch Loss: 0.3416712284088135\n",
            "Epoch: 23, Batch: 781, Batch Loss: 0.23077668249607086\n",
            "Epoch: 23, Batch: 782, Batch Loss: 0.15495504438877106\n",
            "Epoch: 23, Batch: 783, Batch Loss: 0.21228379011154175\n",
            "Epoch: 23, Batch: 784, Batch Loss: 0.2938741147518158\n",
            "Epoch: 23, Batch: 785, Batch Loss: 0.39596664905548096\n",
            "Epoch: 23, Batch: 786, Batch Loss: 0.33038365840911865\n",
            "Epoch: 23, Batch: 787, Batch Loss: 0.5841448903083801\n",
            "Epoch: 23, Batch: 788, Batch Loss: 0.3452553153038025\n",
            "Epoch: 23, Batch: 789, Batch Loss: 0.42564722895622253\n",
            "Epoch: 23, Batch: 790, Batch Loss: 0.31470364332199097\n",
            "Epoch: 23, Batch: 791, Batch Loss: 0.3462003767490387\n",
            "Epoch: 23, Batch: 792, Batch Loss: 0.37946173548698425\n",
            "Epoch: 23, Batch: 793, Batch Loss: 0.32474517822265625\n",
            "Epoch: 23, Batch: 794, Batch Loss: 0.30649393796920776\n",
            "Epoch: 23, Batch: 795, Batch Loss: 0.22997720539569855\n",
            "Epoch: 23, Batch: 796, Batch Loss: 0.27041491866111755\n",
            "Epoch: 23, Batch: 797, Batch Loss: 0.4635191559791565\n",
            "Epoch: 23, Batch: 798, Batch Loss: 0.413590669631958\n",
            "Epoch: 23, Batch: 799, Batch Loss: 0.35933351516723633\n",
            "Epoch: 23, Batch: 800, Batch Loss: 0.3664165735244751\n",
            "Epoch: 23, Batch: 801, Batch Loss: 0.4495002329349518\n",
            "Epoch: 23, Batch: 802, Batch Loss: 0.3814372420310974\n",
            "Epoch: 23, Batch: 803, Batch Loss: 0.5166803002357483\n",
            "Epoch: 23, Batch: 804, Batch Loss: 0.40921077132225037\n",
            "Epoch: 23, Batch: 805, Batch Loss: 0.3830990493297577\n",
            "Epoch: 23, Batch: 806, Batch Loss: 0.5659528374671936\n",
            "Epoch: 23, Batch: 807, Batch Loss: 0.47255778312683105\n",
            "Epoch: 23, Batch: 808, Batch Loss: 0.23410597443580627\n",
            "Epoch: 23, Batch: 809, Batch Loss: 0.27675727009773254\n",
            "Epoch: 23, Batch: 810, Batch Loss: 0.6096213459968567\n",
            "Epoch: 23, Batch: 811, Batch Loss: 0.44171690940856934\n",
            "Epoch: 23, Batch: 812, Batch Loss: 0.40842553973197937\n",
            "Epoch: 23, Batch: 813, Batch Loss: 0.4264492392539978\n",
            "Epoch: 23, Batch: 814, Batch Loss: 0.35877150297164917\n",
            "Epoch: 23, Batch: 815, Batch Loss: 0.5472442507743835\n",
            "Epoch: 23, Batch: 816, Batch Loss: 0.3275703489780426\n",
            "Epoch: 23, Batch: 817, Batch Loss: 0.41541212797164917\n",
            "Epoch: 23, Batch: 818, Batch Loss: 0.4099206030368805\n",
            "Epoch: 23, Batch: 819, Batch Loss: 0.3193970024585724\n",
            "Epoch: 23, Batch: 820, Batch Loss: 0.548120379447937\n",
            "Epoch: 23, Batch: 821, Batch Loss: 0.3136032819747925\n",
            "Epoch: 23, Batch: 822, Batch Loss: 0.2587455213069916\n",
            "Epoch: 23, Batch: 823, Batch Loss: 0.3988249599933624\n",
            "Epoch: 23, Batch: 824, Batch Loss: 0.26542407274246216\n",
            "Epoch: 23, Batch: 825, Batch Loss: 0.4768010377883911\n",
            "Epoch: 23, Batch: 826, Batch Loss: 0.3279664218425751\n",
            "Epoch: 23, Batch: 827, Batch Loss: 0.29125285148620605\n",
            "Epoch: 23, Batch: 828, Batch Loss: 0.24400746822357178\n",
            "Epoch: 23, Batch: 829, Batch Loss: 0.3349628150463104\n",
            "Epoch: 23, Batch: 830, Batch Loss: 0.32527297735214233\n",
            "Epoch: 23, Batch: 831, Batch Loss: 0.46627354621887207\n",
            "Epoch: 23, Batch: 832, Batch Loss: 0.4831506609916687\n",
            "Epoch: 23, Batch: 833, Batch Loss: 0.31061431765556335\n",
            "Epoch: 23, Batch: 834, Batch Loss: 0.30371716618537903\n",
            "Epoch: 23, Batch: 835, Batch Loss: 0.32022395730018616\n",
            "Epoch: 23, Batch: 836, Batch Loss: 0.3987569212913513\n",
            "Epoch: 23, Batch: 837, Batch Loss: 0.517694890499115\n",
            "Epoch: 23, Batch: 838, Batch Loss: 0.5165369510650635\n",
            "Epoch: 23, Batch: 839, Batch Loss: 0.3524675965309143\n",
            "Epoch: 23, Batch: 840, Batch Loss: 0.23565562069416046\n",
            "Epoch: 23, Batch: 841, Batch Loss: 0.3932473659515381\n",
            "Epoch: 23, Batch: 842, Batch Loss: 0.4109506607055664\n",
            "Epoch: 23, Batch: 843, Batch Loss: 0.43142426013946533\n",
            "Epoch: 23, Batch: 844, Batch Loss: 0.47010165452957153\n",
            "Epoch: 23, Batch: 845, Batch Loss: 0.4731191396713257\n",
            "Epoch: 23, Batch: 846, Batch Loss: 0.25681692361831665\n",
            "Epoch: 23, Batch: 847, Batch Loss: 0.3676266074180603\n",
            "Epoch: 23, Batch: 848, Batch Loss: 0.386042058467865\n",
            "Epoch: 23, Batch: 849, Batch Loss: 0.22254744172096252\n",
            "Epoch: 23, Batch: 850, Batch Loss: 0.3077177107334137\n",
            "Epoch: 23, Batch: 851, Batch Loss: 0.41962048411369324\n",
            "Epoch: 23, Batch: 852, Batch Loss: 0.6071840524673462\n",
            "Epoch: 23, Batch: 853, Batch Loss: 0.368084192276001\n",
            "Epoch: 23, Batch: 854, Batch Loss: 0.4597976505756378\n",
            "Epoch: 23, Batch: 855, Batch Loss: 0.35909798741340637\n",
            "Epoch: 23, Batch: 856, Batch Loss: 0.47305530309677124\n",
            "Epoch: 23, Batch: 857, Batch Loss: 0.1975020468235016\n",
            "Epoch: 23, Batch: 858, Batch Loss: 0.32235729694366455\n",
            "Epoch: 23, Batch: 859, Batch Loss: 0.4749065637588501\n",
            "Epoch: 23, Batch: 860, Batch Loss: 0.3866925537586212\n",
            "Epoch: 23, Batch: 861, Batch Loss: 0.2794412672519684\n",
            "Epoch: 23, Batch: 862, Batch Loss: 0.38227173686027527\n",
            "Epoch: 23, Batch: 863, Batch Loss: 0.3342682421207428\n",
            "Epoch: 23, Batch: 864, Batch Loss: 0.37675365805625916\n",
            "Epoch: 23, Batch: 865, Batch Loss: 0.2637292444705963\n",
            "Epoch: 23, Batch: 866, Batch Loss: 0.34795886278152466\n",
            "Epoch: 23, Batch: 867, Batch Loss: 0.24544906616210938\n",
            "Epoch: 23, Batch: 868, Batch Loss: 0.34889447689056396\n",
            "Epoch: 23, Batch: 869, Batch Loss: 0.3860553205013275\n",
            "Epoch: 23, Batch: 870, Batch Loss: 0.40652933716773987\n",
            "Epoch: 23, Batch: 871, Batch Loss: 0.3464667499065399\n",
            "Epoch: 23, Batch: 872, Batch Loss: 0.5244861245155334\n",
            "Epoch: 23, Batch: 873, Batch Loss: 0.394489049911499\n",
            "Epoch: 23, Batch: 874, Batch Loss: 0.39397934079170227\n",
            "Epoch: 23, Batch: 875, Batch Loss: 0.3914543390274048\n",
            "Epoch: 23, Batch: 876, Batch Loss: 0.3230380713939667\n",
            "Epoch: 23, Batch: 877, Batch Loss: 0.34407150745391846\n",
            "Epoch: 23, Batch: 878, Batch Loss: 0.3816955089569092\n",
            "Epoch: 23, Batch: 879, Batch Loss: 0.42971208691596985\n",
            "Epoch: 23, Batch: 880, Batch Loss: 0.6195554733276367\n",
            "Epoch: 23, Batch: 881, Batch Loss: 0.382499635219574\n",
            "Epoch: 23, Batch: 882, Batch Loss: 0.45808911323547363\n",
            "Epoch: 23, Batch: 883, Batch Loss: 0.2924633026123047\n",
            "Epoch: 23, Batch: 884, Batch Loss: 0.46786245703697205\n",
            "Epoch: 23, Batch: 885, Batch Loss: 0.34122830629348755\n",
            "Epoch: 23, Batch: 886, Batch Loss: 0.4875466227531433\n",
            "Epoch: 23, Batch: 887, Batch Loss: 0.194247767329216\n",
            "Epoch: 23, Batch: 888, Batch Loss: 0.21344587206840515\n",
            "Epoch: 23, Batch: 889, Batch Loss: 0.3753405809402466\n",
            "Epoch: 23, Batch: 890, Batch Loss: 0.27188006043434143\n",
            "Epoch: 23, Batch: 891, Batch Loss: 0.2961982786655426\n",
            "Epoch: 23, Batch: 892, Batch Loss: 0.4099842607975006\n",
            "Epoch: 23, Batch: 893, Batch Loss: 0.26781129837036133\n",
            "Epoch: 23, Batch: 894, Batch Loss: 0.5078690648078918\n",
            "Epoch: 23, Batch: 895, Batch Loss: 0.4247268736362457\n",
            "Epoch: 23, Batch: 896, Batch Loss: 0.32193684577941895\n",
            "Epoch: 23, Batch: 897, Batch Loss: 0.3263132572174072\n",
            "Epoch: 23, Batch: 898, Batch Loss: 0.6421284675598145\n",
            "Epoch: 23, Batch: 899, Batch Loss: 0.45694392919540405\n",
            "Epoch: 23, Batch: 900, Batch Loss: 0.46831369400024414\n",
            "Epoch: 23, Batch: 901, Batch Loss: 0.45761531591415405\n",
            "Epoch: 23, Batch: 902, Batch Loss: 0.49951767921447754\n",
            "Epoch: 23, Batch: 903, Batch Loss: 0.45708149671554565\n",
            "Epoch: 23, Batch: 904, Batch Loss: 0.3645658493041992\n",
            "Epoch: 23, Batch: 905, Batch Loss: 0.46942567825317383\n",
            "Epoch: 23, Batch: 906, Batch Loss: 0.3510398864746094\n",
            "Epoch: 23, Batch: 907, Batch Loss: 0.42304980754852295\n",
            "Epoch: 23, Batch: 908, Batch Loss: 0.24772173166275024\n",
            "Epoch: 23, Batch: 909, Batch Loss: 0.44822075963020325\n",
            "Epoch: 23, Batch: 910, Batch Loss: 0.3034829795360565\n",
            "Epoch: 23, Batch: 911, Batch Loss: 0.3694342076778412\n",
            "Epoch: 23, Batch: 912, Batch Loss: 0.4226692318916321\n",
            "Epoch: 23, Batch: 913, Batch Loss: 0.4276401996612549\n",
            "Epoch: 23, Batch: 914, Batch Loss: 0.2819772958755493\n",
            "Epoch: 23, Batch: 915, Batch Loss: 0.33395811915397644\n",
            "Epoch: 23, Batch: 916, Batch Loss: 0.3455726206302643\n",
            "Epoch: 23, Batch: 917, Batch Loss: 0.2762041389942169\n",
            "Epoch: 23, Batch: 918, Batch Loss: 0.42721036076545715\n",
            "Epoch: 23, Batch: 919, Batch Loss: 0.4578346908092499\n",
            "Epoch: 23, Batch: 920, Batch Loss: 0.4625130295753479\n",
            "Epoch: 23, Batch: 921, Batch Loss: 0.3476807475090027\n",
            "Epoch: 23, Batch: 922, Batch Loss: 0.3157042860984802\n",
            "Epoch: 23, Batch: 923, Batch Loss: 0.2831733822822571\n",
            "Epoch: 23, Batch: 924, Batch Loss: 0.3094561994075775\n",
            "Epoch: 23, Batch: 925, Batch Loss: 0.26739737391471863\n",
            "Epoch: 23, Batch: 926, Batch Loss: 0.3742285668849945\n",
            "Epoch: 23, Batch: 927, Batch Loss: 0.35296350717544556\n",
            "Epoch: 23, Batch: 928, Batch Loss: 0.4847504794597626\n",
            "Epoch: 23, Batch: 929, Batch Loss: 0.6089305877685547\n",
            "Epoch: 23, Batch: 930, Batch Loss: 0.3752020597457886\n",
            "Epoch: 23, Batch: 931, Batch Loss: 0.524413526058197\n",
            "Epoch: 23, Batch: 932, Batch Loss: 0.3534156084060669\n",
            "Epoch: 23, Batch: 933, Batch Loss: 0.4534924030303955\n",
            "Epoch: 23, Batch: 934, Batch Loss: 0.3453172445297241\n",
            "Epoch: 23, Batch: 935, Batch Loss: 0.29603075981140137\n",
            "Epoch: 23, Batch: 936, Batch Loss: 0.4006267189979553\n",
            "Epoch: 23, Batch: 937, Batch Loss: 0.4862076938152313\n",
            "Accuracy of train set: 0.8637666666666667\n",
            "Epoch: 23, Batch: 0, test Batch Loss: 0.47535908222198486\n",
            "Epoch: 23, Batch: 1, test Batch Loss: 0.5214034914970398\n",
            "Epoch: 23, Batch: 2, test Batch Loss: 0.4040258526802063\n",
            "Epoch: 23, Batch: 3, test Batch Loss: 0.346987247467041\n",
            "Epoch: 23, Batch: 4, test Batch Loss: 0.37439262866973877\n",
            "Epoch: 23, Batch: 5, test Batch Loss: 0.4810013771057129\n",
            "Epoch: 23, Batch: 6, test Batch Loss: 0.5386746525764465\n",
            "Epoch: 23, Batch: 7, test Batch Loss: 0.3525736927986145\n",
            "Epoch: 23, Batch: 8, test Batch Loss: 0.30841153860092163\n",
            "Epoch: 23, Batch: 9, test Batch Loss: 0.42138588428497314\n",
            "Epoch: 23, Batch: 10, test Batch Loss: 0.49231117963790894\n",
            "Epoch: 23, Batch: 11, test Batch Loss: 0.47410669922828674\n",
            "Epoch: 23, Batch: 12, test Batch Loss: 0.3438366949558258\n",
            "Epoch: 23, Batch: 13, test Batch Loss: 0.6217554807662964\n",
            "Epoch: 23, Batch: 14, test Batch Loss: 0.6118466258049011\n",
            "Epoch: 23, Batch: 15, test Batch Loss: 0.6238894462585449\n",
            "Epoch: 23, Batch: 16, test Batch Loss: 0.3783688545227051\n",
            "Epoch: 23, Batch: 17, test Batch Loss: 0.42435771226882935\n",
            "Epoch: 23, Batch: 18, test Batch Loss: 0.24999159574508667\n",
            "Epoch: 23, Batch: 19, test Batch Loss: 0.5980767607688904\n",
            "Epoch: 23, Batch: 20, test Batch Loss: 0.30956903100013733\n",
            "Epoch: 23, Batch: 21, test Batch Loss: 0.5828447341918945\n",
            "Epoch: 23, Batch: 22, test Batch Loss: 0.619803786277771\n",
            "Epoch: 23, Batch: 23, test Batch Loss: 0.3292523920536041\n",
            "Epoch: 23, Batch: 24, test Batch Loss: 0.39301562309265137\n",
            "Epoch: 23, Batch: 25, test Batch Loss: 0.42105185985565186\n",
            "Epoch: 23, Batch: 26, test Batch Loss: 0.3756033182144165\n",
            "Epoch: 23, Batch: 27, test Batch Loss: 0.6923027038574219\n",
            "Epoch: 23, Batch: 28, test Batch Loss: 0.3081955909729004\n",
            "Epoch: 23, Batch: 29, test Batch Loss: 0.5105069875717163\n",
            "Epoch: 23, Batch: 30, test Batch Loss: 0.35528385639190674\n",
            "Epoch: 23, Batch: 31, test Batch Loss: 0.5055975317955017\n",
            "Epoch: 23, Batch: 32, test Batch Loss: 0.4431469440460205\n",
            "Epoch: 23, Batch: 33, test Batch Loss: 0.4352366626262665\n",
            "Epoch: 23, Batch: 34, test Batch Loss: 0.27802056074142456\n",
            "Epoch: 23, Batch: 35, test Batch Loss: 0.40947356820106506\n",
            "Epoch: 23, Batch: 36, test Batch Loss: 0.3796364367008209\n",
            "Epoch: 23, Batch: 37, test Batch Loss: 0.44735264778137207\n",
            "Epoch: 23, Batch: 38, test Batch Loss: 0.39659541845321655\n",
            "Epoch: 23, Batch: 39, test Batch Loss: 0.521379828453064\n",
            "Epoch: 23, Batch: 40, test Batch Loss: 0.47783613204956055\n",
            "Epoch: 23, Batch: 41, test Batch Loss: 0.38100671768188477\n",
            "Epoch: 23, Batch: 42, test Batch Loss: 0.3352475166320801\n",
            "Epoch: 23, Batch: 43, test Batch Loss: 0.27118515968322754\n",
            "Epoch: 23, Batch: 44, test Batch Loss: 0.34130075573921204\n",
            "Epoch: 23, Batch: 45, test Batch Loss: 0.6002696752548218\n",
            "Epoch: 23, Batch: 46, test Batch Loss: 0.2744293212890625\n",
            "Epoch: 23, Batch: 47, test Batch Loss: 0.276961088180542\n",
            "Epoch: 23, Batch: 48, test Batch Loss: 0.7148933410644531\n",
            "Epoch: 23, Batch: 49, test Batch Loss: 0.32425495982170105\n",
            "Epoch: 23, Batch: 50, test Batch Loss: 0.38646310567855835\n",
            "Epoch: 23, Batch: 51, test Batch Loss: 0.5866120457649231\n",
            "Epoch: 23, Batch: 52, test Batch Loss: 0.29835379123687744\n",
            "Epoch: 23, Batch: 53, test Batch Loss: 0.3657298684120178\n",
            "Epoch: 23, Batch: 54, test Batch Loss: 0.4429980516433716\n",
            "Epoch: 23, Batch: 55, test Batch Loss: 0.3572017252445221\n",
            "Epoch: 23, Batch: 56, test Batch Loss: 0.685971200466156\n",
            "Epoch: 23, Batch: 57, test Batch Loss: 0.7672799825668335\n",
            "Epoch: 23, Batch: 58, test Batch Loss: 0.26112669706344604\n",
            "Epoch: 23, Batch: 59, test Batch Loss: 0.312581330537796\n",
            "Epoch: 23, Batch: 60, test Batch Loss: 0.2787770628929138\n",
            "Epoch: 23, Batch: 61, test Batch Loss: 0.4735429286956787\n",
            "Epoch: 23, Batch: 62, test Batch Loss: 0.5386187434196472\n",
            "Epoch: 23, Batch: 63, test Batch Loss: 0.42488157749176025\n",
            "Epoch: 23, Batch: 64, test Batch Loss: 0.3643546998500824\n",
            "Epoch: 23, Batch: 65, test Batch Loss: 0.23236873745918274\n",
            "Epoch: 23, Batch: 66, test Batch Loss: 0.5911575555801392\n",
            "Epoch: 23, Batch: 67, test Batch Loss: 0.3424944281578064\n",
            "Epoch: 23, Batch: 68, test Batch Loss: 0.22902938723564148\n",
            "Epoch: 23, Batch: 69, test Batch Loss: 0.20246203243732452\n",
            "Epoch: 23, Batch: 70, test Batch Loss: 0.5660642981529236\n",
            "Epoch: 23, Batch: 71, test Batch Loss: 0.27604302763938904\n",
            "Epoch: 23, Batch: 72, test Batch Loss: 0.23633134365081787\n",
            "Epoch: 23, Batch: 73, test Batch Loss: 0.4442841410636902\n",
            "Epoch: 23, Batch: 74, test Batch Loss: 0.5320355296134949\n",
            "Epoch: 23, Batch: 75, test Batch Loss: 0.3189249038696289\n",
            "Epoch: 23, Batch: 76, test Batch Loss: 0.27318263053894043\n",
            "Epoch: 23, Batch: 77, test Batch Loss: 0.385086327791214\n",
            "Epoch: 23, Batch: 78, test Batch Loss: 0.2978030741214752\n",
            "Epoch: 23, Batch: 79, test Batch Loss: 0.5286640524864197\n",
            "Epoch: 23, Batch: 80, test Batch Loss: 0.4138484001159668\n",
            "Epoch: 23, Batch: 81, test Batch Loss: 0.39743590354919434\n",
            "Epoch: 23, Batch: 82, test Batch Loss: 0.4070945084095001\n",
            "Epoch: 23, Batch: 83, test Batch Loss: 0.433813214302063\n",
            "Epoch: 23, Batch: 84, test Batch Loss: 0.4022105038166046\n",
            "Epoch: 23, Batch: 85, test Batch Loss: 0.3721861243247986\n",
            "Epoch: 23, Batch: 86, test Batch Loss: 0.17599409818649292\n",
            "Epoch: 23, Batch: 87, test Batch Loss: 0.5362136363983154\n",
            "Epoch: 23, Batch: 88, test Batch Loss: 0.2681816518306732\n",
            "Epoch: 23, Batch: 89, test Batch Loss: 0.4064769744873047\n",
            "Epoch: 23, Batch: 90, test Batch Loss: 0.4536076784133911\n",
            "Epoch: 23, Batch: 91, test Batch Loss: 0.4310217499732971\n",
            "Epoch: 23, Batch: 92, test Batch Loss: 0.31273549795150757\n",
            "Epoch: 23, Batch: 93, test Batch Loss: 0.663057267665863\n",
            "Epoch: 23, Batch: 94, test Batch Loss: 0.48863455653190613\n",
            "Epoch: 23, Batch: 95, test Batch Loss: 0.45227810740470886\n",
            "Epoch: 23, Batch: 96, test Batch Loss: 0.3825966417789459\n",
            "Epoch: 23, Batch: 97, test Batch Loss: 0.3919392228126526\n",
            "Epoch: 23, Batch: 98, test Batch Loss: 0.2486802339553833\n",
            "Epoch: 23, Batch: 99, test Batch Loss: 0.6078991293907166\n",
            "Epoch: 23, Batch: 100, test Batch Loss: 0.42215868830680847\n",
            "Epoch: 23, Batch: 101, test Batch Loss: 0.24898552894592285\n",
            "Epoch: 23, Batch: 102, test Batch Loss: 0.3966711461544037\n",
            "Epoch: 23, Batch: 103, test Batch Loss: 0.7043764591217041\n",
            "Epoch: 23, Batch: 104, test Batch Loss: 0.3742504119873047\n",
            "Epoch: 23, Batch: 105, test Batch Loss: 0.5053601861000061\n",
            "Epoch: 23, Batch: 106, test Batch Loss: 0.3517638146877289\n",
            "Epoch: 23, Batch: 107, test Batch Loss: 0.5881273746490479\n",
            "Epoch: 23, Batch: 108, test Batch Loss: 0.40088051557540894\n",
            "Epoch: 23, Batch: 109, test Batch Loss: 0.35074588656425476\n",
            "Epoch: 23, Batch: 110, test Batch Loss: 0.3115456700325012\n",
            "Epoch: 23, Batch: 111, test Batch Loss: 0.4905114769935608\n",
            "Epoch: 23, Batch: 112, test Batch Loss: 0.5147237181663513\n",
            "Epoch: 23, Batch: 113, test Batch Loss: 0.4780176877975464\n",
            "Epoch: 23, Batch: 114, test Batch Loss: 0.43147969245910645\n",
            "Epoch: 23, Batch: 115, test Batch Loss: 0.4419539272785187\n",
            "Epoch: 23, Batch: 116, test Batch Loss: 0.5520279407501221\n",
            "Epoch: 23, Batch: 117, test Batch Loss: 0.372495174407959\n",
            "Epoch: 23, Batch: 118, test Batch Loss: 0.4033712148666382\n",
            "Epoch: 23, Batch: 119, test Batch Loss: 0.2902231216430664\n",
            "Epoch: 23, Batch: 120, test Batch Loss: 0.5428006649017334\n",
            "Epoch: 23, Batch: 121, test Batch Loss: 0.39270052313804626\n",
            "Epoch: 23, Batch: 122, test Batch Loss: 0.4218197166919708\n",
            "Epoch: 23, Batch: 123, test Batch Loss: 0.270800918340683\n",
            "Epoch: 23, Batch: 124, test Batch Loss: 0.21820183098316193\n",
            "Epoch: 23, Batch: 125, test Batch Loss: 0.45958587527275085\n",
            "Epoch: 23, Batch: 126, test Batch Loss: 0.531517744064331\n",
            "Epoch: 23, Batch: 127, test Batch Loss: 0.4066135883331299\n",
            "Epoch: 23, Batch: 128, test Batch Loss: 0.28280502557754517\n",
            "Epoch: 23, Batch: 129, test Batch Loss: 0.468923419713974\n",
            "Epoch: 23, Batch: 130, test Batch Loss: 0.3537430167198181\n",
            "Epoch: 23, Batch: 131, test Batch Loss: 0.38083934783935547\n",
            "Epoch: 23, Batch: 132, test Batch Loss: 0.38373106718063354\n",
            "Epoch: 23, Batch: 133, test Batch Loss: 0.4192501902580261\n",
            "Epoch: 23, Batch: 134, test Batch Loss: 0.45868441462516785\n",
            "Epoch: 23, Batch: 135, test Batch Loss: 0.2672688663005829\n",
            "Epoch: 23, Batch: 136, test Batch Loss: 0.41180703043937683\n",
            "Epoch: 23, Batch: 137, test Batch Loss: 0.2438853681087494\n",
            "Epoch: 23, Batch: 138, test Batch Loss: 0.5202372074127197\n",
            "Epoch: 23, Batch: 139, test Batch Loss: 0.5457452535629272\n",
            "Epoch: 23, Batch: 140, test Batch Loss: 0.5142631530761719\n",
            "Epoch: 23, Batch: 141, test Batch Loss: 0.22018353641033173\n",
            "Epoch: 23, Batch: 142, test Batch Loss: 0.48129332065582275\n",
            "Epoch: 23, Batch: 143, test Batch Loss: 0.666749119758606\n",
            "Epoch: 23, Batch: 144, test Batch Loss: 0.5498660802841187\n",
            "Epoch: 23, Batch: 145, test Batch Loss: 0.582413911819458\n",
            "Epoch: 23, Batch: 146, test Batch Loss: 0.2821762263774872\n",
            "Epoch: 23, Batch: 147, test Batch Loss: 0.5842947959899902\n",
            "Epoch: 23, Batch: 148, test Batch Loss: 0.576393187046051\n",
            "Epoch: 23, Batch: 149, test Batch Loss: 0.37944042682647705\n",
            "Epoch: 23, Batch: 150, test Batch Loss: 0.439970463514328\n",
            "Epoch: 23, Batch: 151, test Batch Loss: 0.5072329044342041\n",
            "Epoch: 23, Batch: 152, test Batch Loss: 0.23311127722263336\n",
            "Epoch: 23, Batch: 153, test Batch Loss: 0.5720982551574707\n",
            "Epoch: 23, Batch: 154, test Batch Loss: 0.4729198217391968\n",
            "Epoch: 23, Batch: 155, test Batch Loss: 0.7240325212478638\n",
            "Epoch: 23, Batch: 156, test Batch Loss: 0.7189688682556152\n",
            "Accuracy of test set: 0.8482\n",
            "Epoch 24/25 - Train Loss: 0.3858, Train Acc: 0.8638, Test Loss: 0.4261, Test Acc: 0.8482\n",
            "Epoch: 24, Batch: 0, Batch Loss: 0.30590134859085083\n",
            "Epoch: 24, Batch: 1, Batch Loss: 0.3405868709087372\n",
            "Epoch: 24, Batch: 2, Batch Loss: 0.48535940051078796\n",
            "Epoch: 24, Batch: 3, Batch Loss: 0.409769207239151\n",
            "Epoch: 24, Batch: 4, Batch Loss: 0.5082834959030151\n",
            "Epoch: 24, Batch: 5, Batch Loss: 0.7069855332374573\n",
            "Epoch: 24, Batch: 6, Batch Loss: 0.24977299571037292\n",
            "Epoch: 24, Batch: 7, Batch Loss: 0.2980058491230011\n",
            "Epoch: 24, Batch: 8, Batch Loss: 0.34708255529403687\n",
            "Epoch: 24, Batch: 9, Batch Loss: 0.3193790912628174\n",
            "Epoch: 24, Batch: 10, Batch Loss: 0.4488075375556946\n",
            "Epoch: 24, Batch: 11, Batch Loss: 0.42106252908706665\n",
            "Epoch: 24, Batch: 12, Batch Loss: 0.2907849848270416\n",
            "Epoch: 24, Batch: 13, Batch Loss: 0.49001845717430115\n",
            "Epoch: 24, Batch: 14, Batch Loss: 0.25089144706726074\n",
            "Epoch: 24, Batch: 15, Batch Loss: 0.45307791233062744\n",
            "Epoch: 24, Batch: 16, Batch Loss: 0.34708958864212036\n",
            "Epoch: 24, Batch: 17, Batch Loss: 0.33080294728279114\n",
            "Epoch: 24, Batch: 18, Batch Loss: 0.24087528884410858\n",
            "Epoch: 24, Batch: 19, Batch Loss: 0.4180399477481842\n",
            "Epoch: 24, Batch: 20, Batch Loss: 0.2997143864631653\n",
            "Epoch: 24, Batch: 21, Batch Loss: 0.6097633242607117\n",
            "Epoch: 24, Batch: 22, Batch Loss: 0.3259548842906952\n",
            "Epoch: 24, Batch: 23, Batch Loss: 0.21913397312164307\n",
            "Epoch: 24, Batch: 24, Batch Loss: 0.2211524248123169\n",
            "Epoch: 24, Batch: 25, Batch Loss: 0.43313348293304443\n",
            "Epoch: 24, Batch: 26, Batch Loss: 0.38452672958374023\n",
            "Epoch: 24, Batch: 27, Batch Loss: 0.41861751675605774\n",
            "Epoch: 24, Batch: 28, Batch Loss: 0.5439688563346863\n",
            "Epoch: 24, Batch: 29, Batch Loss: 0.36681199073791504\n",
            "Epoch: 24, Batch: 30, Batch Loss: 0.3673096299171448\n",
            "Epoch: 24, Batch: 31, Batch Loss: 0.37030115723609924\n",
            "Epoch: 24, Batch: 32, Batch Loss: 0.36335790157318115\n",
            "Epoch: 24, Batch: 33, Batch Loss: 0.21982897818088531\n",
            "Epoch: 24, Batch: 34, Batch Loss: 0.41985103487968445\n",
            "Epoch: 24, Batch: 35, Batch Loss: 0.611075758934021\n",
            "Epoch: 24, Batch: 36, Batch Loss: 0.4741702675819397\n",
            "Epoch: 24, Batch: 37, Batch Loss: 0.447628915309906\n",
            "Epoch: 24, Batch: 38, Batch Loss: 0.5429150462150574\n",
            "Epoch: 24, Batch: 39, Batch Loss: 0.34496214985847473\n",
            "Epoch: 24, Batch: 40, Batch Loss: 0.2762179672718048\n",
            "Epoch: 24, Batch: 41, Batch Loss: 0.4456191062927246\n",
            "Epoch: 24, Batch: 42, Batch Loss: 0.2232043743133545\n",
            "Epoch: 24, Batch: 43, Batch Loss: 0.5621988773345947\n",
            "Epoch: 24, Batch: 44, Batch Loss: 0.5279288291931152\n",
            "Epoch: 24, Batch: 45, Batch Loss: 0.31428611278533936\n",
            "Epoch: 24, Batch: 46, Batch Loss: 0.32054001092910767\n",
            "Epoch: 24, Batch: 47, Batch Loss: 0.4824059307575226\n",
            "Epoch: 24, Batch: 48, Batch Loss: 0.4239434599876404\n",
            "Epoch: 24, Batch: 49, Batch Loss: 0.3862892985343933\n",
            "Epoch: 24, Batch: 50, Batch Loss: 0.3761937618255615\n",
            "Epoch: 24, Batch: 51, Batch Loss: 0.2518496513366699\n",
            "Epoch: 24, Batch: 52, Batch Loss: 0.21910937130451202\n",
            "Epoch: 24, Batch: 53, Batch Loss: 0.5097786784172058\n",
            "Epoch: 24, Batch: 54, Batch Loss: 0.28483763337135315\n",
            "Epoch: 24, Batch: 55, Batch Loss: 0.3477526605129242\n",
            "Epoch: 24, Batch: 56, Batch Loss: 0.239670529961586\n",
            "Epoch: 24, Batch: 57, Batch Loss: 0.3893478810787201\n",
            "Epoch: 24, Batch: 58, Batch Loss: 0.3644423484802246\n",
            "Epoch: 24, Batch: 59, Batch Loss: 0.36659184098243713\n",
            "Epoch: 24, Batch: 60, Batch Loss: 0.20372942090034485\n",
            "Epoch: 24, Batch: 61, Batch Loss: 0.37456291913986206\n",
            "Epoch: 24, Batch: 62, Batch Loss: 0.4852186441421509\n",
            "Epoch: 24, Batch: 63, Batch Loss: 0.33608946204185486\n",
            "Epoch: 24, Batch: 64, Batch Loss: 0.4266384243965149\n",
            "Epoch: 24, Batch: 65, Batch Loss: 0.5430377721786499\n",
            "Epoch: 24, Batch: 66, Batch Loss: 0.41348275542259216\n",
            "Epoch: 24, Batch: 67, Batch Loss: 0.37983256578445435\n",
            "Epoch: 24, Batch: 68, Batch Loss: 0.21964356303215027\n",
            "Epoch: 24, Batch: 69, Batch Loss: 0.2757222056388855\n",
            "Epoch: 24, Batch: 70, Batch Loss: 0.4660849869251251\n",
            "Epoch: 24, Batch: 71, Batch Loss: 0.45742642879486084\n",
            "Epoch: 24, Batch: 72, Batch Loss: 0.3400161564350128\n",
            "Epoch: 24, Batch: 73, Batch Loss: 0.32054829597473145\n",
            "Epoch: 24, Batch: 74, Batch Loss: 0.36332714557647705\n",
            "Epoch: 24, Batch: 75, Batch Loss: 0.329420804977417\n",
            "Epoch: 24, Batch: 76, Batch Loss: 0.24993625283241272\n",
            "Epoch: 24, Batch: 77, Batch Loss: 0.427737295627594\n",
            "Epoch: 24, Batch: 78, Batch Loss: 0.35417091846466064\n",
            "Epoch: 24, Batch: 79, Batch Loss: 0.315408319234848\n",
            "Epoch: 24, Batch: 80, Batch Loss: 0.3354667127132416\n",
            "Epoch: 24, Batch: 81, Batch Loss: 0.380280464887619\n",
            "Epoch: 24, Batch: 82, Batch Loss: 0.374076247215271\n",
            "Epoch: 24, Batch: 83, Batch Loss: 0.3083960711956024\n",
            "Epoch: 24, Batch: 84, Batch Loss: 0.33819156885147095\n",
            "Epoch: 24, Batch: 85, Batch Loss: 0.43214908242225647\n",
            "Epoch: 24, Batch: 86, Batch Loss: 0.5192872285842896\n",
            "Epoch: 24, Batch: 87, Batch Loss: 0.6024364829063416\n",
            "Epoch: 24, Batch: 88, Batch Loss: 0.3649172782897949\n",
            "Epoch: 24, Batch: 89, Batch Loss: 0.39767247438430786\n",
            "Epoch: 24, Batch: 90, Batch Loss: 0.35675105452537537\n",
            "Epoch: 24, Batch: 91, Batch Loss: 0.3307588994503021\n",
            "Epoch: 24, Batch: 92, Batch Loss: 0.3873731195926666\n",
            "Epoch: 24, Batch: 93, Batch Loss: 0.4582231640815735\n",
            "Epoch: 24, Batch: 94, Batch Loss: 0.3488636016845703\n",
            "Epoch: 24, Batch: 95, Batch Loss: 0.4660155773162842\n",
            "Epoch: 24, Batch: 96, Batch Loss: 0.17702536284923553\n",
            "Epoch: 24, Batch: 97, Batch Loss: 0.43299734592437744\n",
            "Epoch: 24, Batch: 98, Batch Loss: 0.379784494638443\n",
            "Epoch: 24, Batch: 99, Batch Loss: 0.24758395552635193\n",
            "Epoch: 24, Batch: 100, Batch Loss: 0.27979353070259094\n",
            "Epoch: 24, Batch: 101, Batch Loss: 0.4198285937309265\n",
            "Epoch: 24, Batch: 102, Batch Loss: 0.3387330174446106\n",
            "Epoch: 24, Batch: 103, Batch Loss: 0.4892510771751404\n",
            "Epoch: 24, Batch: 104, Batch Loss: 0.5933891534805298\n",
            "Epoch: 24, Batch: 105, Batch Loss: 0.4343613386154175\n",
            "Epoch: 24, Batch: 106, Batch Loss: 0.40136396884918213\n",
            "Epoch: 24, Batch: 107, Batch Loss: 0.331072062253952\n",
            "Epoch: 24, Batch: 108, Batch Loss: 0.38440120220184326\n",
            "Epoch: 24, Batch: 109, Batch Loss: 0.48745256662368774\n",
            "Epoch: 24, Batch: 110, Batch Loss: 0.589067816734314\n",
            "Epoch: 24, Batch: 111, Batch Loss: 0.23010174930095673\n",
            "Epoch: 24, Batch: 112, Batch Loss: 0.23197133839130402\n",
            "Epoch: 24, Batch: 113, Batch Loss: 0.42457115650177\n",
            "Epoch: 24, Batch: 114, Batch Loss: 0.40136754512786865\n",
            "Epoch: 24, Batch: 115, Batch Loss: 0.5021321773529053\n",
            "Epoch: 24, Batch: 116, Batch Loss: 0.28371286392211914\n",
            "Epoch: 24, Batch: 117, Batch Loss: 0.303301602602005\n",
            "Epoch: 24, Batch: 118, Batch Loss: 0.29997193813323975\n",
            "Epoch: 24, Batch: 119, Batch Loss: 0.4015330672264099\n",
            "Epoch: 24, Batch: 120, Batch Loss: 0.32881036400794983\n",
            "Epoch: 24, Batch: 121, Batch Loss: 0.3299241065979004\n",
            "Epoch: 24, Batch: 122, Batch Loss: 0.39354264736175537\n",
            "Epoch: 24, Batch: 123, Batch Loss: 0.4898134768009186\n",
            "Epoch: 24, Batch: 124, Batch Loss: 0.4387495517730713\n",
            "Epoch: 24, Batch: 125, Batch Loss: 0.2838117182254791\n",
            "Epoch: 24, Batch: 126, Batch Loss: 0.29294586181640625\n",
            "Epoch: 24, Batch: 127, Batch Loss: 0.2526131868362427\n",
            "Epoch: 24, Batch: 128, Batch Loss: 0.3620474338531494\n",
            "Epoch: 24, Batch: 129, Batch Loss: 0.2870762348175049\n",
            "Epoch: 24, Batch: 130, Batch Loss: 0.4843343198299408\n",
            "Epoch: 24, Batch: 131, Batch Loss: 0.42357227206230164\n",
            "Epoch: 24, Batch: 132, Batch Loss: 0.27679410576820374\n",
            "Epoch: 24, Batch: 133, Batch Loss: 0.40060681104660034\n",
            "Epoch: 24, Batch: 134, Batch Loss: 0.5441042184829712\n",
            "Epoch: 24, Batch: 135, Batch Loss: 0.2753307819366455\n",
            "Epoch: 24, Batch: 136, Batch Loss: 0.26652270555496216\n",
            "Epoch: 24, Batch: 137, Batch Loss: 0.5491913557052612\n",
            "Epoch: 24, Batch: 138, Batch Loss: 0.34560251235961914\n",
            "Epoch: 24, Batch: 139, Batch Loss: 0.2909601628780365\n",
            "Epoch: 24, Batch: 140, Batch Loss: 0.3712042570114136\n",
            "Epoch: 24, Batch: 141, Batch Loss: 0.24651962518692017\n",
            "Epoch: 24, Batch: 142, Batch Loss: 0.3407819867134094\n",
            "Epoch: 24, Batch: 143, Batch Loss: 0.5043984055519104\n",
            "Epoch: 24, Batch: 144, Batch Loss: 0.35236409306526184\n",
            "Epoch: 24, Batch: 145, Batch Loss: 0.3848242163658142\n",
            "Epoch: 24, Batch: 146, Batch Loss: 0.2740154266357422\n",
            "Epoch: 24, Batch: 147, Batch Loss: 0.3202648460865021\n",
            "Epoch: 24, Batch: 148, Batch Loss: 0.40452390909194946\n",
            "Epoch: 24, Batch: 149, Batch Loss: 0.25686147809028625\n",
            "Epoch: 24, Batch: 150, Batch Loss: 0.4130532145500183\n",
            "Epoch: 24, Batch: 151, Batch Loss: 0.2546880841255188\n",
            "Epoch: 24, Batch: 152, Batch Loss: 0.3438861072063446\n",
            "Epoch: 24, Batch: 153, Batch Loss: 0.6315937042236328\n",
            "Epoch: 24, Batch: 154, Batch Loss: 0.3276060223579407\n",
            "Epoch: 24, Batch: 155, Batch Loss: 0.32090628147125244\n",
            "Epoch: 24, Batch: 156, Batch Loss: 0.2894431948661804\n",
            "Epoch: 24, Batch: 157, Batch Loss: 0.564960777759552\n",
            "Epoch: 24, Batch: 158, Batch Loss: 0.3748718500137329\n",
            "Epoch: 24, Batch: 159, Batch Loss: 0.4945184588432312\n",
            "Epoch: 24, Batch: 160, Batch Loss: 0.3328269422054291\n",
            "Epoch: 24, Batch: 161, Batch Loss: 0.4998748302459717\n",
            "Epoch: 24, Batch: 162, Batch Loss: 0.5657602548599243\n",
            "Epoch: 24, Batch: 163, Batch Loss: 0.3469626009464264\n",
            "Epoch: 24, Batch: 164, Batch Loss: 0.4441286325454712\n",
            "Epoch: 24, Batch: 165, Batch Loss: 0.5084830522537231\n",
            "Epoch: 24, Batch: 166, Batch Loss: 0.5839637517929077\n",
            "Epoch: 24, Batch: 167, Batch Loss: 0.5022977590560913\n",
            "Epoch: 24, Batch: 168, Batch Loss: 0.26174288988113403\n",
            "Epoch: 24, Batch: 169, Batch Loss: 0.22369951009750366\n",
            "Epoch: 24, Batch: 170, Batch Loss: 0.4053385853767395\n",
            "Epoch: 24, Batch: 171, Batch Loss: 0.35569673776626587\n",
            "Epoch: 24, Batch: 172, Batch Loss: 0.2885773181915283\n",
            "Epoch: 24, Batch: 173, Batch Loss: 0.25914621353149414\n",
            "Epoch: 24, Batch: 174, Batch Loss: 0.2033456712961197\n",
            "Epoch: 24, Batch: 175, Batch Loss: 0.3321149945259094\n",
            "Epoch: 24, Batch: 176, Batch Loss: 0.30411961674690247\n",
            "Epoch: 24, Batch: 177, Batch Loss: 0.34070417284965515\n",
            "Epoch: 24, Batch: 178, Batch Loss: 0.3407968580722809\n",
            "Epoch: 24, Batch: 179, Batch Loss: 0.38878318667411804\n",
            "Epoch: 24, Batch: 180, Batch Loss: 0.26452213525772095\n",
            "Epoch: 24, Batch: 181, Batch Loss: 0.3222774565219879\n",
            "Epoch: 24, Batch: 182, Batch Loss: 0.39075297117233276\n",
            "Epoch: 24, Batch: 183, Batch Loss: 0.7018218040466309\n",
            "Epoch: 24, Batch: 184, Batch Loss: 0.5583295226097107\n",
            "Epoch: 24, Batch: 185, Batch Loss: 0.5200105309486389\n",
            "Epoch: 24, Batch: 186, Batch Loss: 0.4068220853805542\n",
            "Epoch: 24, Batch: 187, Batch Loss: 0.43819156289100647\n",
            "Epoch: 24, Batch: 188, Batch Loss: 0.40589141845703125\n",
            "Epoch: 24, Batch: 189, Batch Loss: 0.25652146339416504\n",
            "Epoch: 24, Batch: 190, Batch Loss: 0.42014220356941223\n",
            "Epoch: 24, Batch: 191, Batch Loss: 0.48569148778915405\n",
            "Epoch: 24, Batch: 192, Batch Loss: 0.26654332876205444\n",
            "Epoch: 24, Batch: 193, Batch Loss: 0.41519856452941895\n",
            "Epoch: 24, Batch: 194, Batch Loss: 0.45708543062210083\n",
            "Epoch: 24, Batch: 195, Batch Loss: 0.3738675117492676\n",
            "Epoch: 24, Batch: 196, Batch Loss: 0.30199193954467773\n",
            "Epoch: 24, Batch: 197, Batch Loss: 0.5751287937164307\n",
            "Epoch: 24, Batch: 198, Batch Loss: 0.3322727680206299\n",
            "Epoch: 24, Batch: 199, Batch Loss: 0.3990890383720398\n",
            "Epoch: 24, Batch: 200, Batch Loss: 0.27559152245521545\n",
            "Epoch: 24, Batch: 201, Batch Loss: 0.43699729442596436\n",
            "Epoch: 24, Batch: 202, Batch Loss: 0.2718699872493744\n",
            "Epoch: 24, Batch: 203, Batch Loss: 0.5098336935043335\n",
            "Epoch: 24, Batch: 204, Batch Loss: 0.33119410276412964\n",
            "Epoch: 24, Batch: 205, Batch Loss: 0.26281416416168213\n",
            "Epoch: 24, Batch: 206, Batch Loss: 0.41678735613822937\n",
            "Epoch: 24, Batch: 207, Batch Loss: 0.37759289145469666\n",
            "Epoch: 24, Batch: 208, Batch Loss: 0.2510043680667877\n",
            "Epoch: 24, Batch: 209, Batch Loss: 0.2837352156639099\n",
            "Epoch: 24, Batch: 210, Batch Loss: 0.4541093111038208\n",
            "Epoch: 24, Batch: 211, Batch Loss: 0.2516188323497772\n",
            "Epoch: 24, Batch: 212, Batch Loss: 0.3871226906776428\n",
            "Epoch: 24, Batch: 213, Batch Loss: 0.4107985496520996\n",
            "Epoch: 24, Batch: 214, Batch Loss: 0.23277366161346436\n",
            "Epoch: 24, Batch: 215, Batch Loss: 0.30290845036506653\n",
            "Epoch: 24, Batch: 216, Batch Loss: 0.3297441899776459\n",
            "Epoch: 24, Batch: 217, Batch Loss: 0.3574400544166565\n",
            "Epoch: 24, Batch: 218, Batch Loss: 0.43384766578674316\n",
            "Epoch: 24, Batch: 219, Batch Loss: 0.24214451014995575\n",
            "Epoch: 24, Batch: 220, Batch Loss: 0.33487629890441895\n",
            "Epoch: 24, Batch: 221, Batch Loss: 0.6096330285072327\n",
            "Epoch: 24, Batch: 222, Batch Loss: 0.4602043628692627\n",
            "Epoch: 24, Batch: 223, Batch Loss: 0.27587950229644775\n",
            "Epoch: 24, Batch: 224, Batch Loss: 0.33141183853149414\n",
            "Epoch: 24, Batch: 225, Batch Loss: 0.3272763788700104\n",
            "Epoch: 24, Batch: 226, Batch Loss: 0.33483344316482544\n",
            "Epoch: 24, Batch: 227, Batch Loss: 0.27792686223983765\n",
            "Epoch: 24, Batch: 228, Batch Loss: 0.3912460207939148\n",
            "Epoch: 24, Batch: 229, Batch Loss: 0.40005791187286377\n",
            "Epoch: 24, Batch: 230, Batch Loss: 0.4057677388191223\n",
            "Epoch: 24, Batch: 231, Batch Loss: 0.41541531682014465\n",
            "Epoch: 24, Batch: 232, Batch Loss: 0.4339188039302826\n",
            "Epoch: 24, Batch: 233, Batch Loss: 0.42572978138923645\n",
            "Epoch: 24, Batch: 234, Batch Loss: 0.4373404085636139\n",
            "Epoch: 24, Batch: 235, Batch Loss: 0.6185451745986938\n",
            "Epoch: 24, Batch: 236, Batch Loss: 0.2925376296043396\n",
            "Epoch: 24, Batch: 237, Batch Loss: 0.2854711711406708\n",
            "Epoch: 24, Batch: 238, Batch Loss: 0.3515942394733429\n",
            "Epoch: 24, Batch: 239, Batch Loss: 0.5093033313751221\n",
            "Epoch: 24, Batch: 240, Batch Loss: 0.2295808494091034\n",
            "Epoch: 24, Batch: 241, Batch Loss: 0.2733228802680969\n",
            "Epoch: 24, Batch: 242, Batch Loss: 0.26969048380851746\n",
            "Epoch: 24, Batch: 243, Batch Loss: 0.43633055686950684\n",
            "Epoch: 24, Batch: 244, Batch Loss: 0.4482082724571228\n",
            "Epoch: 24, Batch: 245, Batch Loss: 0.3404398560523987\n",
            "Epoch: 24, Batch: 246, Batch Loss: 0.47083142399787903\n",
            "Epoch: 24, Batch: 247, Batch Loss: 0.4542168378829956\n",
            "Epoch: 24, Batch: 248, Batch Loss: 0.3401600122451782\n",
            "Epoch: 24, Batch: 249, Batch Loss: 0.37826117873191833\n",
            "Epoch: 24, Batch: 250, Batch Loss: 0.25785496830940247\n",
            "Epoch: 24, Batch: 251, Batch Loss: 0.3908770680427551\n",
            "Epoch: 24, Batch: 252, Batch Loss: 0.32201629877090454\n",
            "Epoch: 24, Batch: 253, Batch Loss: 0.40086883306503296\n",
            "Epoch: 24, Batch: 254, Batch Loss: 0.4193168580532074\n",
            "Epoch: 24, Batch: 255, Batch Loss: 0.33732151985168457\n",
            "Epoch: 24, Batch: 256, Batch Loss: 0.5608134269714355\n",
            "Epoch: 24, Batch: 257, Batch Loss: 0.2958480715751648\n",
            "Epoch: 24, Batch: 258, Batch Loss: 0.2628803551197052\n",
            "Epoch: 24, Batch: 259, Batch Loss: 0.46030375361442566\n",
            "Epoch: 24, Batch: 260, Batch Loss: 0.42403870820999146\n",
            "Epoch: 24, Batch: 261, Batch Loss: 0.5531575679779053\n",
            "Epoch: 24, Batch: 262, Batch Loss: 0.3961058557033539\n",
            "Epoch: 24, Batch: 263, Batch Loss: 0.5070023536682129\n",
            "Epoch: 24, Batch: 264, Batch Loss: 0.3181755244731903\n",
            "Epoch: 24, Batch: 265, Batch Loss: 0.31144118309020996\n",
            "Epoch: 24, Batch: 266, Batch Loss: 0.3074582517147064\n",
            "Epoch: 24, Batch: 267, Batch Loss: 0.3385055959224701\n",
            "Epoch: 24, Batch: 268, Batch Loss: 0.39707791805267334\n",
            "Epoch: 24, Batch: 269, Batch Loss: 0.5137178301811218\n",
            "Epoch: 24, Batch: 270, Batch Loss: 0.3306773006916046\n",
            "Epoch: 24, Batch: 271, Batch Loss: 0.5674351453781128\n",
            "Epoch: 24, Batch: 272, Batch Loss: 0.389782577753067\n",
            "Epoch: 24, Batch: 273, Batch Loss: 0.2534466087818146\n",
            "Epoch: 24, Batch: 274, Batch Loss: 0.4481559097766876\n",
            "Epoch: 24, Batch: 275, Batch Loss: 0.23722970485687256\n",
            "Epoch: 24, Batch: 276, Batch Loss: 0.439223051071167\n",
            "Epoch: 24, Batch: 277, Batch Loss: 0.6917296051979065\n",
            "Epoch: 24, Batch: 278, Batch Loss: 0.24270778894424438\n",
            "Epoch: 24, Batch: 279, Batch Loss: 0.43899011611938477\n",
            "Epoch: 24, Batch: 280, Batch Loss: 0.4452788829803467\n",
            "Epoch: 24, Batch: 281, Batch Loss: 0.4289008677005768\n",
            "Epoch: 24, Batch: 282, Batch Loss: 0.44790616631507874\n",
            "Epoch: 24, Batch: 283, Batch Loss: 0.2945590913295746\n",
            "Epoch: 24, Batch: 284, Batch Loss: 0.2793909013271332\n",
            "Epoch: 24, Batch: 285, Batch Loss: 0.268360435962677\n",
            "Epoch: 24, Batch: 286, Batch Loss: 0.25759315490722656\n",
            "Epoch: 24, Batch: 287, Batch Loss: 0.38377344608306885\n",
            "Epoch: 24, Batch: 288, Batch Loss: 0.3781968951225281\n",
            "Epoch: 24, Batch: 289, Batch Loss: 0.6447798609733582\n",
            "Epoch: 24, Batch: 290, Batch Loss: 0.33370256423950195\n",
            "Epoch: 24, Batch: 291, Batch Loss: 0.32533973455429077\n",
            "Epoch: 24, Batch: 292, Batch Loss: 0.3095242381095886\n",
            "Epoch: 24, Batch: 293, Batch Loss: 0.3304486870765686\n",
            "Epoch: 24, Batch: 294, Batch Loss: 0.3470405638217926\n",
            "Epoch: 24, Batch: 295, Batch Loss: 0.5458967089653015\n",
            "Epoch: 24, Batch: 296, Batch Loss: 0.3009452819824219\n",
            "Epoch: 24, Batch: 297, Batch Loss: 0.459730863571167\n",
            "Epoch: 24, Batch: 298, Batch Loss: 0.272586852312088\n",
            "Epoch: 24, Batch: 299, Batch Loss: 0.39213842153549194\n",
            "Epoch: 24, Batch: 300, Batch Loss: 0.27496740221977234\n",
            "Epoch: 24, Batch: 301, Batch Loss: 0.3252438008785248\n",
            "Epoch: 24, Batch: 302, Batch Loss: 0.5267741084098816\n",
            "Epoch: 24, Batch: 303, Batch Loss: 0.3258591294288635\n",
            "Epoch: 24, Batch: 304, Batch Loss: 0.16480591893196106\n",
            "Epoch: 24, Batch: 305, Batch Loss: 0.4564630389213562\n",
            "Epoch: 24, Batch: 306, Batch Loss: 0.4935747981071472\n",
            "Epoch: 24, Batch: 307, Batch Loss: 0.287308931350708\n",
            "Epoch: 24, Batch: 308, Batch Loss: 0.5332359075546265\n",
            "Epoch: 24, Batch: 309, Batch Loss: 0.4363393485546112\n",
            "Epoch: 24, Batch: 310, Batch Loss: 0.48713964223861694\n",
            "Epoch: 24, Batch: 311, Batch Loss: 0.5367029905319214\n",
            "Epoch: 24, Batch: 312, Batch Loss: 0.30406898260116577\n",
            "Epoch: 24, Batch: 313, Batch Loss: 0.5330415964126587\n",
            "Epoch: 24, Batch: 314, Batch Loss: 0.2636743485927582\n",
            "Epoch: 24, Batch: 315, Batch Loss: 0.295454204082489\n",
            "Epoch: 24, Batch: 316, Batch Loss: 0.2920960783958435\n",
            "Epoch: 24, Batch: 317, Batch Loss: 0.43770304322242737\n",
            "Epoch: 24, Batch: 318, Batch Loss: 0.36362868547439575\n",
            "Epoch: 24, Batch: 319, Batch Loss: 0.14519880712032318\n",
            "Epoch: 24, Batch: 320, Batch Loss: 0.36819320917129517\n",
            "Epoch: 24, Batch: 321, Batch Loss: 0.4037579894065857\n",
            "Epoch: 24, Batch: 322, Batch Loss: 0.5892148613929749\n",
            "Epoch: 24, Batch: 323, Batch Loss: 0.40412649512290955\n",
            "Epoch: 24, Batch: 324, Batch Loss: 0.3328910768032074\n",
            "Epoch: 24, Batch: 325, Batch Loss: 0.3319789469242096\n",
            "Epoch: 24, Batch: 326, Batch Loss: 0.36962664127349854\n",
            "Epoch: 24, Batch: 327, Batch Loss: 0.41646480560302734\n",
            "Epoch: 24, Batch: 328, Batch Loss: 0.4250304698944092\n",
            "Epoch: 24, Batch: 329, Batch Loss: 0.37742727994918823\n",
            "Epoch: 24, Batch: 330, Batch Loss: 0.4985625743865967\n",
            "Epoch: 24, Batch: 331, Batch Loss: 0.28908243775367737\n",
            "Epoch: 24, Batch: 332, Batch Loss: 0.5349669456481934\n",
            "Epoch: 24, Batch: 333, Batch Loss: 0.42659303545951843\n",
            "Epoch: 24, Batch: 334, Batch Loss: 0.5132672190666199\n",
            "Epoch: 24, Batch: 335, Batch Loss: 0.42461708188056946\n",
            "Epoch: 24, Batch: 336, Batch Loss: 0.45085495710372925\n",
            "Epoch: 24, Batch: 337, Batch Loss: 0.3673461675643921\n",
            "Epoch: 24, Batch: 338, Batch Loss: 0.3791121244430542\n",
            "Epoch: 24, Batch: 339, Batch Loss: 0.4184315502643585\n",
            "Epoch: 24, Batch: 340, Batch Loss: 0.48921480774879456\n",
            "Epoch: 24, Batch: 341, Batch Loss: 0.35348206758499146\n",
            "Epoch: 24, Batch: 342, Batch Loss: 0.1649971902370453\n",
            "Epoch: 24, Batch: 343, Batch Loss: 0.404869019985199\n",
            "Epoch: 24, Batch: 344, Batch Loss: 0.3334605395793915\n",
            "Epoch: 24, Batch: 345, Batch Loss: 0.4004904627799988\n",
            "Epoch: 24, Batch: 346, Batch Loss: 0.23401780426502228\n",
            "Epoch: 24, Batch: 347, Batch Loss: 0.3931170701980591\n",
            "Epoch: 24, Batch: 348, Batch Loss: 0.3171306848526001\n",
            "Epoch: 24, Batch: 349, Batch Loss: 0.29086291790008545\n",
            "Epoch: 24, Batch: 350, Batch Loss: 0.4127986431121826\n",
            "Epoch: 24, Batch: 351, Batch Loss: 0.3646789491176605\n",
            "Epoch: 24, Batch: 352, Batch Loss: 0.364482045173645\n",
            "Epoch: 24, Batch: 353, Batch Loss: 0.5428283214569092\n",
            "Epoch: 24, Batch: 354, Batch Loss: 0.444162517786026\n",
            "Epoch: 24, Batch: 355, Batch Loss: 0.36719784140586853\n",
            "Epoch: 24, Batch: 356, Batch Loss: 0.61390620470047\n",
            "Epoch: 24, Batch: 357, Batch Loss: 0.37429869174957275\n",
            "Epoch: 24, Batch: 358, Batch Loss: 0.39627373218536377\n",
            "Epoch: 24, Batch: 359, Batch Loss: 0.3229227066040039\n",
            "Epoch: 24, Batch: 360, Batch Loss: 0.2617819309234619\n",
            "Epoch: 24, Batch: 361, Batch Loss: 0.23764261603355408\n",
            "Epoch: 24, Batch: 362, Batch Loss: 0.38845303654670715\n",
            "Epoch: 24, Batch: 363, Batch Loss: 0.34211230278015137\n",
            "Epoch: 24, Batch: 364, Batch Loss: 0.5016539096832275\n",
            "Epoch: 24, Batch: 365, Batch Loss: 0.2403579205274582\n",
            "Epoch: 24, Batch: 366, Batch Loss: 0.30540624260902405\n",
            "Epoch: 24, Batch: 367, Batch Loss: 0.22667048871517181\n",
            "Epoch: 24, Batch: 368, Batch Loss: 0.4076958894729614\n",
            "Epoch: 24, Batch: 369, Batch Loss: 0.41000550985336304\n",
            "Epoch: 24, Batch: 370, Batch Loss: 0.47549891471862793\n",
            "Epoch: 24, Batch: 371, Batch Loss: 0.35901233553886414\n",
            "Epoch: 24, Batch: 372, Batch Loss: 0.21964150667190552\n",
            "Epoch: 24, Batch: 373, Batch Loss: 0.48053500056266785\n",
            "Epoch: 24, Batch: 374, Batch Loss: 0.4643091857433319\n",
            "Epoch: 24, Batch: 375, Batch Loss: 0.22610095143318176\n",
            "Epoch: 24, Batch: 376, Batch Loss: 0.21736621856689453\n",
            "Epoch: 24, Batch: 377, Batch Loss: 0.37453779578208923\n",
            "Epoch: 24, Batch: 378, Batch Loss: 0.29492104053497314\n",
            "Epoch: 24, Batch: 379, Batch Loss: 0.2520100772380829\n",
            "Epoch: 24, Batch: 380, Batch Loss: 0.26364490389823914\n",
            "Epoch: 24, Batch: 381, Batch Loss: 0.43122628331184387\n",
            "Epoch: 24, Batch: 382, Batch Loss: 0.3234390616416931\n",
            "Epoch: 24, Batch: 383, Batch Loss: 0.7068552374839783\n",
            "Epoch: 24, Batch: 384, Batch Loss: 0.39831581711769104\n",
            "Epoch: 24, Batch: 385, Batch Loss: 0.4286332130432129\n",
            "Epoch: 24, Batch: 386, Batch Loss: 0.4538044333457947\n",
            "Epoch: 24, Batch: 387, Batch Loss: 0.45843780040740967\n",
            "Epoch: 24, Batch: 388, Batch Loss: 0.3020252585411072\n",
            "Epoch: 24, Batch: 389, Batch Loss: 0.42653223872184753\n",
            "Epoch: 24, Batch: 390, Batch Loss: 0.34989696741104126\n",
            "Epoch: 24, Batch: 391, Batch Loss: 0.26621583104133606\n",
            "Epoch: 24, Batch: 392, Batch Loss: 0.36413925886154175\n",
            "Epoch: 24, Batch: 393, Batch Loss: 0.3026701807975769\n",
            "Epoch: 24, Batch: 394, Batch Loss: 0.3336869478225708\n",
            "Epoch: 24, Batch: 395, Batch Loss: 0.39429977536201477\n",
            "Epoch: 24, Batch: 396, Batch Loss: 0.2800627648830414\n",
            "Epoch: 24, Batch: 397, Batch Loss: 0.4231463074684143\n",
            "Epoch: 24, Batch: 398, Batch Loss: 0.3174338936805725\n",
            "Epoch: 24, Batch: 399, Batch Loss: 0.4749881327152252\n",
            "Epoch: 24, Batch: 400, Batch Loss: 0.23211926221847534\n",
            "Epoch: 24, Batch: 401, Batch Loss: 0.7243466377258301\n",
            "Epoch: 24, Batch: 402, Batch Loss: 0.5099323987960815\n",
            "Epoch: 24, Batch: 403, Batch Loss: 0.3543514311313629\n",
            "Epoch: 24, Batch: 404, Batch Loss: 0.4421922564506531\n",
            "Epoch: 24, Batch: 405, Batch Loss: 0.3776548504829407\n",
            "Epoch: 24, Batch: 406, Batch Loss: 0.42643916606903076\n",
            "Epoch: 24, Batch: 407, Batch Loss: 0.3820226788520813\n",
            "Epoch: 24, Batch: 408, Batch Loss: 0.472804456949234\n",
            "Epoch: 24, Batch: 409, Batch Loss: 0.42538216710090637\n",
            "Epoch: 24, Batch: 410, Batch Loss: 0.347413033246994\n",
            "Epoch: 24, Batch: 411, Batch Loss: 0.5411850214004517\n",
            "Epoch: 24, Batch: 412, Batch Loss: 0.6006067991256714\n",
            "Epoch: 24, Batch: 413, Batch Loss: 0.21531696617603302\n",
            "Epoch: 24, Batch: 414, Batch Loss: 0.4519308805465698\n",
            "Epoch: 24, Batch: 415, Batch Loss: 0.31679752469062805\n",
            "Epoch: 24, Batch: 416, Batch Loss: 0.32999923825263977\n",
            "Epoch: 24, Batch: 417, Batch Loss: 0.3483392596244812\n",
            "Epoch: 24, Batch: 418, Batch Loss: 0.5019693374633789\n",
            "Epoch: 24, Batch: 419, Batch Loss: 0.3881016969680786\n",
            "Epoch: 24, Batch: 420, Batch Loss: 0.43041592836380005\n",
            "Epoch: 24, Batch: 421, Batch Loss: 0.44993430376052856\n",
            "Epoch: 24, Batch: 422, Batch Loss: 0.38447195291519165\n",
            "Epoch: 24, Batch: 423, Batch Loss: 0.24218600988388062\n",
            "Epoch: 24, Batch: 424, Batch Loss: 0.37569019198417664\n",
            "Epoch: 24, Batch: 425, Batch Loss: 0.378973126411438\n",
            "Epoch: 24, Batch: 426, Batch Loss: 0.3035590946674347\n",
            "Epoch: 24, Batch: 427, Batch Loss: 0.36622512340545654\n",
            "Epoch: 24, Batch: 428, Batch Loss: 0.4501645267009735\n",
            "Epoch: 24, Batch: 429, Batch Loss: 0.3320672810077667\n",
            "Epoch: 24, Batch: 430, Batch Loss: 0.24305719137191772\n",
            "Epoch: 24, Batch: 431, Batch Loss: 0.5194418430328369\n",
            "Epoch: 24, Batch: 432, Batch Loss: 0.30041345953941345\n",
            "Epoch: 24, Batch: 433, Batch Loss: 0.3149917423725128\n",
            "Epoch: 24, Batch: 434, Batch Loss: 0.4302195906639099\n",
            "Epoch: 24, Batch: 435, Batch Loss: 0.4837643504142761\n",
            "Epoch: 24, Batch: 436, Batch Loss: 0.3729075789451599\n",
            "Epoch: 24, Batch: 437, Batch Loss: 0.29493895173072815\n",
            "Epoch: 24, Batch: 438, Batch Loss: 0.24918794631958008\n",
            "Epoch: 24, Batch: 439, Batch Loss: 0.18559227883815765\n",
            "Epoch: 24, Batch: 440, Batch Loss: 0.41301271319389343\n",
            "Epoch: 24, Batch: 441, Batch Loss: 0.290779709815979\n",
            "Epoch: 24, Batch: 442, Batch Loss: 0.2512361407279968\n",
            "Epoch: 24, Batch: 443, Batch Loss: 0.4109055697917938\n",
            "Epoch: 24, Batch: 444, Batch Loss: 0.4342411756515503\n",
            "Epoch: 24, Batch: 445, Batch Loss: 0.21153056621551514\n",
            "Epoch: 24, Batch: 446, Batch Loss: 0.2563209533691406\n",
            "Epoch: 24, Batch: 447, Batch Loss: 0.5404119491577148\n",
            "Epoch: 24, Batch: 448, Batch Loss: 0.3856653869152069\n",
            "Epoch: 24, Batch: 449, Batch Loss: 0.4511287212371826\n",
            "Epoch: 24, Batch: 450, Batch Loss: 0.4241688549518585\n",
            "Epoch: 24, Batch: 451, Batch Loss: 0.37464016675949097\n",
            "Epoch: 24, Batch: 452, Batch Loss: 0.38132524490356445\n",
            "Epoch: 24, Batch: 453, Batch Loss: 0.6167191863059998\n",
            "Epoch: 24, Batch: 454, Batch Loss: 0.13800406455993652\n",
            "Epoch: 24, Batch: 455, Batch Loss: 0.3684197962284088\n",
            "Epoch: 24, Batch: 456, Batch Loss: 0.46212056279182434\n",
            "Epoch: 24, Batch: 457, Batch Loss: 0.35892313718795776\n",
            "Epoch: 24, Batch: 458, Batch Loss: 0.3493843674659729\n",
            "Epoch: 24, Batch: 459, Batch Loss: 0.45198947191238403\n",
            "Epoch: 24, Batch: 460, Batch Loss: 0.4540470540523529\n",
            "Epoch: 24, Batch: 461, Batch Loss: 0.25544270873069763\n",
            "Epoch: 24, Batch: 462, Batch Loss: 0.5835816860198975\n",
            "Epoch: 24, Batch: 463, Batch Loss: 0.3411696255207062\n",
            "Epoch: 24, Batch: 464, Batch Loss: 0.3242567181587219\n",
            "Epoch: 24, Batch: 465, Batch Loss: 0.3971020579338074\n",
            "Epoch: 24, Batch: 466, Batch Loss: 0.503374457359314\n",
            "Epoch: 24, Batch: 467, Batch Loss: 0.38322824239730835\n",
            "Epoch: 24, Batch: 468, Batch Loss: 0.1846880465745926\n",
            "Epoch: 24, Batch: 469, Batch Loss: 0.21565362811088562\n",
            "Epoch: 24, Batch: 470, Batch Loss: 0.4284922480583191\n",
            "Epoch: 24, Batch: 471, Batch Loss: 0.42660728096961975\n",
            "Epoch: 24, Batch: 472, Batch Loss: 0.3384479284286499\n",
            "Epoch: 24, Batch: 473, Batch Loss: 0.556099534034729\n",
            "Epoch: 24, Batch: 474, Batch Loss: 0.3868849277496338\n",
            "Epoch: 24, Batch: 475, Batch Loss: 0.2742944657802582\n",
            "Epoch: 24, Batch: 476, Batch Loss: 0.355356365442276\n",
            "Epoch: 24, Batch: 477, Batch Loss: 0.40545737743377686\n",
            "Epoch: 24, Batch: 478, Batch Loss: 0.2939407229423523\n",
            "Epoch: 24, Batch: 479, Batch Loss: 0.4363020062446594\n",
            "Epoch: 24, Batch: 480, Batch Loss: 0.37474325299263\n",
            "Epoch: 24, Batch: 481, Batch Loss: 0.3677724003791809\n",
            "Epoch: 24, Batch: 482, Batch Loss: 0.3709660768508911\n",
            "Epoch: 24, Batch: 483, Batch Loss: 0.38892418146133423\n",
            "Epoch: 24, Batch: 484, Batch Loss: 0.34277355670928955\n",
            "Epoch: 24, Batch: 485, Batch Loss: 0.3860913813114166\n",
            "Epoch: 24, Batch: 486, Batch Loss: 0.5546057820320129\n",
            "Epoch: 24, Batch: 487, Batch Loss: 0.26089465618133545\n",
            "Epoch: 24, Batch: 488, Batch Loss: 0.44312697649002075\n",
            "Epoch: 24, Batch: 489, Batch Loss: 0.4967697560787201\n",
            "Epoch: 24, Batch: 490, Batch Loss: 0.4740506708621979\n",
            "Epoch: 24, Batch: 491, Batch Loss: 0.4043428897857666\n",
            "Epoch: 24, Batch: 492, Batch Loss: 0.39128994941711426\n",
            "Epoch: 24, Batch: 493, Batch Loss: 0.32457220554351807\n",
            "Epoch: 24, Batch: 494, Batch Loss: 0.2945592701435089\n",
            "Epoch: 24, Batch: 495, Batch Loss: 0.406058132648468\n",
            "Epoch: 24, Batch: 496, Batch Loss: 0.31697478890419006\n",
            "Epoch: 24, Batch: 497, Batch Loss: 0.3330020308494568\n",
            "Epoch: 24, Batch: 498, Batch Loss: 0.3247983753681183\n",
            "Epoch: 24, Batch: 499, Batch Loss: 0.3016284108161926\n",
            "Epoch: 24, Batch: 500, Batch Loss: 0.26988932490348816\n",
            "Epoch: 24, Batch: 501, Batch Loss: 0.38892245292663574\n",
            "Epoch: 24, Batch: 502, Batch Loss: 0.33590424060821533\n",
            "Epoch: 24, Batch: 503, Batch Loss: 0.5297331809997559\n",
            "Epoch: 24, Batch: 504, Batch Loss: 0.4939747750759125\n",
            "Epoch: 24, Batch: 505, Batch Loss: 0.3571729063987732\n",
            "Epoch: 24, Batch: 506, Batch Loss: 0.44958457350730896\n",
            "Epoch: 24, Batch: 507, Batch Loss: 0.204545259475708\n",
            "Epoch: 24, Batch: 508, Batch Loss: 0.3947319984436035\n",
            "Epoch: 24, Batch: 509, Batch Loss: 0.29259538650512695\n",
            "Epoch: 24, Batch: 510, Batch Loss: 0.5783072710037231\n",
            "Epoch: 24, Batch: 511, Batch Loss: 0.3092149496078491\n",
            "Epoch: 24, Batch: 512, Batch Loss: 0.31816887855529785\n",
            "Epoch: 24, Batch: 513, Batch Loss: 0.36346492171287537\n",
            "Epoch: 24, Batch: 514, Batch Loss: 0.3529146611690521\n",
            "Epoch: 24, Batch: 515, Batch Loss: 0.352345734834671\n",
            "Epoch: 24, Batch: 516, Batch Loss: 0.3767815828323364\n",
            "Epoch: 24, Batch: 517, Batch Loss: 0.32382142543792725\n",
            "Epoch: 24, Batch: 518, Batch Loss: 0.1449202001094818\n",
            "Epoch: 24, Batch: 519, Batch Loss: 0.43446773290634155\n",
            "Epoch: 24, Batch: 520, Batch Loss: 0.6757975220680237\n",
            "Epoch: 24, Batch: 521, Batch Loss: 0.38371869921684265\n",
            "Epoch: 24, Batch: 522, Batch Loss: 0.26896247267723083\n",
            "Epoch: 24, Batch: 523, Batch Loss: 0.409606397151947\n",
            "Epoch: 24, Batch: 524, Batch Loss: 0.24628373980522156\n",
            "Epoch: 24, Batch: 525, Batch Loss: 0.47316139936447144\n",
            "Epoch: 24, Batch: 526, Batch Loss: 0.45369628071784973\n",
            "Epoch: 24, Batch: 527, Batch Loss: 0.37907299399375916\n",
            "Epoch: 24, Batch: 528, Batch Loss: 0.3308054208755493\n",
            "Epoch: 24, Batch: 529, Batch Loss: 0.28534334897994995\n",
            "Epoch: 24, Batch: 530, Batch Loss: 0.41681456565856934\n",
            "Epoch: 24, Batch: 531, Batch Loss: 0.40375301241874695\n",
            "Epoch: 24, Batch: 532, Batch Loss: 0.3821786046028137\n",
            "Epoch: 24, Batch: 533, Batch Loss: 0.41011375188827515\n",
            "Epoch: 24, Batch: 534, Batch Loss: 0.3029549717903137\n",
            "Epoch: 24, Batch: 535, Batch Loss: 0.2583438754081726\n",
            "Epoch: 24, Batch: 536, Batch Loss: 0.3076038956642151\n",
            "Epoch: 24, Batch: 537, Batch Loss: 0.42293280363082886\n",
            "Epoch: 24, Batch: 538, Batch Loss: 0.37540334463119507\n",
            "Epoch: 24, Batch: 539, Batch Loss: 0.51793372631073\n",
            "Epoch: 24, Batch: 540, Batch Loss: 0.39907532930374146\n",
            "Epoch: 24, Batch: 541, Batch Loss: 0.28640756011009216\n",
            "Epoch: 24, Batch: 542, Batch Loss: 0.2550824284553528\n",
            "Epoch: 24, Batch: 543, Batch Loss: 0.2147999405860901\n",
            "Epoch: 24, Batch: 544, Batch Loss: 0.5750346779823303\n",
            "Epoch: 24, Batch: 545, Batch Loss: 0.29566246271133423\n",
            "Epoch: 24, Batch: 546, Batch Loss: 0.34188908338546753\n",
            "Epoch: 24, Batch: 547, Batch Loss: 0.45814812183380127\n",
            "Epoch: 24, Batch: 548, Batch Loss: 0.30742472410202026\n",
            "Epoch: 24, Batch: 549, Batch Loss: 0.4619086980819702\n",
            "Epoch: 24, Batch: 550, Batch Loss: 0.3226392865180969\n",
            "Epoch: 24, Batch: 551, Batch Loss: 0.37941694259643555\n",
            "Epoch: 24, Batch: 552, Batch Loss: 0.4755154550075531\n",
            "Epoch: 24, Batch: 553, Batch Loss: 0.4007028043270111\n",
            "Epoch: 24, Batch: 554, Batch Loss: 0.2917551100254059\n",
            "Epoch: 24, Batch: 555, Batch Loss: 0.31130075454711914\n",
            "Epoch: 24, Batch: 556, Batch Loss: 0.5021802186965942\n",
            "Epoch: 24, Batch: 557, Batch Loss: 0.3383934199810028\n",
            "Epoch: 24, Batch: 558, Batch Loss: 0.35329318046569824\n",
            "Epoch: 24, Batch: 559, Batch Loss: 0.33983075618743896\n",
            "Epoch: 24, Batch: 560, Batch Loss: 0.33176276087760925\n",
            "Epoch: 24, Batch: 561, Batch Loss: 0.4164646863937378\n",
            "Epoch: 24, Batch: 562, Batch Loss: 0.2926740050315857\n",
            "Epoch: 24, Batch: 563, Batch Loss: 0.3601645827293396\n",
            "Epoch: 24, Batch: 564, Batch Loss: 0.2931205630302429\n",
            "Epoch: 24, Batch: 565, Batch Loss: 0.3502768278121948\n",
            "Epoch: 24, Batch: 566, Batch Loss: 0.32060205936431885\n",
            "Epoch: 24, Batch: 567, Batch Loss: 0.3923741579055786\n",
            "Epoch: 24, Batch: 568, Batch Loss: 0.36387601494789124\n",
            "Epoch: 24, Batch: 569, Batch Loss: 0.5346236824989319\n",
            "Epoch: 24, Batch: 570, Batch Loss: 0.3459453880786896\n",
            "Epoch: 24, Batch: 571, Batch Loss: 0.38008344173431396\n",
            "Epoch: 24, Batch: 572, Batch Loss: 0.4030018448829651\n",
            "Epoch: 24, Batch: 573, Batch Loss: 0.3010389506816864\n",
            "Epoch: 24, Batch: 574, Batch Loss: 0.4014356732368469\n",
            "Epoch: 24, Batch: 575, Batch Loss: 0.33139219880104065\n",
            "Epoch: 24, Batch: 576, Batch Loss: 0.23383969068527222\n",
            "Epoch: 24, Batch: 577, Batch Loss: 0.2696981728076935\n",
            "Epoch: 24, Batch: 578, Batch Loss: 0.30988752841949463\n",
            "Epoch: 24, Batch: 579, Batch Loss: 0.3389301896095276\n",
            "Epoch: 24, Batch: 580, Batch Loss: 0.5420675277709961\n",
            "Epoch: 24, Batch: 581, Batch Loss: 0.2796534299850464\n",
            "Epoch: 24, Batch: 582, Batch Loss: 0.36946314573287964\n",
            "Epoch: 24, Batch: 583, Batch Loss: 0.35633158683776855\n",
            "Epoch: 24, Batch: 584, Batch Loss: 0.28715312480926514\n",
            "Epoch: 24, Batch: 585, Batch Loss: 0.5040522813796997\n",
            "Epoch: 24, Batch: 586, Batch Loss: 0.5101333856582642\n",
            "Epoch: 24, Batch: 587, Batch Loss: 0.4840427339076996\n",
            "Epoch: 24, Batch: 588, Batch Loss: 0.41554370522499084\n",
            "Epoch: 24, Batch: 589, Batch Loss: 0.2473694384098053\n",
            "Epoch: 24, Batch: 590, Batch Loss: 0.5487582087516785\n",
            "Epoch: 24, Batch: 591, Batch Loss: 0.29805460572242737\n",
            "Epoch: 24, Batch: 592, Batch Loss: 0.24630147218704224\n",
            "Epoch: 24, Batch: 593, Batch Loss: 0.43667182326316833\n",
            "Epoch: 24, Batch: 594, Batch Loss: 0.37123599648475647\n",
            "Epoch: 24, Batch: 595, Batch Loss: 0.2656600773334503\n",
            "Epoch: 24, Batch: 596, Batch Loss: 0.4177343249320984\n",
            "Epoch: 24, Batch: 597, Batch Loss: 0.47602006793022156\n",
            "Epoch: 24, Batch: 598, Batch Loss: 0.2862618863582611\n",
            "Epoch: 24, Batch: 599, Batch Loss: 0.5621265172958374\n",
            "Epoch: 24, Batch: 600, Batch Loss: 0.5117559432983398\n",
            "Epoch: 24, Batch: 601, Batch Loss: 0.4204801917076111\n",
            "Epoch: 24, Batch: 602, Batch Loss: 0.40001869201660156\n",
            "Epoch: 24, Batch: 603, Batch Loss: 0.4248710572719574\n",
            "Epoch: 24, Batch: 604, Batch Loss: 0.2624618411064148\n",
            "Epoch: 24, Batch: 605, Batch Loss: 0.29713571071624756\n",
            "Epoch: 24, Batch: 606, Batch Loss: 0.31689751148223877\n",
            "Epoch: 24, Batch: 607, Batch Loss: 0.42411723732948303\n",
            "Epoch: 24, Batch: 608, Batch Loss: 0.4205864369869232\n",
            "Epoch: 24, Batch: 609, Batch Loss: 0.4651292562484741\n",
            "Epoch: 24, Batch: 610, Batch Loss: 0.6130344867706299\n",
            "Epoch: 24, Batch: 611, Batch Loss: 0.3716376721858978\n",
            "Epoch: 24, Batch: 612, Batch Loss: 0.39874058961868286\n",
            "Epoch: 24, Batch: 613, Batch Loss: 0.4240894615650177\n",
            "Epoch: 24, Batch: 614, Batch Loss: 0.3706217110157013\n",
            "Epoch: 24, Batch: 615, Batch Loss: 0.2730368971824646\n",
            "Epoch: 24, Batch: 616, Batch Loss: 0.35643792152404785\n",
            "Epoch: 24, Batch: 617, Batch Loss: 0.38335394859313965\n",
            "Epoch: 24, Batch: 618, Batch Loss: 0.44663089513778687\n",
            "Epoch: 24, Batch: 619, Batch Loss: 0.43810856342315674\n",
            "Epoch: 24, Batch: 620, Batch Loss: 0.3715808093547821\n",
            "Epoch: 24, Batch: 621, Batch Loss: 0.437447726726532\n",
            "Epoch: 24, Batch: 622, Batch Loss: 0.5048733949661255\n",
            "Epoch: 24, Batch: 623, Batch Loss: 0.36570823192596436\n",
            "Epoch: 24, Batch: 624, Batch Loss: 0.3251938819885254\n",
            "Epoch: 24, Batch: 625, Batch Loss: 0.7171444892883301\n",
            "Epoch: 24, Batch: 626, Batch Loss: 0.36298006772994995\n",
            "Epoch: 24, Batch: 627, Batch Loss: 0.41502076387405396\n",
            "Epoch: 24, Batch: 628, Batch Loss: 0.4173673987388611\n",
            "Epoch: 24, Batch: 629, Batch Loss: 0.33031028509140015\n",
            "Epoch: 24, Batch: 630, Batch Loss: 0.32274919748306274\n",
            "Epoch: 24, Batch: 631, Batch Loss: 0.3329855501651764\n",
            "Epoch: 24, Batch: 632, Batch Loss: 0.36318641901016235\n",
            "Epoch: 24, Batch: 633, Batch Loss: 0.25644737482070923\n",
            "Epoch: 24, Batch: 634, Batch Loss: 0.40545207262039185\n",
            "Epoch: 24, Batch: 635, Batch Loss: 0.27596649527549744\n",
            "Epoch: 24, Batch: 636, Batch Loss: 0.19952602684497833\n",
            "Epoch: 24, Batch: 637, Batch Loss: 0.32458409667015076\n",
            "Epoch: 24, Batch: 638, Batch Loss: 0.4008357524871826\n",
            "Epoch: 24, Batch: 639, Batch Loss: 0.22300007939338684\n",
            "Epoch: 24, Batch: 640, Batch Loss: 0.25304776430130005\n",
            "Epoch: 24, Batch: 641, Batch Loss: 0.2715204358100891\n",
            "Epoch: 24, Batch: 642, Batch Loss: 0.5712527632713318\n",
            "Epoch: 24, Batch: 643, Batch Loss: 0.5189607739448547\n",
            "Epoch: 24, Batch: 644, Batch Loss: 0.3760509788990021\n",
            "Epoch: 24, Batch: 645, Batch Loss: 0.33395451307296753\n",
            "Epoch: 24, Batch: 646, Batch Loss: 0.2576751708984375\n",
            "Epoch: 24, Batch: 647, Batch Loss: 0.33604907989501953\n",
            "Epoch: 24, Batch: 648, Batch Loss: 0.4139654040336609\n",
            "Epoch: 24, Batch: 649, Batch Loss: 0.431959867477417\n",
            "Epoch: 24, Batch: 650, Batch Loss: 0.2761448323726654\n",
            "Epoch: 24, Batch: 651, Batch Loss: 0.2686585783958435\n",
            "Epoch: 24, Batch: 652, Batch Loss: 0.25992873311042786\n",
            "Epoch: 24, Batch: 653, Batch Loss: 0.30738168954849243\n",
            "Epoch: 24, Batch: 654, Batch Loss: 0.20437125861644745\n",
            "Epoch: 24, Batch: 655, Batch Loss: 0.3402021527290344\n",
            "Epoch: 24, Batch: 656, Batch Loss: 0.4993878901004791\n",
            "Epoch: 24, Batch: 657, Batch Loss: 0.35391154885292053\n",
            "Epoch: 24, Batch: 658, Batch Loss: 0.3383290767669678\n",
            "Epoch: 24, Batch: 659, Batch Loss: 0.31730079650878906\n",
            "Epoch: 24, Batch: 660, Batch Loss: 0.3498392105102539\n",
            "Epoch: 24, Batch: 661, Batch Loss: 0.283304363489151\n",
            "Epoch: 24, Batch: 662, Batch Loss: 0.31835997104644775\n",
            "Epoch: 24, Batch: 663, Batch Loss: 0.3344120979309082\n",
            "Epoch: 24, Batch: 664, Batch Loss: 0.3477432131767273\n",
            "Epoch: 24, Batch: 665, Batch Loss: 0.402811735868454\n",
            "Epoch: 24, Batch: 666, Batch Loss: 0.4093404710292816\n",
            "Epoch: 24, Batch: 667, Batch Loss: 0.4191214144229889\n",
            "Epoch: 24, Batch: 668, Batch Loss: 0.25555211305618286\n",
            "Epoch: 24, Batch: 669, Batch Loss: 0.4801103472709656\n",
            "Epoch: 24, Batch: 670, Batch Loss: 0.4390704333782196\n",
            "Epoch: 24, Batch: 671, Batch Loss: 0.33882346749305725\n",
            "Epoch: 24, Batch: 672, Batch Loss: 0.3452710807323456\n",
            "Epoch: 24, Batch: 673, Batch Loss: 0.3589273691177368\n",
            "Epoch: 24, Batch: 674, Batch Loss: 0.637540340423584\n",
            "Epoch: 24, Batch: 675, Batch Loss: 0.3043641448020935\n",
            "Epoch: 24, Batch: 676, Batch Loss: 0.32996666431427\n",
            "Epoch: 24, Batch: 677, Batch Loss: 0.37471383810043335\n",
            "Epoch: 24, Batch: 678, Batch Loss: 0.4106154441833496\n",
            "Epoch: 24, Batch: 679, Batch Loss: 0.5203754305839539\n",
            "Epoch: 24, Batch: 680, Batch Loss: 0.2258053719997406\n",
            "Epoch: 24, Batch: 681, Batch Loss: 0.2882797420024872\n",
            "Epoch: 24, Batch: 682, Batch Loss: 0.4713748097419739\n",
            "Epoch: 24, Batch: 683, Batch Loss: 0.4174917936325073\n",
            "Epoch: 24, Batch: 684, Batch Loss: 0.2713541090488434\n",
            "Epoch: 24, Batch: 685, Batch Loss: 0.27035754919052124\n",
            "Epoch: 24, Batch: 686, Batch Loss: 0.3711937367916107\n",
            "Epoch: 24, Batch: 687, Batch Loss: 0.3233548402786255\n",
            "Epoch: 24, Batch: 688, Batch Loss: 0.39635100960731506\n",
            "Epoch: 24, Batch: 689, Batch Loss: 0.30381473898887634\n",
            "Epoch: 24, Batch: 690, Batch Loss: 0.50923091173172\n",
            "Epoch: 24, Batch: 691, Batch Loss: 0.29059112071990967\n",
            "Epoch: 24, Batch: 692, Batch Loss: 0.468034952878952\n",
            "Epoch: 24, Batch: 693, Batch Loss: 0.40383094549179077\n",
            "Epoch: 24, Batch: 694, Batch Loss: 0.3845684826374054\n",
            "Epoch: 24, Batch: 695, Batch Loss: 0.33759695291519165\n",
            "Epoch: 24, Batch: 696, Batch Loss: 0.5044247508049011\n",
            "Epoch: 24, Batch: 697, Batch Loss: 0.3289671540260315\n",
            "Epoch: 24, Batch: 698, Batch Loss: 0.6410757303237915\n",
            "Epoch: 24, Batch: 699, Batch Loss: 0.367168664932251\n",
            "Epoch: 24, Batch: 700, Batch Loss: 0.45446574687957764\n",
            "Epoch: 24, Batch: 701, Batch Loss: 0.41121751070022583\n",
            "Epoch: 24, Batch: 702, Batch Loss: 0.24114678800106049\n",
            "Epoch: 24, Batch: 703, Batch Loss: 0.35946422815322876\n",
            "Epoch: 24, Batch: 704, Batch Loss: 0.4614013433456421\n",
            "Epoch: 24, Batch: 705, Batch Loss: 0.6386515498161316\n",
            "Epoch: 24, Batch: 706, Batch Loss: 0.36267173290252686\n",
            "Epoch: 24, Batch: 707, Batch Loss: 0.37012964487075806\n",
            "Epoch: 24, Batch: 708, Batch Loss: 0.28092777729034424\n",
            "Epoch: 24, Batch: 709, Batch Loss: 0.30953317880630493\n",
            "Epoch: 24, Batch: 710, Batch Loss: 0.36051616072654724\n",
            "Epoch: 24, Batch: 711, Batch Loss: 0.31813398003578186\n",
            "Epoch: 24, Batch: 712, Batch Loss: 0.3833804428577423\n",
            "Epoch: 24, Batch: 713, Batch Loss: 0.42424631118774414\n",
            "Epoch: 24, Batch: 714, Batch Loss: 0.22500839829444885\n",
            "Epoch: 24, Batch: 715, Batch Loss: 0.5175119638442993\n",
            "Epoch: 24, Batch: 716, Batch Loss: 0.42632484436035156\n",
            "Epoch: 24, Batch: 717, Batch Loss: 0.3112143278121948\n",
            "Epoch: 24, Batch: 718, Batch Loss: 0.3695812523365021\n",
            "Epoch: 24, Batch: 719, Batch Loss: 0.5174017548561096\n",
            "Epoch: 24, Batch: 720, Batch Loss: 0.4786938726902008\n",
            "Epoch: 24, Batch: 721, Batch Loss: 0.3529341220855713\n",
            "Epoch: 24, Batch: 722, Batch Loss: 0.4718352258205414\n",
            "Epoch: 24, Batch: 723, Batch Loss: 0.3495677709579468\n",
            "Epoch: 24, Batch: 724, Batch Loss: 0.2276908904314041\n",
            "Epoch: 24, Batch: 725, Batch Loss: 0.39434540271759033\n",
            "Epoch: 24, Batch: 726, Batch Loss: 0.51683109998703\n",
            "Epoch: 24, Batch: 727, Batch Loss: 0.33473193645477295\n",
            "Epoch: 24, Batch: 728, Batch Loss: 0.36619776487350464\n",
            "Epoch: 24, Batch: 729, Batch Loss: 0.26100677251815796\n",
            "Epoch: 24, Batch: 730, Batch Loss: 0.33995747566223145\n",
            "Epoch: 24, Batch: 731, Batch Loss: 0.389065146446228\n",
            "Epoch: 24, Batch: 732, Batch Loss: 0.23959404230117798\n",
            "Epoch: 24, Batch: 733, Batch Loss: 0.4181104004383087\n",
            "Epoch: 24, Batch: 734, Batch Loss: 0.3268936276435852\n",
            "Epoch: 24, Batch: 735, Batch Loss: 0.35398590564727783\n",
            "Epoch: 24, Batch: 736, Batch Loss: 0.4010103940963745\n",
            "Epoch: 24, Batch: 737, Batch Loss: 0.29460570216178894\n",
            "Epoch: 24, Batch: 738, Batch Loss: 0.41133466362953186\n",
            "Epoch: 24, Batch: 739, Batch Loss: 0.3977718949317932\n",
            "Epoch: 24, Batch: 740, Batch Loss: 0.4911019504070282\n",
            "Epoch: 24, Batch: 741, Batch Loss: 0.6067056059837341\n",
            "Epoch: 24, Batch: 742, Batch Loss: 0.29055628180503845\n",
            "Epoch: 24, Batch: 743, Batch Loss: 0.3903810679912567\n",
            "Epoch: 24, Batch: 744, Batch Loss: 0.3725004196166992\n",
            "Epoch: 24, Batch: 745, Batch Loss: 0.2949758470058441\n",
            "Epoch: 24, Batch: 746, Batch Loss: 0.32454559206962585\n",
            "Epoch: 24, Batch: 747, Batch Loss: 0.4121723175048828\n",
            "Epoch: 24, Batch: 748, Batch Loss: 0.2433096170425415\n",
            "Epoch: 24, Batch: 749, Batch Loss: 0.191252201795578\n",
            "Epoch: 24, Batch: 750, Batch Loss: 0.3827138841152191\n",
            "Epoch: 24, Batch: 751, Batch Loss: 0.3625956177711487\n",
            "Epoch: 24, Batch: 752, Batch Loss: 0.5106014013290405\n",
            "Epoch: 24, Batch: 753, Batch Loss: 0.7059853076934814\n",
            "Epoch: 24, Batch: 754, Batch Loss: 0.3498735725879669\n",
            "Epoch: 24, Batch: 755, Batch Loss: 0.31393322348594666\n",
            "Epoch: 24, Batch: 756, Batch Loss: 0.3886339068412781\n",
            "Epoch: 24, Batch: 757, Batch Loss: 0.3041621446609497\n",
            "Epoch: 24, Batch: 758, Batch Loss: 0.3637489974498749\n",
            "Epoch: 24, Batch: 759, Batch Loss: 0.44019314646720886\n",
            "Epoch: 24, Batch: 760, Batch Loss: 0.20264388620853424\n",
            "Epoch: 24, Batch: 761, Batch Loss: 0.5755446553230286\n",
            "Epoch: 24, Batch: 762, Batch Loss: 0.3154262900352478\n",
            "Epoch: 24, Batch: 763, Batch Loss: 0.46354910731315613\n",
            "Epoch: 24, Batch: 764, Batch Loss: 0.5108318328857422\n",
            "Epoch: 24, Batch: 765, Batch Loss: 0.3914647698402405\n",
            "Epoch: 24, Batch: 766, Batch Loss: 0.42688289284706116\n",
            "Epoch: 24, Batch: 767, Batch Loss: 0.35676369071006775\n",
            "Epoch: 24, Batch: 768, Batch Loss: 0.5297370553016663\n",
            "Epoch: 24, Batch: 769, Batch Loss: 0.28896793723106384\n",
            "Epoch: 24, Batch: 770, Batch Loss: 0.24426791071891785\n",
            "Epoch: 24, Batch: 771, Batch Loss: 0.2906310260295868\n",
            "Epoch: 24, Batch: 772, Batch Loss: 0.3620583713054657\n",
            "Epoch: 24, Batch: 773, Batch Loss: 0.4848555028438568\n",
            "Epoch: 24, Batch: 774, Batch Loss: 0.3818928897380829\n",
            "Epoch: 24, Batch: 775, Batch Loss: 0.325601726770401\n",
            "Epoch: 24, Batch: 776, Batch Loss: 0.2944279611110687\n",
            "Epoch: 24, Batch: 777, Batch Loss: 0.4195600152015686\n",
            "Epoch: 24, Batch: 778, Batch Loss: 0.9216524362564087\n",
            "Epoch: 24, Batch: 779, Batch Loss: 0.41068944334983826\n",
            "Epoch: 24, Batch: 780, Batch Loss: 0.2519703805446625\n",
            "Epoch: 24, Batch: 781, Batch Loss: 0.2843581438064575\n",
            "Epoch: 24, Batch: 782, Batch Loss: 0.28757476806640625\n",
            "Epoch: 24, Batch: 783, Batch Loss: 0.42880406975746155\n",
            "Epoch: 24, Batch: 784, Batch Loss: 0.18009400367736816\n",
            "Epoch: 24, Batch: 785, Batch Loss: 0.3050397038459778\n",
            "Epoch: 24, Batch: 786, Batch Loss: 0.25098803639411926\n",
            "Epoch: 24, Batch: 787, Batch Loss: 0.35165780782699585\n",
            "Epoch: 24, Batch: 788, Batch Loss: 0.3895949423313141\n",
            "Epoch: 24, Batch: 789, Batch Loss: 0.273468017578125\n",
            "Epoch: 24, Batch: 790, Batch Loss: 0.36248624324798584\n",
            "Epoch: 24, Batch: 791, Batch Loss: 0.30835244059562683\n",
            "Epoch: 24, Batch: 792, Batch Loss: 0.35124677419662476\n",
            "Epoch: 24, Batch: 793, Batch Loss: 0.5562245845794678\n",
            "Epoch: 24, Batch: 794, Batch Loss: 0.2665059566497803\n",
            "Epoch: 24, Batch: 795, Batch Loss: 0.8206434845924377\n",
            "Epoch: 24, Batch: 796, Batch Loss: 0.49783578515052795\n",
            "Epoch: 24, Batch: 797, Batch Loss: 0.37588080763816833\n",
            "Epoch: 24, Batch: 798, Batch Loss: 0.3381004333496094\n",
            "Epoch: 24, Batch: 799, Batch Loss: 0.20171935856342316\n",
            "Epoch: 24, Batch: 800, Batch Loss: 0.3847563862800598\n",
            "Epoch: 24, Batch: 801, Batch Loss: 0.3898470103740692\n",
            "Epoch: 24, Batch: 802, Batch Loss: 0.2739049792289734\n",
            "Epoch: 24, Batch: 803, Batch Loss: 0.6101667284965515\n",
            "Epoch: 24, Batch: 804, Batch Loss: 0.37804463505744934\n",
            "Epoch: 24, Batch: 805, Batch Loss: 0.4216247797012329\n",
            "Epoch: 24, Batch: 806, Batch Loss: 0.5448617339134216\n",
            "Epoch: 24, Batch: 807, Batch Loss: 0.3273504078388214\n",
            "Epoch: 24, Batch: 808, Batch Loss: 0.3329547941684723\n",
            "Epoch: 24, Batch: 809, Batch Loss: 0.42458847165107727\n",
            "Epoch: 24, Batch: 810, Batch Loss: 0.28085067868232727\n",
            "Epoch: 24, Batch: 811, Batch Loss: 0.39737755060195923\n",
            "Epoch: 24, Batch: 812, Batch Loss: 0.30959510803222656\n",
            "Epoch: 24, Batch: 813, Batch Loss: 0.4229929745197296\n",
            "Epoch: 24, Batch: 814, Batch Loss: 0.32780954241752625\n",
            "Epoch: 24, Batch: 815, Batch Loss: 0.5290946960449219\n",
            "Epoch: 24, Batch: 816, Batch Loss: 0.3225555121898651\n",
            "Epoch: 24, Batch: 817, Batch Loss: 0.41481947898864746\n",
            "Epoch: 24, Batch: 818, Batch Loss: 0.24312765896320343\n",
            "Epoch: 24, Batch: 819, Batch Loss: 0.2749091386795044\n",
            "Epoch: 24, Batch: 820, Batch Loss: 0.4409194588661194\n",
            "Epoch: 24, Batch: 821, Batch Loss: 0.30039286613464355\n",
            "Epoch: 24, Batch: 822, Batch Loss: 0.44482553005218506\n",
            "Epoch: 24, Batch: 823, Batch Loss: 0.34791725873947144\n",
            "Epoch: 24, Batch: 824, Batch Loss: 0.593753457069397\n",
            "Epoch: 24, Batch: 825, Batch Loss: 0.35742396116256714\n",
            "Epoch: 24, Batch: 826, Batch Loss: 0.4449540078639984\n",
            "Epoch: 24, Batch: 827, Batch Loss: 0.3796418011188507\n",
            "Epoch: 24, Batch: 828, Batch Loss: 0.21002162992954254\n",
            "Epoch: 24, Batch: 829, Batch Loss: 0.3032378554344177\n",
            "Epoch: 24, Batch: 830, Batch Loss: 0.35089701414108276\n",
            "Epoch: 24, Batch: 831, Batch Loss: 0.3201369643211365\n",
            "Epoch: 24, Batch: 832, Batch Loss: 0.34531280398368835\n",
            "Epoch: 24, Batch: 833, Batch Loss: 0.2907657027244568\n",
            "Epoch: 24, Batch: 834, Batch Loss: 0.21922601759433746\n",
            "Epoch: 24, Batch: 835, Batch Loss: 0.32754987478256226\n",
            "Epoch: 24, Batch: 836, Batch Loss: 0.49967852234840393\n",
            "Epoch: 24, Batch: 837, Batch Loss: 0.35061749815940857\n",
            "Epoch: 24, Batch: 838, Batch Loss: 0.6134991645812988\n",
            "Epoch: 24, Batch: 839, Batch Loss: 0.2895946800708771\n",
            "Epoch: 24, Batch: 840, Batch Loss: 0.2761761248111725\n",
            "Epoch: 24, Batch: 841, Batch Loss: 0.35521143674850464\n",
            "Epoch: 24, Batch: 842, Batch Loss: 0.37809550762176514\n",
            "Epoch: 24, Batch: 843, Batch Loss: 0.2671976685523987\n",
            "Epoch: 24, Batch: 844, Batch Loss: 0.3876878023147583\n",
            "Epoch: 24, Batch: 845, Batch Loss: 0.3019390404224396\n",
            "Epoch: 24, Batch: 846, Batch Loss: 0.32998448610305786\n",
            "Epoch: 24, Batch: 847, Batch Loss: 0.2749191224575043\n",
            "Epoch: 24, Batch: 848, Batch Loss: 0.33081337809562683\n",
            "Epoch: 24, Batch: 849, Batch Loss: 0.5610084533691406\n",
            "Epoch: 24, Batch: 850, Batch Loss: 0.4090753197669983\n",
            "Epoch: 24, Batch: 851, Batch Loss: 0.2534487843513489\n",
            "Epoch: 24, Batch: 852, Batch Loss: 0.3869154751300812\n",
            "Epoch: 24, Batch: 853, Batch Loss: 0.3179316818714142\n",
            "Epoch: 24, Batch: 854, Batch Loss: 0.43973103165626526\n",
            "Epoch: 24, Batch: 855, Batch Loss: 0.6377282738685608\n",
            "Epoch: 24, Batch: 856, Batch Loss: 0.36858227849006653\n",
            "Epoch: 24, Batch: 857, Batch Loss: 0.3445258140563965\n",
            "Epoch: 24, Batch: 858, Batch Loss: 0.49044978618621826\n",
            "Epoch: 24, Batch: 859, Batch Loss: 0.3758661150932312\n",
            "Epoch: 24, Batch: 860, Batch Loss: 0.42580389976501465\n",
            "Epoch: 24, Batch: 861, Batch Loss: 0.27668336033821106\n",
            "Epoch: 24, Batch: 862, Batch Loss: 0.26405513286590576\n",
            "Epoch: 24, Batch: 863, Batch Loss: 0.4793415069580078\n",
            "Epoch: 24, Batch: 864, Batch Loss: 0.3975176513195038\n",
            "Epoch: 24, Batch: 865, Batch Loss: 0.3813905715942383\n",
            "Epoch: 24, Batch: 866, Batch Loss: 0.4242323935031891\n",
            "Epoch: 24, Batch: 867, Batch Loss: 0.328029602766037\n",
            "Epoch: 24, Batch: 868, Batch Loss: 0.3714464604854584\n",
            "Epoch: 24, Batch: 869, Batch Loss: 0.3176829516887665\n",
            "Epoch: 24, Batch: 870, Batch Loss: 0.36900755763053894\n",
            "Epoch: 24, Batch: 871, Batch Loss: 0.26667046546936035\n",
            "Epoch: 24, Batch: 872, Batch Loss: 0.27712857723236084\n",
            "Epoch: 24, Batch: 873, Batch Loss: 0.27902650833129883\n",
            "Epoch: 24, Batch: 874, Batch Loss: 0.4981737732887268\n",
            "Epoch: 24, Batch: 875, Batch Loss: 0.43839138746261597\n",
            "Epoch: 24, Batch: 876, Batch Loss: 0.4736993610858917\n",
            "Epoch: 24, Batch: 877, Batch Loss: 0.3066738545894623\n",
            "Epoch: 24, Batch: 878, Batch Loss: 0.3756534457206726\n",
            "Epoch: 24, Batch: 879, Batch Loss: 0.289864718914032\n",
            "Epoch: 24, Batch: 880, Batch Loss: 0.31851187348365784\n",
            "Epoch: 24, Batch: 881, Batch Loss: 0.289598286151886\n",
            "Epoch: 24, Batch: 882, Batch Loss: 0.3628806471824646\n",
            "Epoch: 24, Batch: 883, Batch Loss: 0.37316083908081055\n",
            "Epoch: 24, Batch: 884, Batch Loss: 0.33083683252334595\n",
            "Epoch: 24, Batch: 885, Batch Loss: 0.37816864252090454\n",
            "Epoch: 24, Batch: 886, Batch Loss: 0.4156281352043152\n",
            "Epoch: 24, Batch: 887, Batch Loss: 0.5338366031646729\n",
            "Epoch: 24, Batch: 888, Batch Loss: 0.219689279794693\n",
            "Epoch: 24, Batch: 889, Batch Loss: 0.37866395711898804\n",
            "Epoch: 24, Batch: 890, Batch Loss: 0.382058709859848\n",
            "Epoch: 24, Batch: 891, Batch Loss: 0.380476713180542\n",
            "Epoch: 24, Batch: 892, Batch Loss: 0.4280381202697754\n",
            "Epoch: 24, Batch: 893, Batch Loss: 0.5202749371528625\n",
            "Epoch: 24, Batch: 894, Batch Loss: 0.6962946057319641\n",
            "Epoch: 24, Batch: 895, Batch Loss: 0.3309357464313507\n",
            "Epoch: 24, Batch: 896, Batch Loss: 0.5783475637435913\n",
            "Epoch: 24, Batch: 897, Batch Loss: 0.22085320949554443\n",
            "Epoch: 24, Batch: 898, Batch Loss: 0.5811864733695984\n",
            "Epoch: 24, Batch: 899, Batch Loss: 0.2604559063911438\n",
            "Epoch: 24, Batch: 900, Batch Loss: 0.3046853542327881\n",
            "Epoch: 24, Batch: 901, Batch Loss: 0.35743293166160583\n",
            "Epoch: 24, Batch: 902, Batch Loss: 0.3450624346733093\n",
            "Epoch: 24, Batch: 903, Batch Loss: 0.6838140487670898\n",
            "Epoch: 24, Batch: 904, Batch Loss: 0.32144346833229065\n",
            "Epoch: 24, Batch: 905, Batch Loss: 0.23818746209144592\n",
            "Epoch: 24, Batch: 906, Batch Loss: 0.3136846423149109\n",
            "Epoch: 24, Batch: 907, Batch Loss: 0.26609933376312256\n",
            "Epoch: 24, Batch: 908, Batch Loss: 0.3318288028240204\n",
            "Epoch: 24, Batch: 909, Batch Loss: 0.5368590354919434\n",
            "Epoch: 24, Batch: 910, Batch Loss: 0.27979183197021484\n",
            "Epoch: 24, Batch: 911, Batch Loss: 0.46175846457481384\n",
            "Epoch: 24, Batch: 912, Batch Loss: 0.3985625207424164\n",
            "Epoch: 24, Batch: 913, Batch Loss: 0.2896941900253296\n",
            "Epoch: 24, Batch: 914, Batch Loss: 0.5245596170425415\n",
            "Epoch: 24, Batch: 915, Batch Loss: 0.28326526284217834\n",
            "Epoch: 24, Batch: 916, Batch Loss: 0.261932373046875\n",
            "Epoch: 24, Batch: 917, Batch Loss: 0.35266435146331787\n",
            "Epoch: 24, Batch: 918, Batch Loss: 0.26668018102645874\n",
            "Epoch: 24, Batch: 919, Batch Loss: 0.4165950417518616\n",
            "Epoch: 24, Batch: 920, Batch Loss: 0.5324272513389587\n",
            "Epoch: 24, Batch: 921, Batch Loss: 0.46856802701950073\n",
            "Epoch: 24, Batch: 922, Batch Loss: 0.3997606933116913\n",
            "Epoch: 24, Batch: 923, Batch Loss: 0.2581821084022522\n",
            "Epoch: 24, Batch: 924, Batch Loss: 0.41567137837409973\n",
            "Epoch: 24, Batch: 925, Batch Loss: 0.5644418597221375\n",
            "Epoch: 24, Batch: 926, Batch Loss: 0.29068735241889954\n",
            "Epoch: 24, Batch: 927, Batch Loss: 0.5074567198753357\n",
            "Epoch: 24, Batch: 928, Batch Loss: 0.3634267747402191\n",
            "Epoch: 24, Batch: 929, Batch Loss: 0.3361794352531433\n",
            "Epoch: 24, Batch: 930, Batch Loss: 0.321685254573822\n",
            "Epoch: 24, Batch: 931, Batch Loss: 0.2699353098869324\n",
            "Epoch: 24, Batch: 932, Batch Loss: 0.44139182567596436\n",
            "Epoch: 24, Batch: 933, Batch Loss: 0.42850103974342346\n",
            "Epoch: 24, Batch: 934, Batch Loss: 0.3881911039352417\n",
            "Epoch: 24, Batch: 935, Batch Loss: 0.4546155631542206\n",
            "Epoch: 24, Batch: 936, Batch Loss: 0.45298898220062256\n",
            "Epoch: 24, Batch: 937, Batch Loss: 0.38979852199554443\n",
            "Accuracy of train set: 0.8662333333333333\n",
            "Epoch: 24, Batch: 0, test Batch Loss: 0.557915449142456\n",
            "Epoch: 24, Batch: 1, test Batch Loss: 0.3124377429485321\n",
            "Epoch: 24, Batch: 2, test Batch Loss: 0.43536433577537537\n",
            "Epoch: 24, Batch: 3, test Batch Loss: 0.31851303577423096\n",
            "Epoch: 24, Batch: 4, test Batch Loss: 0.4646194875240326\n",
            "Epoch: 24, Batch: 5, test Batch Loss: 0.5379698276519775\n",
            "Epoch: 24, Batch: 6, test Batch Loss: 0.3243768513202667\n",
            "Epoch: 24, Batch: 7, test Batch Loss: 0.460527628660202\n",
            "Epoch: 24, Batch: 8, test Batch Loss: 0.38369807600975037\n",
            "Epoch: 24, Batch: 9, test Batch Loss: 0.4710509777069092\n",
            "Epoch: 24, Batch: 10, test Batch Loss: 0.38352781534194946\n",
            "Epoch: 24, Batch: 11, test Batch Loss: 0.42900294065475464\n",
            "Epoch: 24, Batch: 12, test Batch Loss: 0.43821096420288086\n",
            "Epoch: 24, Batch: 13, test Batch Loss: 0.31286877393722534\n",
            "Epoch: 24, Batch: 14, test Batch Loss: 0.42937207221984863\n",
            "Epoch: 24, Batch: 15, test Batch Loss: 0.3193531632423401\n",
            "Epoch: 24, Batch: 16, test Batch Loss: 0.3020172715187073\n",
            "Epoch: 24, Batch: 17, test Batch Loss: 0.4298771023750305\n",
            "Epoch: 24, Batch: 18, test Batch Loss: 0.512967586517334\n",
            "Epoch: 24, Batch: 19, test Batch Loss: 0.31525224447250366\n",
            "Epoch: 24, Batch: 20, test Batch Loss: 0.2922789454460144\n",
            "Epoch: 24, Batch: 21, test Batch Loss: 0.37524622678756714\n",
            "Epoch: 24, Batch: 22, test Batch Loss: 0.6500139832496643\n",
            "Epoch: 24, Batch: 23, test Batch Loss: 0.4572750926017761\n",
            "Epoch: 24, Batch: 24, test Batch Loss: 0.3534599244594574\n",
            "Epoch: 24, Batch: 25, test Batch Loss: 0.5873531103134155\n",
            "Epoch: 24, Batch: 26, test Batch Loss: 0.2772914469242096\n",
            "Epoch: 24, Batch: 27, test Batch Loss: 0.6181004643440247\n",
            "Epoch: 24, Batch: 28, test Batch Loss: 0.6860254406929016\n",
            "Epoch: 24, Batch: 29, test Batch Loss: 0.3341526985168457\n",
            "Epoch: 24, Batch: 30, test Batch Loss: 0.5537216663360596\n",
            "Epoch: 24, Batch: 31, test Batch Loss: 0.2961919903755188\n",
            "Epoch: 24, Batch: 32, test Batch Loss: 0.2775527834892273\n",
            "Epoch: 24, Batch: 33, test Batch Loss: 0.4358561038970947\n",
            "Epoch: 24, Batch: 34, test Batch Loss: 0.36119380593299866\n",
            "Epoch: 24, Batch: 35, test Batch Loss: 0.6169909834861755\n",
            "Epoch: 24, Batch: 36, test Batch Loss: 0.38014283776283264\n",
            "Epoch: 24, Batch: 37, test Batch Loss: 0.4395792484283447\n",
            "Epoch: 24, Batch: 38, test Batch Loss: 0.520708441734314\n",
            "Epoch: 24, Batch: 39, test Batch Loss: 0.3017139136791229\n",
            "Epoch: 24, Batch: 40, test Batch Loss: 0.4316188097000122\n",
            "Epoch: 24, Batch: 41, test Batch Loss: 0.708329439163208\n",
            "Epoch: 24, Batch: 42, test Batch Loss: 0.5406310558319092\n",
            "Epoch: 24, Batch: 43, test Batch Loss: 0.4303399324417114\n",
            "Epoch: 24, Batch: 44, test Batch Loss: 0.3899354934692383\n",
            "Epoch: 24, Batch: 45, test Batch Loss: 0.6097766160964966\n",
            "Epoch: 24, Batch: 46, test Batch Loss: 0.31331300735473633\n",
            "Epoch: 24, Batch: 47, test Batch Loss: 0.2934367060661316\n",
            "Epoch: 24, Batch: 48, test Batch Loss: 0.35623878240585327\n",
            "Epoch: 24, Batch: 49, test Batch Loss: 0.506352961063385\n",
            "Epoch: 24, Batch: 50, test Batch Loss: 0.3619660437107086\n",
            "Epoch: 24, Batch: 51, test Batch Loss: 0.37706276774406433\n",
            "Epoch: 24, Batch: 52, test Batch Loss: 0.4499858021736145\n",
            "Epoch: 24, Batch: 53, test Batch Loss: 0.36182406544685364\n",
            "Epoch: 24, Batch: 54, test Batch Loss: 0.4740248918533325\n",
            "Epoch: 24, Batch: 55, test Batch Loss: 0.696575403213501\n",
            "Epoch: 24, Batch: 56, test Batch Loss: 0.3836294412612915\n",
            "Epoch: 24, Batch: 57, test Batch Loss: 0.4343689978122711\n",
            "Epoch: 24, Batch: 58, test Batch Loss: 0.29964518547058105\n",
            "Epoch: 24, Batch: 59, test Batch Loss: 0.48486900329589844\n",
            "Epoch: 24, Batch: 60, test Batch Loss: 0.4448353946208954\n",
            "Epoch: 24, Batch: 61, test Batch Loss: 0.23533296585083008\n",
            "Epoch: 24, Batch: 62, test Batch Loss: 0.42922064661979675\n",
            "Epoch: 24, Batch: 63, test Batch Loss: 0.38941115140914917\n",
            "Epoch: 24, Batch: 64, test Batch Loss: 0.3715890347957611\n",
            "Epoch: 24, Batch: 65, test Batch Loss: 0.3646763265132904\n",
            "Epoch: 24, Batch: 66, test Batch Loss: 0.310859739780426\n",
            "Epoch: 24, Batch: 67, test Batch Loss: 0.51609867811203\n",
            "Epoch: 24, Batch: 68, test Batch Loss: 0.37243637442588806\n",
            "Epoch: 24, Batch: 69, test Batch Loss: 0.42451536655426025\n",
            "Epoch: 24, Batch: 70, test Batch Loss: 0.5101348161697388\n",
            "Epoch: 24, Batch: 71, test Batch Loss: 0.3690049648284912\n",
            "Epoch: 24, Batch: 72, test Batch Loss: 0.31792187690734863\n",
            "Epoch: 24, Batch: 73, test Batch Loss: 0.272879421710968\n",
            "Epoch: 24, Batch: 74, test Batch Loss: 0.5349316000938416\n",
            "Epoch: 24, Batch: 75, test Batch Loss: 0.5165183544158936\n",
            "Epoch: 24, Batch: 76, test Batch Loss: 0.6050117611885071\n",
            "Epoch: 24, Batch: 77, test Batch Loss: 0.6128286719322205\n",
            "Epoch: 24, Batch: 78, test Batch Loss: 0.6156836748123169\n",
            "Epoch: 24, Batch: 79, test Batch Loss: 0.42611628770828247\n",
            "Epoch: 24, Batch: 80, test Batch Loss: 0.3887570798397064\n",
            "Epoch: 24, Batch: 81, test Batch Loss: 0.39827823638916016\n",
            "Epoch: 24, Batch: 82, test Batch Loss: 0.26921507716178894\n",
            "Epoch: 24, Batch: 83, test Batch Loss: 0.35838624835014343\n",
            "Epoch: 24, Batch: 84, test Batch Loss: 0.4772332012653351\n",
            "Epoch: 24, Batch: 85, test Batch Loss: 0.6350271105766296\n",
            "Epoch: 24, Batch: 86, test Batch Loss: 0.6129317879676819\n",
            "Epoch: 24, Batch: 87, test Batch Loss: 0.4057891070842743\n",
            "Epoch: 24, Batch: 88, test Batch Loss: 0.40905290842056274\n",
            "Epoch: 24, Batch: 89, test Batch Loss: 0.39447808265686035\n",
            "Epoch: 24, Batch: 90, test Batch Loss: 0.3893384635448456\n",
            "Epoch: 24, Batch: 91, test Batch Loss: 0.31423136591911316\n",
            "Epoch: 24, Batch: 92, test Batch Loss: 0.5612677335739136\n",
            "Epoch: 24, Batch: 93, test Batch Loss: 0.40634334087371826\n",
            "Epoch: 24, Batch: 94, test Batch Loss: 0.349398672580719\n",
            "Epoch: 24, Batch: 95, test Batch Loss: 0.32929426431655884\n",
            "Epoch: 24, Batch: 96, test Batch Loss: 0.4425369203090668\n",
            "Epoch: 24, Batch: 97, test Batch Loss: 0.5284414887428284\n",
            "Epoch: 24, Batch: 98, test Batch Loss: 0.6298819184303284\n",
            "Epoch: 24, Batch: 99, test Batch Loss: 0.4577687382698059\n",
            "Epoch: 24, Batch: 100, test Batch Loss: 0.6843036413192749\n",
            "Epoch: 24, Batch: 101, test Batch Loss: 0.29695481061935425\n",
            "Epoch: 24, Batch: 102, test Batch Loss: 0.4349234104156494\n",
            "Epoch: 24, Batch: 103, test Batch Loss: 0.48449116945266724\n",
            "Epoch: 24, Batch: 104, test Batch Loss: 0.6058084964752197\n",
            "Epoch: 24, Batch: 105, test Batch Loss: 0.6265474557876587\n",
            "Epoch: 24, Batch: 106, test Batch Loss: 0.2813807725906372\n",
            "Epoch: 24, Batch: 107, test Batch Loss: 0.4474731683731079\n",
            "Epoch: 24, Batch: 108, test Batch Loss: 0.43115895986557007\n",
            "Epoch: 24, Batch: 109, test Batch Loss: 0.3278912305831909\n",
            "Epoch: 24, Batch: 110, test Batch Loss: 0.49524417519569397\n",
            "Epoch: 24, Batch: 111, test Batch Loss: 0.4223347306251526\n",
            "Epoch: 24, Batch: 112, test Batch Loss: 0.4162851572036743\n",
            "Epoch: 24, Batch: 113, test Batch Loss: 0.22813816368579865\n",
            "Epoch: 24, Batch: 114, test Batch Loss: 0.5600573420524597\n",
            "Epoch: 24, Batch: 115, test Batch Loss: 0.48729759454727173\n",
            "Epoch: 24, Batch: 116, test Batch Loss: 0.35245174169540405\n",
            "Epoch: 24, Batch: 117, test Batch Loss: 0.39024513959884644\n",
            "Epoch: 24, Batch: 118, test Batch Loss: 0.23848044872283936\n",
            "Epoch: 24, Batch: 119, test Batch Loss: 0.5350527167320251\n",
            "Epoch: 24, Batch: 120, test Batch Loss: 0.4011736512184143\n",
            "Epoch: 24, Batch: 121, test Batch Loss: 0.45184043049812317\n",
            "Epoch: 24, Batch: 122, test Batch Loss: 0.34439241886138916\n",
            "Epoch: 24, Batch: 123, test Batch Loss: 0.474707692861557\n",
            "Epoch: 24, Batch: 124, test Batch Loss: 0.4702976942062378\n",
            "Epoch: 24, Batch: 125, test Batch Loss: 0.3400841951370239\n",
            "Epoch: 24, Batch: 126, test Batch Loss: 0.5035858154296875\n",
            "Epoch: 24, Batch: 127, test Batch Loss: 0.6917397975921631\n",
            "Epoch: 24, Batch: 128, test Batch Loss: 0.6440068483352661\n",
            "Epoch: 24, Batch: 129, test Batch Loss: 0.5892122983932495\n",
            "Epoch: 24, Batch: 130, test Batch Loss: 0.23782743513584137\n",
            "Epoch: 24, Batch: 131, test Batch Loss: 0.5045267939567566\n",
            "Epoch: 24, Batch: 132, test Batch Loss: 0.4078565835952759\n",
            "Epoch: 24, Batch: 133, test Batch Loss: 0.6142261028289795\n",
            "Epoch: 24, Batch: 134, test Batch Loss: 0.45948338508605957\n",
            "Epoch: 24, Batch: 135, test Batch Loss: 0.4391709268093109\n",
            "Epoch: 24, Batch: 136, test Batch Loss: 0.3939434885978699\n",
            "Epoch: 24, Batch: 137, test Batch Loss: 0.49096786975860596\n",
            "Epoch: 24, Batch: 138, test Batch Loss: 0.6121731996536255\n",
            "Epoch: 24, Batch: 139, test Batch Loss: 0.40129873156547546\n",
            "Epoch: 24, Batch: 140, test Batch Loss: 0.4177660644054413\n",
            "Epoch: 24, Batch: 141, test Batch Loss: 0.5461632013320923\n",
            "Epoch: 24, Batch: 142, test Batch Loss: 0.33190658688545227\n",
            "Epoch: 24, Batch: 143, test Batch Loss: 0.8351112008094788\n",
            "Epoch: 24, Batch: 144, test Batch Loss: 0.4240926206111908\n",
            "Epoch: 24, Batch: 145, test Batch Loss: 0.4426973760128021\n",
            "Epoch: 24, Batch: 146, test Batch Loss: 0.307846337556839\n",
            "Epoch: 24, Batch: 147, test Batch Loss: 0.37089306116104126\n",
            "Epoch: 24, Batch: 148, test Batch Loss: 0.4196741580963135\n",
            "Epoch: 24, Batch: 149, test Batch Loss: 0.641022801399231\n",
            "Epoch: 24, Batch: 150, test Batch Loss: 0.47395244240760803\n",
            "Epoch: 24, Batch: 151, test Batch Loss: 0.6413943767547607\n",
            "Epoch: 24, Batch: 152, test Batch Loss: 0.2313283085823059\n",
            "Epoch: 24, Batch: 153, test Batch Loss: 0.368548184633255\n",
            "Epoch: 24, Batch: 154, test Batch Loss: 0.4917771816253662\n",
            "Epoch: 24, Batch: 155, test Batch Loss: 0.4037550091743469\n",
            "Epoch: 24, Batch: 156, test Batch Loss: 0.48042216897010803\n",
            "Accuracy of test set: 0.8433\n",
            "Epoch 25/25 - Train Loss: 0.3784, Train Acc: 0.8662, Test Loss: 0.4412, Test Acc: 0.8433\n"
          ]
        }
      ],
      "source": [
        "Y_pred = train_model([train_loader, test_loader], num_epochs=25, learning_rate=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "ceb5783f",
      "metadata": {
        "id": "ceb5783f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8763d894-d471-424e-e934-96912c0384cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final test accuracy: 0.8433\n"
          ]
        }
      ],
      "source": [
        "print(f'Final test accuracy: {test_accuracies[-1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e128ed",
      "metadata": {
        "id": "a5e128ed"
      },
      "source": [
        "## Visualization of the labels and predictions\n",
        "\n",
        "In this section, you should visual one image from each class and show both the actual label and the predicted label for that image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "6c0b79fd",
      "metadata": {
        "id": "6c0b79fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "0a0e2275-77ec-4014-d137-6320f4aa3581"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAAChCAYAAACGcHWBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABU4klEQVR4nO3dd5QUVfo//vcocZAseQLDDAxZkugoOamIgIougjngiiIYwBVFZQVMrOIxsCp8MAGCgfB1BQQUQcBVQEkCSxwyDBkGSUP9/vBH+dxnpu90N9NUh/frHM65Nbe7qrpv3arq4j7PjXMcxwEREREREREREVEBu8jrHSAiIiIiIiIioujEB09ERERERERERBQSfPBEREREREREREQhwQdPREREREREREQUEnzwREREREREREREIcEHT0REREREREREFBJ88ERERERERERERCHBB09ERERERERERBQSfPBEREREREREREQhwQdPREREREREREQUEp4+eIqLi/Pr37x587zcTavp06ejSZMmKFasGJKSkvD888/jzJkzXu+WpyK9XSdNmoTbb78dNWvWRFxcHNq0aeP1LoWFSG7X/fv347XXXkOrVq1QoUIFlClTBldeeSUmTZrk9a55LpLbFQAee+wxNGnSBOXKlUN8fDzq1KmDF154AceOHfN61zwX6W0rbdy4EcWKFUNcXByWLFni9e54KtLbtXr16nnu79///nevd81Tkd6uAHD06FEMGjQIKSkpKFq0KKpVq4YePXrg+PHjXu+aZyK5XefNm2fd5+HDh3u9i56K5LYFgBMnTuCll15C3bp1ER8fj2rVquGWW27B6tWrvd41T0V6ux47dgwDBgxAQkICihYtijp16mD06NFe7xYAoJCXG//kk0+M5Y8//hizZ8/O9fc6depcyN3y24wZM9C9e3e0adMGb731FlauXIlhw4Zh7969YdPAXoj0dh09ejSWLl2Kyy+/HPv37/d6d8JGJLfr4sWL8cwzz6Bz58549tlnUahQIXz55Zfo2bMnfv/9dwwdOtTrXfRMJLcrAPzyyy9o2bIl7rnnHhQrVgy//vorXn75ZcyZMwfz58/HRRfF7sDeSG9b6bHHHkOhQoVw8uRJr3fFc9HQro0aNcITTzxh/K1WrVoe7U14iPR2PXz4MFq3bo3t27ejT58+SEtLQ1ZWFhYsWICTJ08iPj7e6130RCS3a506dXLtJ/DnZ/r222/RqVMnD/YqfERy2wJA7969MX36dDzwwANo0qQJdu7ciXfeeQcZGRlYuXIlkpOTvd5FT0Ryu+bk5OCaa67BkiVL8PDDD6NmzZqYNWsW+vbti4MHD2Lw4MHe7qATRh5++GHHn13Kzs6+AHuTv7p16zqXXXaZc/r0afdvzzzzjBMXF+esWbPGwz0LL5HWrlu3bnVycnIcx3GcevXqOa1bt/Z2h8JUJLXrpk2bnC1bthh/O3v2rNOuXTunaNGizrFjxzzas/ATSe3qy8iRIx0AzuLFi73elbASqW07c+ZMp0iRIs6zzz7rAHB++eUXr3cprERauyYnJzvXX3+917sR9iKtXR966CGnTJkyzqZNm7zelbAWae2al7S0NKdmzZpe70bYiaS23b59uwPAefLJJ42/f/fddw4A5/XXX/doz8JPJLXr5MmTHQDO2LFjjb/ffPPNTrFixZw9e/Z4tGd/Cvv/Cm7Tpg3q16+PpUuXolWrVoiPj3ef1sXFxeGFF17I9Z7q1avj7rvvNv526NAhDBgwAImJiShatCjS0tLwyiuv4OzZs8brdu3ahbVr1+L06dPW/fr999/x+++/o0+fPihU6K+BY3379oXjOPjiiy+C+8AxIlzbFQASExNjepTE+QjXdk1JScn1PzdxcXHo3r07Tp48iU2bNgX+YWNIuLarL9WrV3e3R3bh3ranT59G//790b9/f6Smpgb1GWNRuLcrAJw6dQrZ2dkBf7ZYFq7teujQIYwbNw59+vRBSkoKTp06xdGJAQjXds3Lzz//jA0bNqB3794BvzcWhWvbHj16FABQqVIl4+9VqlQBABQvXjyQjxlzwrVdFyxYAADo2bOn8feePXvixIkTmDZtWoCftGB5Gmrnr/379+O6665Dz549cfvtt+fqJPk5fvw4WrdujR07duDBBx9EUlISFi1ahKeffhq7du3CqFGj3Nc+/fTT+Oijj7B582b3x0tefv31VwBAs2bNjL9XrVoVCQkJbj35Fo7tSucvktp19+7dAIBLL7004PfGmnBu1zNnzuDQoUM4deoUVq1ahWeffRYlS5ZE8+bNA/yUsSmc23bUqFE4ePAgnn32WXz11VcBfrLYFs7t+t133yE+Ph45OTlITk7GY489hv79+wf4CWNTOLbrjz/+iBMnTiAtLQ09evTA1KlTcfbsWWRkZOCdd95Bo0aNgvuwMSQc2zUv48ePBwA+eApAOLZtamoqEhIS8K9//Qvp6elo3Lgxdu7c6eZo0w8uKLdwbNeTJ0/i4osvRpEiRYy/nwt1Xrp0KR544IGA9rMgRcSDp927d+Pf//43HnzwwaDe//rrr2Pjxo349ddfUbNmTQDAgw8+iKpVq+K1117DE088gcTExIDWuWvXLgB/PRmWqlSpgp07dwa1r7EkHNuVzl+ktOuBAwcwZswYtGzZMs9+TKZwbtclS5YgIyPDXU5PT8f06dNRrly5oNYXa8K1bXfv3o0XX3wRI0eORKlSpYLat1gWru3asGFDtGjRAunp6di/fz8+/PBDDBgwADt37sQrr7wS1L7GknBs1/Xr1wP488dRamoqPv74Yxw+fBhDhw5Fu3btsHr1al5n8xGO7arl5ORg0qRJaN68OdLS0s5rXbEkHNu2cOHC+PLLL9GrVy907drV/XvTpk2xaNEilClTJqh9jSXh2K7p6enIycnBTz/9hBYtWrh/PzcSaseOHUHta0GJiHiiokWL4p577gn6/Z9//jlatmyJsmXLYt++fe6/Dh06ICcnB/Pnz3df++GHH8JxnHz/B+CPP/5w900rVqyYW0++hWO70vmLhHY9e/YsevfujUOHDuGtt94Kel9jSTi3a926dTF79mxMnToVgwYNQokSJTirXQDCtW2feuop1KhRA/fff3/Q+xbLwrVdp0+fjkGDBqFbt26499578cMPP+Caa67B66+/ju3btwe9v7EiHNv13Pk2Li4Oc+fORa9evfDQQw9h6tSpOHjwIN55552g9zdWhGO7anPnzsWePXs42ilA4dq2ZcuWRaNGjfCPf/wDU6dOxciRI7FlyxbccsstOHHiRND7GyvCsV179eqF0qVL495778Xs2bOxZcsWvP/++3j33XcBwPPnExEx4qlatWq5howFYv369VixYgUqVKiQZ/3evXsDXue52Ne8YthPnDjB2Fg/hGO70vmLhHbt168fZs6ciY8//hiXXXbZea8vFoRzu5YqVQodOnQAAHTr1g0TJkxAt27dsGzZMravH8KxbX/66Sd88sknmDt3LnPuBSkc2zUvcXFxeOyxxzBr1izMmzcPt99+e4GsN1qFY7ueu+e94YYbcMkll7h/v/LKK5GSkoJFixYFt7MxJBzbVRs/fjwuvvhi/O1vfzvvdcWScGzbw4cPo2XLlhg4cKAxw2izZs3Qpk0bjBs3Dg899FDQ+xwLwrFdK1eujOnTp+OOO+5wZ50sVaoU3nrrLdx1113G+dkLEfHgKdCHODk5Ocby2bNn0bFjRwwaNCjP1wczhe+5IcO7du3KNQxu165dzC3ih3BsVzp/4d6uQ4cOxbvvvouXX34Zd9xxx3mtK5aEe7tKN910E+644w589tlnfPDkh3Bs20GDBqFly5ZISUnBli1bAAD79u0D8Oc1duvWrUhKSgp4vbEkHNvVl3P3UQcOHCiwdUarcGzXqlWrAsidqBgAKlasiIMHDwa8zlgTju0q/fHHH5gyZQo6dOgQcC6bWBeObfvll19iz549RpgdALRu3RqlSpXCwoUL+eApH+HYrgDQqlUrbNq0CStXrkR2djYuu+wyNwWQ17+NI+LBky9ly5bNNWvRqVOn3PxL56SmpuLYsWPu/4gXhHOJEpcsWWI8ZNq5cye2b9+OPn36FNi2Yo2X7UqhEw7t+s477+CFF17AgAED8NRTTxX4+mNROLSrdvLkSZw9exaHDx8O+baimZdtu3XrVmRmZiIlJSVXXdeuXVG6dGnOWhikcOyz52YW9fU/v5Q/L9u1adOmAPLOH7Jz507Url27wLYVa8Klv06fPh1Hjx5lmF0B8rJt9+zZAyD3wxDHcZCTk4MzZ84U2LZiTTj02YsvvtiY1GHOnDkA4Plv5ogev56ammrEPwLA+++/n6sT3XrrrVi8eDFmzZqVax2HDh0yOpe/0xXWq1cPtWvXzrW90aNHIy4uDj169AjmIxG8bVcKHa/bddKkSXj00UfRu3dvvP7660F+CtK8bNdDhw7l+ZoxY8YAyD3rKAXGy7Z9//33MWXKFONfv379AAAjR450Z1aiwHnZrgcOHMi1ndOnT+Pll19GkSJF0LZt20A/Dv3/vGzX9PR0XHbZZZg2bZo7MhEAvv32W2zbtg0dO3YM5iMRvL93OmfChAmIj4/HjTfeGOAnIF+8bNtzI18+++wz4+/Tp09HdnY2GjduHNBnob+ES589JysrC6+88goaNmzo+YOniB7xdP/99+Pvf/87br75ZnTs2BHLly/HrFmzck2NPnDgQEyfPh1dunTB3XffjaZNmyI7OxsrV67EF198gS1btrjvCWSK0ddeew1du3ZFp06d0LNnT6xatQpvv/027r//ftSpUydUHzvqed2u8+fPd08YWVlZyM7OxrBhwwD8OXyxVatWBf+hY4CX7frzzz/jzjvvRPny5dG+fftcP1qvuuoq1KhRo8A/cyzwsl3nzZuHRx99FD169EDNmjVx6tQpLFiwAF999RWaNWvGXDHnycu2PZebQDr3P4itW7fmQ8Xz4GW7Tp8+HcOGDUOPHj2QkpKCAwcOYMKECVi1ahVGjBiBypUrh/KjRzWv753eeOMNdOzYES1atMCDDz6Iw4cP4/XXX0etWrUYsnMevG5X4M8HxjNmzMDNN9/seY6YaOJl295www2oV68e/vnPfyIzMxNXXnklNmzYgLfffhtVqlTBfffdF8qPHtW87rOtW7dGRkYG0tLSsHv3brz//vs4duwYvv76a89zZkb0g6cHHngAmzdvxtixYzFz5ky0bNkSs2fPRvv27Y3XxcfH44cffsCIESPw+eef4+OPP0apUqVQq1YtDB06FKVLlw5q+126dMFXX32FoUOHol+/fqhQoQIGDx6M5557riA+Xszyul2/++47DB061PjbkCFDAADPP/88HzwFyct2/f3333Hq1ClkZWXh3nvvzVU/btw4PngKkpft2qBBA7Rt2xbTpk3Drl274DgOUlNT8dxzz2HgwIHnlfSRvD8XU2h43Wfr1q2LTz/9FFlZWShSpAgaNWqEyZMn45ZbbimojxiTvO6vbdu2xcyZMzFkyBAMHjwY8fHx6N69O1599VU+rDgPXrcr8OfsW6dPn0avXr3O9+OQ4GXbFilSBAsWLMCLL76I//znP5g4cSJKliyJ7t27Y8SIEbkekpD/vO6zTZs2xeeff44dO3agVKlS6NixI1588cWw+J0T5ziO4/VOEBERERERERFR9InoHE9ERERERERERBS++OCJiIiIiIiIiIhCgg+eiIiIiIiIiIgoJPjgiYiIiIiIiIiIQoIPnoiIiIiIiIiIKCT44ImIiIiIiIiIiEIi5h88Va9eHXfffbfXu0EFjO0andiu0YttG53YrtGJ7Rqd2K7Rie0avdi20Sla29XTB08ffvgh4uLi3H/FihVDrVq18Mgjj2DPnj1e7prfzp49i1dffRUpKSkoVqwYGjZsiIkTJ3q9W56KhnYdPnw4unbtikqVKiEuLg4vvPCC17vkuUhv17Vr12LQoEFo1KgRSpYsiSpVquD666/HkiVLvN41z0V62+7cuRO333470tPTUbJkSZQpUwbNmzfHRx99BMdxvN49z0R6u2rjx49HXFwcLrnkEq93xVOR3q5btmwx9l/+++yzz7zePc9Eerues3HjRvTq1QsVK1ZE8eLFUbNmTTzzzDNe75ZnIr1dX3jhBZ/9NS4uDgsXLvR6Fz0T6W0LALt27UKfPn2QkpKC4sWLIzU1FY8//jj279/v9a55JhradcOGDejRowfKli2L+Ph4tGjRAt9//73Xu4VCXu8AAPzzn/9ESkoKTpw4gR9//BGjR4/GN998g1WrViE+Pt7r3bN65pln8PLLL+OBBx7A5ZdfjmnTpqFXr16Ii4tDz549vd49T0Vyuz777LOoXLkyGjdujFmzZnm9O2ElUtt1zJgxGDt2LG6++Wb07dsXhw8fxnvvvYcrr7wSM2fORIcOHbzeRc9Fatvu27cP27dvR48ePZCUlITTp09j9uzZuPvuu7Fu3TqMGDHC6130VKS2q3Ts2DEMGjQIJUqU8HpXwkakt+ttt92Gzp07G3/LyMjwaG/CRyS362+//YY2bdqgWrVqeOKJJ1C+fHls3boV27Zt83rXPBep7XrTTTchLS0t198HDx6MY8eO4fLLL/dgr8JLpLbtsWPHkJGRgezsbPTt2xeJiYlYvnw53n77bXz//fdYunQpLroodoOjIrVdt23bhoyMDFx88cUYOHAgSpQogXHjxqFTp06YO3cuWrVq5d3OOR4aN26cA8D55ZdfjL8//vjjDgBnwoQJPt977NixAtmH5ORk56677grqvdu3b3cKFy7sPPzww+7fzp4967Rs2dJJSEhwzpw5UyD7GGkivV0dx3E2b97sOI7jZGVlOQCc559/vkD2K5JFersuWbLEOXr0qPG3ffv2ORUqVHCuvvrqAti7yBXpbetLly5dnBIlSvBcHAXt+tRTTznp6elO7969nRIlSpz/jkWwSG/XzZs3OwCc1157rUD2JVpEervm5OQ49evXd6644grn+PHjBbI/0SDS2zUvW7dudeLi4pwHHnigwNYZiSK9bcePH+8AcL7++mvj788995wDwFm2bFkB7GHkifR27du3r1OoUCFn7dq17t+ys7OdxMREp0mTJgWyf8EKy8eY7dq1AwBs3rwZAHD33XfjkksuwcaNG9G5c2eULFkSvXv3BvBnqNuoUaNQr149FCtWDJUqVcKDDz6IgwcPGut0HAfDhg1DQkIC4uPj0bZtW6xevTrP7W/cuBEbN27Mdz+nTZuG06dPo2/fvu7f4uLi8NBDD2H79u1YvHhxUJ8/WkVKuwJ/xtaSfyKlXZs2bZorRKd8+fJo2bIl1qxZE/DnjgWR0ra+VK9eHcePH8epU6eCXkc0irR2Xb9+Pd544w28/vrrKFQoLAZqh6VIa1cAyM7OZv/MR6S067fffotVq1bh+eefR/HixXH8+HHk5OScz0ePapHSrnmZOHEiHMdx949MkdK2R44cAQBUqlTJ+HuVKlUAAMWLFw/gU0e/SGnXBQsWoHHjxkhPT3f/Fh8fj65du2LZsmVYv359UJ+/IITlHdy5L7V8+fLu386cOYNrrrkGLVq0wMiRI90hbg8++CA+/PBD3HPPPXj00UexefNmvP322/j111+xcOFCFC5cGADw3HPPYdiwYejcuTM6d+6MZcuWoVOnTnne8LRv3x7An3kIbH799VeUKFECderUMf7evHlzt75FixbBfQlRKFLalQIT6e26e/duXHrppUG9N9pFWtv+8ccfyM7OxrFjx/DDDz9g3LhxyMjI4M2TEmntOmDAALRt2xadO3fG5MmTz+ejR7VIa9ehQ4di4MCBiIuLQ9OmTTF8+HB06tTpfL6CqBQp7TpnzhwAQNGiRdGsWTMsXboURYoUwY033oh3330X5cqVO+/vIppESrvmZfz48UhMTPQ2ZCeMRUrbtmrVChdddBH69++Pf/3rX0hISMCKFSswfPhwdO/eHbVr1y6IryNqREq7njx5EmXLls3193P7tnTpUtSsWTPwL6AgeDTSynGcv4ayzZkzx8nKynK2bdvmfPbZZ0758uWd4sWLO9u3b3ccx3HuuusuB4Dzj3/8w3j/ggULHADO+PHjjb/PnDnT+PvevXudIkWKONdff71z9uxZ93WDBw92AOQaypacnOwkJyfnu//XX3+9U6NGjVx/z87OznN/Y0Wkt6vEULu/RFO7njN//nwnLi7OGTJkSFDvjxbR0rYvvfSSA8D91759e2fr1q0BfBPRJRra9euvv3YKFSrkrF692t1XhtpFdrtmZmY6nTp1ckaPHu1Mnz7dGTVqlJOUlORcdNFFuUI+Ykmkt2vXrl0dAE758uWd3r17O1988YUzZMgQp1ChQs5VV11lbCuWRHq7aqtWrXIAOIMGDQr4vdEmGtp2zJgxTpkyZYx7p7vuuss5ffp0gN9G9Ij0dr3hhhucMmXKOEeOHDH+npGR4QBwRo4c6e9XUeDC4sGT/pecnOzMnDnTfd25hs3MzDTe/+ijjzqlS5d29u7d62RlZRn/LrnkEuf+++93HMdxJkyY4AAw1uk4fzZ4Xg3rr3bt2jl16tTJ9fecnBwHgNO/f/+g1hvpIr1dJT54+ks0tavjOM6ePXuchIQEp0aNGrlyP8WaaGnbLVu2OLNnz3YmTJjg9OrVy2nfvr2zbt2681pnJIv0dj158qRTs2ZN55FHHjH2lQ+eIrtd87J//36nUqVKTnp6eoGtM9JEeru2a9fOAeBce+21xt/P/YfA7Nmzg1pvpIv0dtWefvppB4CzfPnyAllfJIuGtp0xY4bTqVMnZ9SoUc6UKVOcxx9/3ClUqJDzxBNPBL3OSBfp7frNN984AJzrrrvOWbZsmbNu3Tqnf//+TuHChR0AzosvvhjUegtCWITavfPOO6hVqxYKFSqESpUqIT09PVcW/UKFCiEhIcH42/r163H48GFUrFgxz/Xu3bsXAJCZmQkAuYaVVahQIc+haP4qXrw4Tp48mevvJ06ccOtjWaS2K9lFQ7tmZ2ejS5cuOHr0KH788ceYn579nEhv2+TkZCQnJwP4c8asPn36oEOHDli3bl1Mn48jtV3feOMN7Nu3D0OHDg16HdEsUts1L+XKlcM999yDl19+Gdu3b8+1z7EkUtv13Dn2tttuM/7eq1cvPP3001i0aFFMzx4bqe0qOY6DCRMmoH79+mjYsGGBrDMaRGrbLly4EF26dMFPP/2EZs2aAQC6d++OUqVKYejQobj33ntRt27doNcf6SK1Xa+77jq89dZb+Mc//oEmTZoAANLS0jB8+HAMGjTI0988YfHgqXnz5u4B70vRokVzNfbZs2dRsWJFjB8/Ps/3VKhQocD2MS9VqlTB999/D8dxEBcX5/59165dAICqVauGdPvhLlLblewivV1PnTqFm266CStWrMCsWbNQv379C7LdSBDpbav16NEDH3zwAebPn49rrrnGk30IB5HYrocPH8awYcPQt29fHDlyxE2CeuzYMTiOgy1btiA+Pt7njV0siMR2tUlMTAQAHDhwIKYfPEVqu56759WJis/1UZ1UN9ZEartKCxcuRGZmJl566aULts1IEKlt+95776FSpUq59r1r16544YUXsGjRoph+8BSp7QoAjzzyCO655x6sWLECRYoUQaNGjTB27FgAQK1atUK+fV/C4sFTsFJTUzFnzhxcffXV1v/NPvc/4OvXr0eNGjXcv2dlZZ3XhbBRo0YYM2YM1qxZY3TM//73v249Bc7rdqXQCId2PXv2LO68807MnTsXkydPRuvWrc9rffSncGjbvPzxxx8A/nyIQYHzsl0PHjyIY8eO4dVXX8Wrr76aqz4lJQXdunXD1KlTg1p/LAvX/rpp0yYA/M+lYHndrk2bNsUHH3yAHTt2GH/fuXMnALZrsLxuV2n8+PGIi4tDr169CmR9sc7rtt2zZ0+eM0+ePn0awJ+JsylwXrfrOSVKlEBGRoa7PGfOHBQvXhxXX331ea87WBfl/5LwdeuttyInJwcvvvhirrozZ87g0KFDAIAOHTqgcOHCeOutt+A4jvuaUaNG5blef6cr7NatGwoXLox3333X/ZvjOPj3v/+NatWq4aqrrgrsAxEA79uVQiMc2rVfv36YNGkS3n33Xdx0000BfwbKm9dtm5WVleffx44di7i4OHeoMQXGy3atWLEipkyZkutf27ZtUaxYMUyZMgVPP/100J8tloVjf92xYwf+7//+Dw0bNnSn8qbAeN2u3bp1Q9GiRTFu3DicPXvW/fuYMWMAAB07dgzg09A5XrfrOadPn8bnn3+OFi1aICkpKaDPQHnzum1r1aqFPXv2YN68ecbfJ06cCABo3Lixfx+EDF63a14WLVqEr776Cvfddx9Kly4d1DoKQkSPeGrdujUefPBBvPTSS/jtt9/QqVMnFC5cGOvXr8fnn3+ON998Ez169ECFChXw5JNP4qWXXkKXLl3QuXNn/Prrr5gxY0ae06j7O11hQkICBgwYgNdeew2nT5/G5ZdfjqlTp2LBggUYP348Lr744lB87KjndbsCwCeffILMzEwcP34cADB//nwMGzYMAHDHHXe4T6nJf16366hRo/Duu+8iIyMD8fHx+PTTT436G2+8ESVKlCiwzxtLvG7b4cOHY+HChbj22muRlJSEAwcO4Msvv8Qvv/yCfv36IS0tLRQfO+p52a7x8fHo3r17rr9PnToVP//8c5515B+v++ugQYOwceNGtG/fHlWrVsWWLVvw3nvvITs7G2+++WYoPnJM8LpdK1eujGeeeQbPPfccrr32WnTv3h3Lly/HBx98gNtuuw2XX355KD521PO6Xc+ZNWsW9u/fj969exfkx4tpXrftI488gnHjxuGGG25Av379kJycjB9++AETJ05Ex44dccUVV4TiY0c9r9s1MzMTt956K7p27YrKlStj9erV+Pe//42GDRtixIgRofjI/vMio/k557LG//LLL9bX5TeLzfvvv+80bdrUKV68uFOyZEmnQYMGzqBBg5ydO3e6r8nJyXGGDh3qVKlSxSlevLjTpk0bZ9WqVU5ycvJ5TUOZk5PjjBgxwklOTnaKFCni1KtXz/n000/9em+0ioZ2bd26dZ4zGgBwvv/+e7/WEW0ivV3PzT7h69/mzZvzXUe0ivS2/fbbb50uXbo4VatWdQoXLuyULFnSufrqq51x48bF7BTejhP57RrMvsaCSG/XCRMmOK1atXIqVKjgFCpUyLn00kudG2+80Vm6dGm+741mkd6ujuM4Z8+edd566y2nVq1aTuHChZ3ExETn2WefdU6dOuXX+6NRNLSr4zhOz549ncKFCzv79+/3+z3RLhradu3atU6PHj2cxMREp3Dhwk5ycrLz5JNPOtnZ2X69PxpFerseOHDA6datm1O5cmWnSJEiTkpKivPUU085R44cyfe9oRbnOGJsFxERERERERERUQGJ6BxPREREREREREQUvvjgiYiIiIiIiIiIQoIPnoiIiIiIiIiIKCT44ImIiIiIiIiIiEKCD56IiIiIiIiIiCgk+OCJiIiIiIiIiIhCopC/L4yLiwvlfuSrWrVqbrl27dpG3a5du9zy77//HvQ20tPT3XJCQoJRd/bsWbf8448/GnWnT58OepvBcBynwNbldbtef/31bvmKK64w6o4cOeKWT548adSdOXPGLV90kfn89MCBA8ZyoUJ/HeayHQGgXr16bnnevHlG3bfffmvb9QIXye0qv2MAuPjii92ybrtwJr833R62OpuCbFe9H1646qqr3PITTzxh1H311VdueenSpUbd7t273XKlSpWMultuucVYlufiO+64w+e+yOMMAHJycny+NhQiuc9qbdu2dcvvvfeeUXf48GG3LM+9AHDixAm3XKZMGaOufPnyxvKGDRvccrt27YLe11CLpnalv0Ryu8r+CQB///vf3fI333xj1H300UduuXTp0kbdTTfd5Jb3799v1Ml+DgBr1qxxy7Vq1TLqrrnmGrdcrFgxo27gwIG5P0AIRds1lv4SyX3Wa/rzFnQ/OR9s1+jkT7tyxBMREREREREREYUEHzwREREREREREVFI8METERERERERERGFRJzjZ6DlhYihrFGjhltOTU016mSuCJ1jonDhwj7XKfNPyDKQOx9FfHy8W9Z5aUqUKOGWT506ZdStX7/eLev8T6EQTbGxY8eOdcsy9wAAHD161C0fO3bMqJNtXqpUKaNO5vwCzBxQ+vOWK1fOLS9YsMCo69mzp3XfC1qktWvXrl3zLAPAJZdc4pYXLlxo1K1du9Yt//zzz0adzOsVyPehzxe33nqrW05KSjLqfvvtN7esc9lIOneYzg/mr0jIP2HLlaTPr5s2bXLL8rwImOfQokWL+r19mf8JMM/Nn3zyiVHXp08fn9u40PnEIq3PSvfdd5+xPGrUKLesr7Ey90vx4sWNOpnfRZ+n9XElj6Xs7GyjbujQoW5ZXhe8EMntSr6Fe7u+8cYbxvKdd97plnV/kdvXeZxkH9X5F+X5VPflvXv3+nzt4sWLjTrZ1w8dOmTUyZys+r7qsccec8vLli1DQYiEaywFJxz6rM5vdvvtt7vl5557zqgrW7asW9Y5DuU9ZJ06dYw6+duxSJEiRp3MidmyZUujbvTo0dZ9D7W0tDS3LHM45icc2pUKHnM8ERERERERERGRZ/jgiYiIiIiIiIiIQiIkoXa2acfl0Pv27dsbdTK8QoZZAWZ4m96X06dPu2UddiXDAHSonW1aaB0ioMNupIoVK7plPeT5448/dsv6MwUrmoYoyqHlzZs3N+oOHDjglvUQcHms6O9Dv1a2iZ72V8rKyjKW5XTFF0I4tKtt+tWOHTsadY8//rhb1qFSJUuWdMu6L9n2TfZlHdJqC3XT7SpDerZt2+Zz33TdkCFDfG4jWJEQBqCHdsvvPjk52aiTocWvvPKKUVevXj23nJ6ebtTJY6Rdu3ZGne5rgwcPdsvz5s0z6u666y63rNtdn+NDLRz7rKT3r379+m55xYoVRt2OHTvcsu6zkv6OZb/UYZk6lEf2b92fK1eu7JZlyKZ+nw4d0tfxghAO7UoFLxzbdcaMGW65adOmRp28J9HXQ3nc65BjeY2rXr26UWfb740bNxrLP/zwg1tu0aKFUSfDmmVoNmCeP2TYvV4eOHCgUffhhx/63E9b20XCNZaC41Wfvfvuu93yU089ZdTJcLrly5cbdVWrVnXLiYmJRt26devcsvzdCJi/MfU1Ti7L30UAMGfOHGNZXlfldRMwzxP6+nvppZe6ZRkqC9jbQN7n6d8BTzzxhFv+/vvv/V5noNhfwwdD7YiIiIiIiIiIyDN88ERERERERERERCHBB09ERERERERERBQShfJ/SeBsMX5t27Z1yzJPD2DGl+tcETKXh16/jHXX8a8y9lOvU8e/+lun84ps3rzZLVeoUMGou+6669zy5MmTfa4zVsm4Yt12Mq5ZT9su21Xnp5H5DfR6dJ4EeUzo/FyxyNZ3dY4nOb2z7i8yN0VqaqpRJ3PJ6DhzmaNNt6uO45bHi87zInNO6CneJR2DL/NhbNmyxaiTMfi2fFPRpkmTJsayzN+h62Ter7Vr1xp1ckrib775xqjbv3+/sZyUlOSWdS4ESeYZAez5BaNVIJ+ze/fuPutkf9b9Ql7zdD+0fed6+fjx425Z9y957XzkkUeMOpkLMBQ5nYgKki0PmbwnBIBGjRq55U2bNhl18v7Edu+i864dOnTILVepUsWoe/rpp33ud40aNYxlmY9J3ucCZt/Wn1f28z/++MOok8syXx9g5niKlfM3hacHHnjALev7W9m/dG5aeb+pj/2EhAS3bLuO6b4u+5POm3jnnXf6XI++Vst7N30PK/ubbd/0++RnlDk+AaBv375uWed4otjFEU9ERERERERERBQSfPBEREREREREREQhEZJQO6l27drGshzC/+uvvxp1MpxKDxGUQ4n1EFwZbqHD4CRb+Jzeph46LIco6mHNMqxHDsEEzGHO7du3N+rmzp1r3Z9YIMOX9PBS2a66LpBh2PK1ej2SDsUkU3JysrEs20dPmSzDZnUIowy5WrVqlVEn13PkyBGjTvdJGYqnQ1z/+9//+ty+nFJWTxsvh03rUKBoHvov+6FWv359Y1mGZOlQu5EjR7rlNWvWGHVyiLgOs/7oo4+M5czMTLdcp04dn/um20S2p57iOxbp6dlvv/12t6ynPpbfpQ5PjY+Pd8v6+vfTTz+55caNGxt1uu/Ja7BcJ2D298GDBxt1Xbt2dcv9+vUz6vQ5hMhrtlDsli1bGsuyT8hrE5D7mifZphCXfUteiwFgyJAhPt+3cuVKY1n2dZ3uwEZex/V3Ie/BdBigTJNw9OhRv7dHdL70sXjVVVe5Zd3Xli9f7pb1PYj8DaqvlZIOmZPb0Pel8hyh74u3b99uLMu+p3/TyHsifc9nO2fJPqtTYMhzlP68MnQ2VuhjRR4ftjoZcg3kfpYhf9PYfoucTyqEC4UjnoiIiIiIiIiIKCT44ImIiIiIiIiIiEKCD56IiIiIiIiIiCgkQp7jKSMjw1iW+UF0DKOMP9X5mGSsqi1OUk8DKWNlbVPc6m3qWFW5Hr19+Tl03K6cHldPR7948WK3LKfLjCWyTXS8qZ6KVJK5Q/TrdAyy/G5tucNsMc6xSubi0THh8ruU/RoAqlWr5pbnz59v1LVt29YtN2jQwKiT8ep6e7qPpKSk+NyGPF/ofi6X9TEn46wnT55s1EVzjqdgyTxfANChQwe3rHMIybxBzZo1M+oWLVpkLMvvOi0tzaiTff/w4cNGnTxmYjXHk5wG+s033zTq5PlOfz9ly5Z1y/v37zfqLr30Uresr80VK1Z0y7ZcYQBw4MABt2zL2aavv7Jffv3110Zd9erVrdskutBs9xIyzylg9kN9fyL7k+4v/uYO0fliVq9e7XOdOlejrA/kfCqvsXob8tqs87zJ/I9Lly71e3tE52vXrl3G8vPPP+/ztfJ3ns59Jq+dOseS7bwg+6y+15TnAZkHDcjdv+W5QN/7yvUEkotI0nno5DZKlSpl1EVrnjbb92Nj+w2h82O2bt3aWL7hhhvc8qhRo4y6rKwsn9sIx98tHPFEREREREREREQhwQdPREREREREREQUEiEJtatRo4Zb1iE4e/fudctyWC0ArFixwuc6ZeiOHp4rh5np0A/JNrQfMEN59PTscmid3B5ghtrpcCC5r3v27DHq5FC6GTNm+NzvaGab/ly2lx4yKskQESB3+I0M29BtLulhsWSG2OjvToY4yulWAbPt6tWrZ9T9+OOPbrlHjx5GnTx36CHEemr2WbNmuWXdtypVquSWdfhPuXLl3LIeCizfF0tsw3H1eVm+Vn+3+/btc8v6PC2HpOtQrtq1axvL8ljTIXu6f0sMlwWee+45t6y/K/n96P4lv3MZPgcAW7dudcvJyclGXd26dX3ui+6Xcvu6r8nziQ7nk59DT3stp4d/8cUXfe4LUTjQ02bL+x7dJ4MNdbOlrZDr1PfE+rW21Bi2sFrZz3X4np4OXmKoHYULmcpBk78zdT+QfUgf+7J/63tm+RvT1rfyC6WSy/p+SG7Dds+n6+R+63OU7Z5rx44dPusime27CzYMT18X9D2y/N3y0ksvGXX/7//9P7csU/gA5jOXcMERT0REREREREREFBJ88ERERERERERERCHBB09ERERERERERBQSIcnxJGNjdayqzLej4yRlXiWde0XGw+pYcxljqqdhljHstlh3wIzN1HmDqlat6pYXLlzo8306D43cppxOHAAaNmzolmM1x5PM3aFzCMm8TjrHk8ylpd+nl+XxoXNwyfbReb3InPZe58CSx73MzQSYeXl0e9SvX98tz58/36i77bbb3LLsc3m9Vraljo+WuSlknirAzCWjzxcyl1wsscWs//bbb8aybHd9DpXLOvZfLuv36fwlclnHutuE49Sxoda2bVtjWU71fOjQIaNO5t3S7SPzc+n8S3JZ59yS1zy9Tp1zMSkpyS3r/FPymq/zJMhzj15n586d3TJzPFG409cY2e80mU/FNv257Vyrz636PtjX9vLbhn6tv+u0XQcSEhL8Wiflzd8cPvn517/+5ZYXLVpk1H355ZdBrzeSlClTxmedvFbpXE3yt4q+Vsl7YVu/0H1NrlPfs+rf2HIbtlxRtvOJrrPljLOdBzZt2uSzLprY+p2tLjEx0S3rNk9LSzOWZZ5NfQ82depUt7x582ajTj7L2Llzp1G3Zs0at/y///3PqEtNTXXL/fr1M+pk3qhgclpxxBMREREREREREYUEHzwREREREREREVFIhCTUbu7cuW65cuXKRp0cZqyHMsqh9zrUTg7n0kP9ZChGyZIljTo5RFGHCukhi5Ie/ixDd4oWLWrUyeHCOqxI7uv69euNuq+++srn9mOFDJfS4Y2yXfW0pHJYom4PPYW3bB8ZZgWYQ1F1GB4BderUccu2Ib56uK0cmquHYso+qadtl9OC2ob7AmYInR6mKo+XUqVKGXVy+LMe+io/o5zaGcg9FDWa2KbEzcrKMpZlH7INF9ftZxuSaxsurs/bNrEYategQQNjWZ4PdfvIcG8dsi5D9OT1DjDbTr5O06F9uu/Jod5632whnLbQoUCODyIvyGP94MGDRp08tnWflOdB3Sdt52y5Ht3PbKEx+jws16PDhmS/0+dduW+BTL8uQ08ocIFc/+RvsWHDhhl18ndbixYtjLpQh9oFOx19QduwYYNblukhgNz3RJLtvlj2Yf05ZV/Tv3Hla/VvTL0euU19HZX3brof2vZb0qGFtutvtN6PBXKM2kLtrrzySresn10sW7bMWJa/h9PT0406+dtV35/J31v6/CrTInXo0MGok8eK3jeG2hERERERERERUVjigyciIiIiIiIiIgoJPngiIiIiIiIiIqKQCEmOJ0lP+yeXZb4JAGjSpIlb1jl9ZM4nHV9rm2pZbkNO+5wXGdeqcwHJ2EydU6hEiRJuWX/eH3/80brNWCdzguipdGW+HR2rLNtKxzyXK1fOWLblFZHH2ZEjR/zc69iRnJzslnWOCdnvdNvJ+HhNTumu+7lt+mid20XGNevjQ54v5LSggNl/Zdw0YMYyN23a1KiL1RxPOveZzMWn87LJ+H9bnh69PVtby+3lJ1pzCtjo41vS1yrJNgW7Jq+rOv+E/M51m+tjR75Xv9Y29bNt3ypUqOCzjigcyGuJvubJfBk6P4c87nW/09dDf8n+qu+XbVOl2/LF6fOM7Mu2c7L+DDqvIgVv9OjRxnKlSpWM5SuuuMItf/fdd0adnJJd5+lt06aNW543b55RZ8tnM2LECLes+8Cjjz7q831eeeutt9zyww8/bNTJ3xj62iT7gv4s8p45kNxrkl6n7X36d6y/+d30tVmeJ/R1Wq5z+/btPtcfTXQb2PIc2Y5nmUNXPw+R/RMAvvnmG5+vteVDlvfktucaOvegfJaxcePGvD8AguuvHPFEREREREREREQhwQdPREREREREREQUEiEJtfN32NmBAweMOjmdpA6XksMX16xZY9TJKQG3bNli1N17771uefLkyUadHlYsQ/H09mXYl234pJ5yXtJDFOV6wmV46YW2adMmt6xDm2T76CHhsn10myclJRnLe/bscctyWDtgTvct94X+JPvW2rVrjToZMqenVJUhWDr8VJ4fdHijfJ8+j+ip2bdu3eqWbeFgtrBdPTWs3GbdunVBucm+qNtIDjvXdXI5vzBKf+so91S3MvRbhwHI64wedi/7gr4eyaH3esr3zMxMtyzPCUDuMDi5Htt9gm5z+Vp93Zah1vozxeKxo8MkZFvajgetdu3abrlXr15G3Ztvvmks65BlMjVs2NAt6+Pe1j7ytfrYltNk28JfdR+Qy/r6ZwvN1fdgcvt63+S1Wu+bPD51nQ7rIrtq1aoZy++//75blmE8QO6+Lu/L6tevb9TJ+6dLL73UqNO/22zbkJo1a+aWZfqLcCXvL3XqiD59+rhl2z2kPr5l/9IpQmTf1/3J9ltR/+aU4bp6G7ZQSF+v0/utU25ItrpYZfueZdvpFEI6bLF8+fJ5vg8AZs6c6ZblbzbAfK6hz+9y3/S9Wyh//3DEExERERERERERhQQfPBERERERERERUUjwwRMREREREREREYVESHI8+UvnhZExrjpuVsaqJiYmGnW7du1yyzqeUua/qFmzplG3cuVKn6/VeWFkXLqeklCSce9arOZxsjl06JBb1lMJy+ND5z6wTbdum15b5yeRuQjkcRSrdJ+Ux70+tmV76e9Vxrbr3GbytTL+GDBjl3Wb634nY5J1XhMZH62nEZbr0cecPK50/oRoFopzky3HU37bl8eM7XxL9lxNuu/J413n5ZHXWN2fJJ1PTeZl0ecPnRdG1uv8E7Y8FrbjU65HX+N1XrpoYctlZbsHsenWrZux3LdvX7cs850AwI033mgsjxkzJqhtSgkJCcaybEt9rCQnJ7vlSZMmGXXyfkAf/16R+Sv1dU3S/UX2V52fQ55Pdb/z9Tq9fX0c6X4v36u3L6+/geQOk8eqzj8VLjmebHm4Anmf7ZpnOw6kNm3aGMuvvvqqW5Z52ADz3KxzMeljRN776vs3+ftHHxO9e/d2y/q3mNShQwdjWR7b+t7q9ttvd8uffvqpz3WGkq3NP/jgA6Nu2LBhbrlMmTJGncwjq/uMPI/pY0qet239ML9jTL5X9y95zNmusbpOvk+vU75W5peMJfI7COTcYes/OnexbAP9Pct75BUrVhh18rmGLc+0LU+vTTC/HcLjqkxERERERERERFGHD56IiIiIiIiIiCgkQhJq5+/QK1sIhR6GKocsrlq1yuf79BDFsWPHuuUrrrjC+loZnvO///3PqEtKSnLLeliqHD557Ngxn/umMfTOnEJSDwO0hUTJ18pwPSB3+xw5csQt6/aR65XTy8YqPfRTDiPWQ0jlMH099FO+VodJyH6nw31sQ4E1uQ29fR3CJ8mhp3oKURmmJMM5op3ue7Zp6OUQfR3WI48JvQ65jfymuZdtb5vim3Jfx2SYq26fYMPZJFv4iD6ObNPD20LCbCFS+vPK5QYNGhh14R5qF8iwfH/7j7xXAYCrr77aLevQHHnNa968uVEnpzw/evSoUdepUydjOTU11S3r9pHXY71vkm5zeS1avXq1z9dOnTrV5zrDRb169dyynmJdhjjo9pftrMPiZN/S3528jgUSimPbN9uxagvNtYXz6e2FS6hOIFPN217rbzjdbbfdZiwPGjTILZcrV86ok22t00PI7el7Zk3ud3Z2tlEnl3Xakz59+uS5n4B5r62ng5fHmg7jGTVqlFv2KtQukN9jOoxRqlixolvWobO2kGjZrrZrrL5n1X3I1/b0em1hV7bjVvdnuU5dFw4CSfEQ7Dpt91WSDj+V5zsdzq77r7yO6u9Z/t7Rx4P8/WVLhaDfJ39X53dfFyiOeCIiIiIiIiIiopDggyciIiIiIiIiIgoJPngiIiIiIiIiIqKQCEmOJ3/puGJJ54WRca116tQx6mQcq45HlvlcdH6flJQUY1nnBpJkboLff//d5+tseauY0ym3ffv2uWUdRypzu+jvVcbYbty40ajT+SdkLLWOzZVxtHr6ylgk49MBM5ZXx6TL+GQdsy/b8uDBg0adjE/W0yfL40HnjdDT1sp8Anrf5PGyefNmo05O5Vu+fHmjTsbu2/JWRBtbjqfq1asbdTKeXOd+kd+Z7mu2vD36tXL76enpPt9nW0+snG9tOQxseSRsx7fOTWHLQxNIu8rrur5W+0t/JplzrFKlSkGt0yu2Y1TnNpNtIqc7B8wcKfpaKc+pOl+MXNbnSZkPqkKFCj73BQBq1KiRZxkApk2b5pYnTZpk1C1ZssQt67wVcmr4QPqyLc+cV+S9pi2Pks6dYcvXJun3+ft96b5ry9Fiy+thm+LdlhtSnwPyy0sUDmzfra3u1ltvNZaHDBnilnW/lL+NdH+2bUMeI/rabMv3p68F8t5OHyMyd1NmZqZRJ9tWn7/kuV+fPwLJjRsqgeTukudG/btBfu86p52ss+Ve02z5l/R+ynq9Tllnu2+wnTf1+/xdZ7goiPvCQNYh719btmzp83W6L8n7GsC85ut2lf1J93vZD3V+MNnvdF5c+eykVatWRt28efNy7X8gOOKJiIiIiIiIiIhCgg+eiIiIiIiIiIgoJDyNJdHDbOWQUj2UTA4z08My5bBAPYxZTjeqpxLU5JA0Of0tYE4tqIeJSsGGD8SqvXv3umU9pNc2NFe2pZwSGsg9XFy2iT6ubOuJRVWqVDGW5TBaPRTz0ksvdcuyfwDApk2b3LIO1ZLDVHV4q9y+HsKsXyvbTvd7OUx1x44dRl3jxo3dsm7z/fv3u2VbWKYtpDYS2YZWZ2RkGMv5nUfP0f3QFpKl62R7BhIu4++U89HEFtJoG4avv3Nbfwp2eLo+BmT/0kPJJdv0vXpf5HJiYmJQ+3kh2cIRZBvoa97VV1/tlh9++GGjTk5rrqcxD9bw4cPdsg7ts4Vo/e1vfyuQ7QdL9vtwCf2QIaDr1q0z6mxTYctl22fR7WELdbNNf66XbdOE26Zmt9VJOmxIvi8tLc2o27Bhg8/1XEj6HlIe7z179jTqZIiKTi0iz4XyPhgw+76+3uo0JJJsP72ftlAufa2UYXn6XkemPNDtJ99nC+3Tx1lycrJb9vf+IlzI1A0AsHjxYrdsC5c6ceKEUWdLEyC/5/zua2S9rV/atqHrZFvqOnlchUPIpHahUy7o3zvy2qzPATNmzHDLun/q8Hbb7yaZdkSnD5H9Nysry6iTx4MOw5PHart27Yw6htoREREREREREVFY4oMnIiIiIiIiIiIKCT54IiIiIiIiIiKikAir+cJtU7nu3LnTLa9evdqok/GnOk5STsmr45FteaR++eUXo07Gca9fv96ok3G0tilvKTc59aP+7mT8qY5rl8eKjkG35TTQeYpk3KyehjIWyfh9wJ5jQk4BrHMU+DtVu84NJfurbXptwMzJpqfulbH1ttxdOlZa5oPSOSbktKi//fabz3VGIttU2Z07dzaWbblGbDkEAsm3IvMUyPwogJnrZuHChUadzA8RKzmedC4AeT7UOR7kd2LL8aDZcr3I9+l16OV9+/a5ZZ3/wpZ/yt9rrD5WwkEgx70tR+SNN97oljdu3GjUFURep4SEBGP52muvdcv6nsd270S5vx95LdPHr6zT7e9vriRdJ7ev+6stB5wm6235Ymy5omzHvy1fqs7X5mWOpz59+rjlu+++26iT90E6P9HWrVvdsm53eU+r77tk/if9vctjROfUkevR1z/9XctjRN8/yfsifUzK3ES23Kv62JLTs+tcNzJ/pvw+w5XM06bvE+Vxu23bNqOufv36btmWT82WO8t2HgDsOW1t5wUb229zub0SJUr4vc5woM9NweaDqlq1qlseMWKEUbdgwQK3fPDgQaNO3gPp417m0AXM32KbN2826mSOtMOHDxt18reZ/v0r8zrp/IIrV650yw0bNjTqZB4pea7yF0c8ERERERERERFRSPDBExERERERERERhQQfPBERERERERERUUiEVY4nGWMoYw8BM5a4bNmyRp3MTbBp0yajTsYu79q1y6jTMZRZWVl5lgFg3rx5btkWB2rL0VBQ8aTRRLa5jjGVccU6F4+MX9e5mWS8OGB+77Y2iJWcMDY678qBAwfcso7LlzkKZBwzYPY7/b3KttT5aXTuEknnEZH7qvM/yHwCep3yeNE5GeS5RX/eWM1jctNNNxnLMoeQjv239TVbvhJbHhCdp+Cuu+5yyzrHk8w/ESt0fg6ZD0LX2XI12er8zTVjyxMFAHXr1nXLun/Z1ms7ruT5RecCDAcFdZ2XuUNkzsmC8uSTTxrLEyZMcMu6D/bt29dYlt/79OnTjbquXbu65Qt9D+TVPVbz5s191unroewz+p5U5jbVbPn0ZHvZ7kk1W/4pWx4nnetHXkf1vZvcV1vuGC9z/dSoUcNYfuCBB9yyzqEiP4++95T3Fzr/jcxZqe9h5Xlbr1PSOVtkW+troT7u9G8sSZ6b9T2SPO709UUu29pWn6fld7pnzx6f7wulQM5Nsi31Na9atWpuWec+lflw9PEtv3PbbxF9nbTlLrblXNSfTx4v+nxvuzbLfdX38xdKsNeVYK8POifbzTff7JYXL15s1Mk8tvp9sv/qOlvevipVqhh1sg10v5e/hXS7yvO2Plbk73G5DgCoXbu2W9b34P7giCciIiIiIiIiIgoJPngiIiIiIiIiIqKQCKtQOznsSw/tksNSZfgPYJ/yXS6npqYadXpomXxtq1atjDo5XE6H3NiGL0q28AWG3eUeEi6/Ez00Vw5Z1SEbepiqfK8+PvR7Y13lypWNZTkEXPcX25S7MmRAD52Ww3F1+KttaLoM8QLMfq+HdR85csTnvskhrHroqRzyrYeR63NSNJPfi56yWR4H+nuX360eKuzvcG39Wt1+t956q1uW01xrsRLarI9hW51su/zC4nyxhVfmR17Hbe/T+ya3qdtRvlaH9YQDHT7VuHFjt6y/Sxlapb8D+bl1SINcjz5vyvsVOb07ADz++ONuuX///kadHM6fkZFh1K1atcpYliElenrxhx56yC3rMAAZbiKPDcAM+9LHig7L9+W7777z63UFTU6vDQC7d+/2+Vp5rtPfj/zc+liR98u2e0sb/TrbOVvXyXO2DtuS04bbQrVs4Vg67P9CuuKKK4xlGRKj70NkP7WFD+twRFuInlzW25Pfpz7fyXsWfR6whXjqEEu5Ddt1W9+Xy8+k12kL5dbnpUgmvzt9Lly/fr1b1tcFeZ62/aax/cbV27f9xtXvs/1Okmwh+oGE9RakUNzr6XNTgwYN3LJ+PiCvXZmZmUadTAWk21z2Ud1fbedm/dtE3qPLZxWA2a76XGy7X5Lb0NdbGUrOUDsiIiIiIiIiIgobfPBEREREREREREQhwQdPREREREREREQUEmGV48mWq0JOw9ykSROjTsbFr1271qiTceI6nlFPs67jL33Zt2+fsZyUlOSWbbGlsZJzJFg6jlTG2Oq8XnLKUh1LrvMGyfh8/Z3LXASUe4pXGXcsY5UBYN26dW5Z5wGS+ZD0NKHly5d3y7pPbt682S3rnAg6rlnmOZE5nfQ29TZkfpKKFSsadbap2atXr45Y0aFDB7es20/mc9FtIunznS2fh23qWJ03QK5XT3u9adOmPNcB+J8XJtLYrpu2nC22XEm67WxTNMu8Afl9x3L7OueI3B9bjgn9meR5wjZFuFf0teu3335zyzqvgzw36u/g5ZdfdsvNmjUz6mw5WeT3o8/vMgfS2LFjjTp576SniJ4yZQqCofetRYsWblle0wHzvk6fiyX9PclzUrB5zM6X/iyyX+h9kvlBVq9ebdTJvCK2vqXXKb9nW06Y/PLFyPXo/CAyD43Of7h8+XK3rHOe1KlTxy3r6/b27dvdsr42X0gTJ040lu+77z63nJ6ebtTZcurY8pTZvlt5vrXl1tLncFmn74tt+f70euRr9Xlarlcfk/Iz6u3LOv0+mVt0wIABCHfyXljnppPfqzyfA2ZuWv07RebU08eDvHey5cIF7H3f1+sAe04ff8+jgeR7LEh6/2SONJ2vTf5u0Psr16OfB8g+IXPfAub1Sf9OkuvRfVBuP7/8WLKdbW2nr/Hy+YTOIShz2uprrLzvl68DgJo1a1r3NT8c8URERERERERERCHBB09ERERERERERBQSYRVqJ0Ni9FA2WffFF18YdXIaSj2UTU4tqIc/6yGkK1ascMs6hOOaa65xy4sWLTLq5FB2r6aTjAa2KdVluBxgDonU37kOrZJDYfUUvXoIYazTQzHlkFs9ra/87vTQYNmWOgxPDoPdsmWLUSfbSofN6Clm5TZtYTv6+JDnhHr16vncNx0GIIdCR7sbbrjBLQcSPmwbam2rs4WK6CH7so3+9re/GXUvvfSSW9bHRLSyhTTYwiv0cG35Pl1nC8uwrVPvm216dttU3PIar48j+Vrb9MBe0cd2VlZWnmUg9/nQFxmuF0n0dzF//nyP9iS0ZAghAFSqVMkt65BjGfqhU0XY+pa/5+VAwl9s4WB6ezK8Q98byPssW5oE/V3I0KR27doZda+88op130NJhp6npaUZdXK5TZs2Rp38fPp+Rl7H9Hcrw170Pau8F9b3XbK99Pt06gL5Wt1+8p5J3xPKOp12RN5bybAywAwt0++TIZZLly416t544w1cCMGmPrGFQurznbyH1H1dngds+6b7jN6GvyGUOpxO1ult2D6TLQzfK/LcocOAd+/e7ZZ1qLvsT/q8JT+bvrfU5ypJHts6NYXsW7bvVW9T90l5LtHnGZlORm8/NTXVLes2l9+F/g2nf48HiiOeiIiIiIiIiIgoJPjgiYiIiIiIiIiIQoIPnoiIiIiIiIiIKCTCKseTjCnUuQ9kjPW7775r1D3//PNu+T//+Y9RJ3OV6OlZdZzk+PHj3fLIkSONOhlvKeOYAeD33393y4HkFZHx9MHGF0cT29Ssuq1knY6NlflAAPsU3rGSB8ZfOkeKziEgyfaSU28CZt4VHSst8xfovE2yH+g4Yv1aGZ+tpz6V7apjl+V+62NO7pvukzKOOtrJnHY6N4SOPZf8zfGkX6fbyJbTQLZZr169jDqZ4ylc8g2Ems7PIem2kv3S9v3Yrkf6ffK1thwx+r2219r2zbZ9ncOAyAv33XefsSxz0dWuXduok9dOeS8JAO3bt3fLGzduNOps/cXfHE/55Yux3TvJ9+prs8wd8tRTTxl18rU6d4jMh/L+++/73G8vbdiwwefyzJkzL/Tu+KTbnb8x7HRf0HkGfdGvk/1EX39lviF9by1zitpy2up12nI12X7f6GuzrU7uq+2aLu+fLyR9TpV5jvRvA3lu0jl+9XlMkr9BdRts27Ytz9fpfbHlctO/L/R+y987us3lsavbQG5f3yvu3LnTLcv8unpZn6dlLj6dZ9UfHPFEREREREREREQhwQdPREREREREREQUEmEVaieH7OkpASdOnOiWExMTjTo5BXHZsmWNOjl8UQ+ltIXu/PTTT0bd6NGj3bIeZteyZUsEg0NfTbo9ZNiEDgGTbSCndwVyHzvBTvEeiwKZRl2+VoefyqG5cgpZwGxn3V9lu9pCiABz2LLe/p49e3xuQx4venipPOb05w3HqdpDRQ5H1lMf+xvGoets77MdW/q1ciiznjI6Fulh0PI6p4fay/6sz5vyO9fnAdkv9DBvKb/zabDhQfK1+jou12kLAyW6UOR9JwB88MEHfr3vqquuMpblNUf3F9kPbCFytnOt7ue2/qvP0fK1+pwg01osWbLEqOvZs6fPbVDB4e+LwAQbmh9IWLqk70tl2JcOs5L3PDqUS29D/o7V10N5zbddYzX5WltaBFv4Xijpc0pmZqZb3rp1q1FXtWpVt1yhQgWjLikpyS3rUMiDBw+6Zf3bpFy5cm5Z35PK9qhcubJRJ+/PdLvq38Ny+/re7ejRoz7XI+8PddoM2XYyfA4w2zwhIcGok9+b/n3gD454IiIiIiIiIiKikOCDJyIiIiIiIiIiCgk+eCIiIiIiIiIiopAIq4QIMqZSx4xffvnlbnnx4sVG3f/+9z+3rPPJyKkudcyknLpVv/ebb74x6mQMp566UcZe6vhX23SWZNLxpzI2Vscjy+9Vt6telm2ntyFjYwnYvXu3sZyenu6WdS4ZGT+uY8ll7iQdOyynil27dq1RJ2PbdRyznirdlgNKxlnrWG15fOjpVGWcuz42/J1eNxLJPqLl1w6S7Ke2/CG6Tn+3tnw/8tqg97tZs2ZuWecWiVb6Wimn09Xx/vK71NPu2vLC+Dstc359RF4fdW4MW64MmevGlmMi2DwdRAXJdu7Tx688vzZu3Nio27t3r89t2PKu2XKt+JsvTdOvtU2jvmPHDrd8zz33GHUyX6qeQlx+F7ovM2cRhZLt+NL5mCR9bZT9xHY9lL9vAODAgQM+1ymv4/nlZZPvDeQaa3udLfeb7ZzRqFEjt/zbb7/5te1gyDzPAFCvXj23rHOzys+2c+dOo04+E7Dl0tJtJ3PKyjJgHg8///yzUSfPm9WqVTPq9H22/N2i6+R69LEjf3/ZzuGavKbo39TyPK1zKvuDI56IiIiIiIiIiCgk+OCJiIiIiIiIiIhCIqxC7S655BK3rIcOb9iwwS3r0J06deq4ZT2tepkyZdyyDhmRw/EAYNmyZW5ZDnsEzKnb16xZY9RddtllblkPgdPTtZNvtmGptimBdZiXXpYhWXqIpB5OGets021qtvaSwz1128lhm3rop2wPPQxf90lZr4fTZmVluWU9FFR+Rv0ZZFie7steTRV7ITRo0MBYtoU82Kbxtg3JDuR18riz9X3d7i1atHDLsRJqp0NJbdMbT5482S23adPGqJPtqq+Vtr5uO0foOnld1+0qz9u6btOmTW65Vq1aRp08nzAch8JBsCGfeipuW8ixvMbqfi6X9f2Qvrf2lw7hkOdefR8lz0l6ynJJn2eYmoK8oq8dsi8uX77cqJP3kLawNF0nzwv6WJd9VvcLeW3W13t9rrGF2gV7DyvPIbbPpM8t8rd5KEPtPvzwQ2NZ/l5v3ry5UZeRkeGW9X1v5cqV81wHYIazyfQ+gJnyQf9ukSlKZCoRwDzGMjMzjTr9PctjQt4P6e1XrFjRqNu/f79b1ulJbOls5OfXv5vlOnVaIn9E7y8pIiIiIiIiIiLyFB88ERERERERERFRSPDBExERERERERERhURY5XiScaQ6jlVOcyjL+n0658euXbvcss4no19rm+pZTq0uc1EBZmykjguVOZ5suUoosLwIMv+OjofWZGyuLW6Wck/fLGPZdeyy/F51biiZh03nWJL52nRMeOnSpX3W6fh0eY6QcdSA2UePHDkCX/T7ZCyzziU3e/Zsn+uJdO3bt/f7tbb8S7YcAvK1tpwkmi3vhz5GmjZt6vO10UqfN2W+Fd33Dh8+7JZl/kPA7N/6ew22zW3TOdtyPOn3bd682ec2JOaIoUimc4DIfqCPbXmN07k7ZE42neMpkPtOW44puR59by33VU8T7ut1ROFkxowZbjkxMdGok/lG9bEv2a5/ttxMOjewvKbr663Ov2jr37bcmnK9+nW232byfbo/161b1+f7Qkn+Xp87d65Rp5cl2Zb6XNysWTO3rPNVyeND5pACgPnz57vlKlWqGHXyN4z+faF/m/irYcOGxvLll1/ulleuXGnU2Y5jeQ+o23/fvn0+9/O9997Ldx854omIiIiIiIiIiEKCD56IiIiIiIiIiCgkwirUTk6LrKcyl8OKbdNH66F+MnzANiRS09uQQw/10EbbsGby36FDh4xlOURbt50M7ZLDKnUdYA4ZlKFcALBt27ag9jVaff7558byTTfd5JZlaB1gHve6TpJTbwJmH9HhPnLYrp6iWU/pKYd/6rBZeR7Qx4OcblRP9SxDL3V4z7hx4xCtdIiaPP/pod22odyyTfS5ULZJfmG18nxrC/HU52k5fW+sOHjwoLFs+25lqN3LL79s1NWsWdMt6z4r21y3vzy/6mujHrIv63X/lu0qh4AD5vVfD2XX2ySKVHoqbHld031JhtfplAHyHKDPn/I8rO+rdN+Wr9X9TNbpa4S8f9chK5I+f+sQXyKvyP62bt06o07+NtHHrLyO6bQs8pqnr3+NGzd2y7o/yxQuenv6t7K879LnDFv/sl3jbecMWaf3RYZkRQL5Wfbs2WPU/ec///H5vh07drjln376qeB3LAArVqywLocDjngiIiIiIiIiIqKQ4IMnIiIiIiIiIiIKCT54IiIiIiIiIiKikPA0IZGOP5U5XHRsrMzj42+cKmDGu+r8TzouXcbV6thzuW86Zl7mDSpbtqxRJ2M/9eeVy4FMcRutdJ4eme9At4delho1amQsb9++3S3rXER6uvFYp/PFyKky5XSiADB27Fif7+vfv79blnllALNP6D5Yvnx5t5zflK4yD4zOP1GrVi23rM8lkyZNcss1atQw6tLS0tyyzg2lc5BFk+uvv95Ybtu2rVueOXOmUWebdtffPHr55R6QbabrNmzY4JaXL19u1N12221+bT+a6LxW8nqkr1XyHDt06NDQ7lgBSkpKcsuvv/66USf7qf68ROHGliNl+vTpRp28l9H5EOUU3vocKe95dN4Vea3M7/wt36vvz+Q9cWZmplG3Zs0at/z222/DF973Urhau3atW+7WrZtRJ/ub/s0nzZgxw1hu3ry5Wy5XrpxRN23aNLdctWpVo05e0/X79G8a+ZtX31/re+Fg7Nq1y1iWv6F0ztw333zzvLdH0YcjnoiIiIiIiIiIKCT44ImIiIiIiIiIiEIizvFzrKsekhsK3bt3d8s6zOXIkSNB7YscOqyn97ZNO62HKMpt6u3LYZA//PCDUZeVleX3vvqrIIcnX4h29Ve9evWM5Ztvvtkt6+m9d+7c6ZanTJli1OmwITlsVYdizJo1yy3rKVMvtHBs1+uuu84t6/aZOHGiW5bhc5oeCiyHJus+KcPn5HTRQO5hwrap2f01YsQIY1mGDyxdutSo+/jjj4PaRkGHE1zoPjtkyBBjOTU11S3rEEs55eycOXOMutq1a7vlzz77zKgbPXq0sfzee+8Ft7MXWDj02VatWhnLclpmGboKAJMnT3bLq1atMupsYekX4piT29Dbl2S4AmBO2Xz8+HGjbvfu3UHtSzi0KxW8SG7X+vXrG8uyn+uQcRmGJ+9PAfPeVn8f2dnZxvLevXvdsg6nk+F8P//8s1En788uhEi/xpJv4dBnq1WrZiw3aNDALev70ssuu8wt632X/fLhhx826vS1K1LIe2Z9/rAJh3algudPu3LEExERERERERERhQQfPBERERERERERUUjwwRMREREREREREYWE3zmeiIiIiIiIiIiIAsERT0REREREREREFBJ88ERERERERERERCHBB09ERERERERERBQSfPBEREREREREREQhwQdPREREREREREQUEnzwREREREREREREIcEHT0REREREREREFBJ88ERERERERERERCHBB09ERERERERERBQS/x+4HhVCj0/v8wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_labels_and_predictions(dataset, predictions):\n",
        "    num_classes = 10  # Assuming FashionMNIST or a similar dataset with 10 classes\n",
        "    fig, axes = plt.subplots(1, num_classes, figsize=(15, 2))\n",
        "    class_images = {}\n",
        "\n",
        "    # Collect one correctly predicted image for each class\n",
        "    for idx in range(len(dataset)):\n",
        "        image, true_label = dataset[idx][0], dataset[idx][1]\n",
        "        predicted_label = predictions[idx]\n",
        "        if true_label not in class_images and true_label == predicted_label:\n",
        "            class_images[true_label] = (image, predicted_label)\n",
        "\n",
        "        if len(class_images) == num_classes:\n",
        "            break\n",
        "\n",
        "    # Plot the images\n",
        "    for label in range(num_classes):\n",
        "        ax = axes[label]\n",
        "        image, predicted_label = class_images[label]\n",
        "        ax.imshow(image.squeeze(), cmap='gray')\n",
        "        ax.set_title(f'True: {label}\\nPred: {predicted_label}')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "visualize_labels_and_predictions(test_set, Y_pred)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}